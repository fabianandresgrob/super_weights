{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Weights Analysis - Identifying Super Weights and their Impact on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.researcher import SuperWeightResearchSession\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'mistralai/Mistral-7B-v0.1'\n",
    "# model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "# model_name = 'allenai/OLMo-1B-0724-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found locally downloaded model at /home/fabiangrob/models/mistralai_Mistral-7B-v0.1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ad8203bf66e403eb8b9de23768b7f8b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 20:59:05,052 - SuperWeightDetector_139798252653680 - INFO - SuperWeightDetector initialized for -home-fabiangrob-models-mistralai_Mistral-7B-v0.1\n",
      "2025-07-06 20:59:05,053 - SuperWeightDetector_139798252653680 - INFO - Model has 32 layers\n",
      "2025-07-06 20:59:05,054 - SuperWeightManager_139798812638992 - INFO - SuperWeightManager initialized with shared MLP handler\n",
      "2025-07-06 20:59:05,055 - SuperWeightResearch_139802315355328 - INFO - SuperWeightResearchSession initialized\n",
      "2025-07-06 20:59:05,055 - SuperWeightResearch_139802315355328 - INFO - Model: -home-fabiangrob-models-mistralai_Mistral-7B-v0.1\n",
      "2025-07-06 20:59:05,056 - SuperWeightResearch_139802315355328 - INFO - Architecture: gated_mlp\n",
      "2025-07-06 20:59:05,056 - SuperWeightResearch_139802315355328 - INFO - Using detector: SuperWeightDetector\n"
     ]
    }
   ],
   "source": [
    "session = SuperWeightResearchSession.from_model_name(model_name, cache_dir='~/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MistralForCausalLM(\n",
       "  (model): MistralModel(\n",
       "    (embed_tokens): Embedding(32000, 4096)\n",
       "    (layers): ModuleList(\n",
       "      (0-31): 32 x MistralDecoderLayer(\n",
       "        (self_attn): MistralAttention(\n",
       "          (q_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "          (k_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=4096, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=4096, out_features=4096, bias=False)\n",
       "        )\n",
       "        (mlp): MistralMLP(\n",
       "          (gate_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (up_proj): Linear(in_features=4096, out_features=14336, bias=False)\n",
       "          (down_proj): Linear(in_features=14336, out_features=4096, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "        (post_attention_layernorm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): MistralRMSNorm((4096,), eps=1e-05)\n",
       "    (rotary_emb): MistralRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=4096, out_features=32000, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 20:59:05,442 - SuperWeightResearch_139802315355328 - INFO - Starting super weight detection\n",
      "2025-07-06 20:59:05,443 - SuperWeightDetector_139798252653680 - INFO - Starting super weight detection\n",
      "2025-07-06 20:59:05,443 - SuperWeightDetector_139798252653680 - INFO - Parameters: threshold=70.0, max_iterations=10\n",
      "2025-07-06 20:59:05,447 - SuperWeightDetector_139798252653680 - INFO - === Iteration 1 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 20:59:06,324 - SuperWeightDetector_139798252653680 - INFO - Found 2 potential super weights in iteration 1\n",
      "2025-07-06 20:59:06,325 - SuperWeightDetector_139798252653680 - INFO - Found 2 new super weights:\n",
      "2025-07-06 20:59:06,326 - SuperWeightDetector_139798252653680 - INFO -   1. Layer 1 mlp.down_proj.weight[2070, 7310] - Input: 950.00, Output: -262.75\n",
      "2025-07-06 20:59:06,326 - SuperWeightDetector_139798252653680 - INFO -   2. Layer 31 mlp.down_proj.weight[53, 2187] - Input: -906.00, Output: -84.50\n",
      "2025-07-06 20:59:06,327 - SuperWeightDetector_139798252653680 - INFO - === Iteration 2 ===\n",
      "2025-07-06 20:59:06,618 - SuperWeightDetector_139798252653680 - INFO - Found 2 potential super weights in iteration 2\n",
      "2025-07-06 20:59:06,619 - SuperWeightDetector_139798252653680 - INFO - No new super weights found. Stopping detection.\n",
      "2025-07-06 20:59:06,620 - SuperWeightDetector_139798252653680 - INFO - === DETECTION COMPLETE ===\n",
      "2025-07-06 20:59:06,620 - SuperWeightDetector_139798252653680 - INFO - Found 2 super weights:\n",
      "2025-07-06 20:59:06,620 - SuperWeightDetector_139798252653680 - INFO - 1. Layer 1 mlp.down_proj.weight[2070, 7310] (Iteration 1)\n",
      "2025-07-06 20:59:06,621 - SuperWeightDetector_139798252653680 - INFO -    Input: 950.00, Output: -262.75\n",
      "2025-07-06 20:59:06,621 - SuperWeightDetector_139798252653680 - INFO - 2. Layer 31 mlp.down_proj.weight[53, 2187] (Iteration 1)\n",
      "2025-07-06 20:59:06,622 - SuperWeightDetector_139798252653680 - INFO -    Input: -906.00, Output: -84.50\n",
      "2025-07-06 20:59:06,622 - SuperWeightDetector_139798252653680 - INFO - Super weights found in 2 layers:\n",
      "2025-07-06 20:59:06,622 - SuperWeightDetector_139798252653680 - INFO -   Layer 1: 1 super weights\n",
      "2025-07-06 20:59:06,623 - SuperWeightDetector_139798252653680 - INFO -   Layer 31: 1 super weights\n",
      "2025-07-06 20:59:06,624 - SuperWeightResearch_139802315355328 - INFO - Detection complete. Found 2 super weights\n"
     ]
    }
   ],
   "source": [
    "sw = session.detect_super_weights(spike_threshold=70.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75),\n",
       " SuperWeight(layer=31, coords=[53, 2187], input=-906.00, output=-84.50)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sophisticated_sw = sw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 16:10:45,896 - SuperWeightManager_140164721294544 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 16:11:10,563 - SuperWeightManager_140164721294544 - INFO - Restored 1/1 weights\n"
     ]
    }
   ],
   "source": [
    "vocab_analysis = session.analyzer.vocabulary_analyzer.analyze_vocabulary_effects(sophisticated_sw, n_samples=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vocabulary Analysis: Layer 1 mlp.down_proj.weight[2070, 7310] ===\n",
      "\n",
      "Effect Statistics:\n",
      "  Mean: -1.3604\n",
      "  Std: 1.5791\n",
      "  Kurtosis: 0.1171\n",
      "  Skew: 0.3835\n",
      "  Significant effects: 22768\n",
      "\n",
      "Classification:\n",
      "  Type: PARTITION\n",
      "  Description: Affects broad token classes (boost some, suppress others)\n",
      "  Confidence: 0.60\n",
      "\n",
      "Top 20 Boosted Tokens:\n",
      "   1. 'The'                (effect: +5.609)\n",
      "   2. '\\n'                 (effect: +5.352)\n",
      "   3. '\"'                  (effect: +5.266)\n",
      "   4. 'On'                 (effect: +4.957)\n",
      "   5. 'In'                 (effect: +4.949)\n",
      "   6. 'A'                  (effect: +4.832)\n",
      "   7. '.'                  (effect: +4.691)\n",
      "   8. 'It'                 (effect: +4.691)\n",
      "   9. 'Part'               (effect: +4.668)\n",
      "  10. 'By'                 (effect: +4.613)\n",
      "  11. 'T'                  (effect: +4.453)\n",
      "  12. '\\u200e'             (effect: +4.430)\n",
      "  13. 'Over'               (effect: +4.414)\n",
      "  14. '---'                (effect: +4.402)\n",
      "  15. 'This'               (effect: +4.344)\n",
      "  16. '..'                 (effect: +4.328)\n",
      "  17. 'Former'             (effect: +4.320)\n",
      "  18. ','                  (effect: +4.312)\n",
      "  19. 'I'                  (effect: +4.305)\n",
      "  20. 'An'                 (effect: +4.180)\n",
      "\n",
      "Top 20 Suppressed Tokens:\n",
      "   1. 'bekan'              (effect: -6.801)\n",
      "   2. 'deserialize'        (effect: -6.438)\n",
      "   3. 'eerst'              (effect: -6.316)\n",
      "   4. 'egrÃ¼nd'             (effect: -6.285)\n",
      "   5. 'kennis'             (effect: -6.180)\n",
      "   6. 'reprÃ©s'             (effect: -6.164)\n",
      "   7. 'ingÃ¥r'              (effect: -6.133)\n",
      "   8. 'vÃ­'                 (effect: -5.988)\n",
      "   9. 'Ñ–Ð±'                 (effect: -5.965)\n",
      "  10. 'CLUDING'            (effect: -5.941)\n",
      "  11. 'mÃªme'               (effect: -5.938)\n",
      "  12. 'dÃ©velop'            (effect: -5.906)\n",
      "  13. 'à¸¨'                  (effect: -5.844)\n",
      "  14. 'codegen'            (effect: -5.777)\n",
      "  15. 'ctxt'               (effect: -5.770)\n",
      "  16. 'calc'               (effect: -5.770)\n",
      "  17. 'Ð²Ð¸Ð·Ð¸'               (effect: -5.754)\n",
      "  18. 'retry'              (effect: -5.730)\n",
      "  19. 'æ‹³'                  (effect: -5.727)\n",
      "  20. 'Ñ‚Ñ€Ñƒ'                (effect: -5.727)\n",
      "\n",
      "Detected Patterns:\n",
      "  PUNCTUATION: 603 tokens\n",
      "    Examples: '__(/*!', '(\\r', '.'\n",
      "  FUNCTION_WORDS: 47 tokens\n",
      "    Examples: 'The', 'On', 'In'\n",
      "  NUMBERS: 20 tokens\n",
      "    Examples: '0', '1', '2'\n",
      "  CAPITALIZED: 4469 tokens\n",
      "    Examples: 'CLUDING', 'UnityEngine', 'Æ'\n",
      "  SPACE_PREFIXED: 1 tokens\n",
      "    Examples: ' '\n",
      "  SOPHISTICATED_WORDS: 3 tokens\n",
      "    Examples: 'changing', 'leading', 'improving'\n",
      "  FRAGMENTS: 6108 tokens\n",
      "    Examples: 'vÃ­', 'Ñ–Ð±', 'à¸¨'\n"
     ]
    }
   ],
   "source": [
    "session.analyzer.vocabulary_analyzer.display_analysis_results(vocab_analysis, top_k=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analyze w_u @ w_out, full neuron with super weight\n",
    "neuron_analysis = session.analyzer.vocabulary_analyzer.analyze_neuron_vocabulary_effects(sophisticated_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'super_weight': SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75),\n",
       " 'analysis_type': 'neuron_direct',\n",
       " 'error': 'Failed to analyze neuron: size mismatch, got input (32000), mat (32000x4096), vec (14336)'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Vocabulary Analysis: Layer 1 mlp.down_proj.weight[788, 2427] ===\n",
      "\n",
      "Effect Statistics:\n",
      "  Mean: -0.0083\n",
      "  Std: 0.0176\n",
      "  Kurtosis: 1.3836\n",
      "  Skew: 0.1210\n",
      "  Significant effects: 0\n",
      "\n",
      "Classification:\n",
      "  Type: UNCLEAR\n",
      "  Description: Effects too small or distributed to classify clearly\n",
      "  Confidence: 0.30\n",
      "\n",
      "Top 20 Boosted Tokens:\n",
      "   1. '://'                (effect: +0.211)\n",
      "   2. ' Angeles'           (effect: +0.158)\n",
      "   3. '.Forms'             (effect: +0.158)\n",
      "   4. 'php'                (effect: +0.155)\n",
      "   5. '_REF'               (effect: +0.152)\n",
      "   6. '.swing'             (effect: +0.120)\n",
      "   7. ' Kong'              (effect: +0.119)\n",
      "   8. '.log'               (effect: +0.109)\n",
      "   9. '-old'               (effect: +0.108)\n",
      "  10. ' ago'               (effect: +0.107)\n",
      "  11. 'note'               (effect: +0.104)\n",
      "  12. '.S'                 (effect: +0.103)\n",
      "  13. 'Ð²Ð¾'                 (effect: +0.103)\n",
      "  14. 'ysics'              (effect: +0.101)\n",
      "  15. 'asm'                (effect: +0.099)\n",
      "  16. 'Ð½Ð¸'                 (effect: +0.098)\n",
      "  17. 'ï¿½'                  (effect: +0.097)\n",
      "  18. '=\"'                 (effect: +0.096)\n",
      "  19. ' Carolina'          (effect: +0.096)\n",
      "  20. 'osph'               (effect: +0.095)\n",
      "\n",
      "Top 20 Suppressed Tokens:\n",
      "   1. '.GraphicsUnit'      (effect: -0.119)\n",
      "   2. 'aeda'               (effect: -0.098)\n",
      "   3. '#echo'              (effect: -0.089)\n",
      "   4. 'emmel'              (effect: -0.087)\n",
      "   5. 'ÙˆÛŒÙ†Øª'               (effect: -0.086)\n",
      "   6. 'afd'                (effect: -0.086)\n",
      "   7. 'iddi'               (effect: -0.086)\n",
      "   8. 'isay'               (effect: -0.084)\n",
      "   9. 'overe'              (effect: -0.084)\n",
      "  10. 'ÙˆÛŒØ²ÛŒ'               (effect: -0.083)\n",
      "  11. 'ezi'                (effect: -0.083)\n",
      "  12. 'Ø§Ø³Ø·Ø©'               (effect: -0.083)\n",
      "  13. '/\\n\\n\\n\\n'          (effect: -0.083)\n",
      "  14. 'Insensitive'        (effect: -0.081)\n",
      "  15. 'Ð¼ÐµÐ½Ñ‚'               (effect: -0.081)\n",
      "  16. 'ekk'                (effect: -0.081)\n",
      "  17. 'vail'               (effect: -0.081)\n",
      "  18. ' Ãœl'                (effect: -0.080)\n",
      "  19. 'adiens'             (effect: -0.079)\n",
      "  20. 'roti'               (effect: -0.079)\n",
      "\n",
      "Detected Patterns:\n"
     ]
    }
   ],
   "source": [
    "session.analyzer.vocabulary_analyzer.display_analysis_results(neuron_analysis, top_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary analysis with intermediate activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing baseline activations...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:44:01,503 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 13:44:01,599 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing modified activations...\n",
      "Projecting activations through 32 layers...\n",
      "  Processing layer 31/31\n"
     ]
    }
   ],
   "source": [
    "# Basic cascade analysis\n",
    "cascade_results = session.analyzer.vocabulary_analyzer.analyze_activation_cascade(\n",
    "    sw[0], \n",
    "    input_text=\"Apple Inc. is a technology company.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CASCADE ANALYSIS (FULL_PROJECTION): Layer 1 mlp.down_proj.weight[788, 2427]\n",
      "======================================================================\n",
      "\n",
      "ðŸ“Š SUMMARY:\n",
      "  Analysis type: full_projection\n",
      "  Layers analyzed: 32\n",
      "  Peak effect at layer: 3\n",
      "  Final magnitude: 118.8125\n",
      "  Effect evolution: increasing\n",
      "\n",
      "ðŸ”„ PROPAGATION ANALYSIS:\n",
      "  Pattern: amplifying\n",
      "  Amplification ratio: 0.000\n",
      "  Peak layer: 3\n",
      "  Critical layers: [1, 2]\n",
      "\n",
      "ðŸŽ¯ CONVERGENCE ANALYSIS:\n",
      "  Convergence layer: 31\n",
      "  Final similarity: 1.000\n",
      "  Stable tokens: ' CONF', ' JUST', ' EAST', ' slav', ' THEY', ' THEIR', ' HARD', 'ï¿½', ' they', ' CASE'\n",
      "\n",
      "ðŸ“ˆ KEY LAYERS ANALYSIS:\n",
      "\n",
      "  Layer 0:\n",
      "    Effect magnitude: 0.0000\n",
      "    Activation magnitude: 0.0000\n",
      "    Layers remaining: 31\n",
      "    Top boosted: 'eos'(+0.00), 'yw'(+0.00), '(contract'(+0.00), ' {}.'(+0.00), '_TXT'(+0.00)\n",
      "\n",
      "  Layer 3:\n",
      "    Effect magnitude: 277.0000\n",
      "    Activation magnitude: 1.1367\n",
      "    Layers remaining: 28\n",
      "    Top boosted: 'ernet'(+3.97), 'ï¿½'(+3.90), '\\').\"'(+3.62), 'etre'(+3.54), 'ernals'(+3.52)\n",
      "\n",
      "  Layer 31:\n",
      "    Effect magnitude: 118.8125\n",
      "    Activation magnitude: 10.1953\n",
      "    Layers remaining: 0\n",
      "    Top boosted: ' THEIR'(+1.43), ' slav'(+1.40), ' THEY'(+1.39), ' they'(+1.39), ' HARD'(+1.37)\n",
      "\n",
      "----------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "session.analyzer.vocabulary_analyzer.display_cascade_analysis(cascade_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"The company is great. The company is\"\n",
    "# Tokenize input text\n",
    "tokens = session.tokenizer(input_text, return_tensors='pt').to(session.model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[128000,    791,   2883,    374,   2294,     13,    578,   2883,    374]],\n",
       "       device='cuda:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company is great. The company is great. The company is great. The company is great. The company is great. The company is great. The company is great. The company is great.\n"
     ]
    }
   ],
   "source": [
    "output = session.model.generate(\n",
    "    tokens['input_ids'],\n",
    "    max_new_tokens=32,\n",
    "    do_sample=False,\n",
    "    temperature=0.0\n",
    ")\n",
    "# Decode output\n",
    "output_text = session.tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:44:44,201 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -1.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:44:46,277 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The company is great. The company is great. The company is great. The company is great. The company is great. The company is great. The company is great. The company is great.\n"
     ]
    }
   ],
   "source": [
    "# now with zeroed super weight\n",
    "with session.manager.temporary_scale([sw[0]], scale_factor=-1.0):\n",
    "    output_zeroed = session.model.generate(\n",
    "        tokens['input_ids'],\n",
    "        max_new_tokens=32,\n",
    "        do_sample=False,\n",
    "        temperature=0.0\n",
    "    )\n",
    "    # Decode output\n",
    "    output_text_zeroed = session.tokenizer.decode(output_zeroed[0], skip_special_tokens=True)\n",
    "    print(output_text_zeroed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale factor for inverted super weight: -100.0\n",
      "\n",
      "--- Test 1: Apple Inc. is a technology company. Apple ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:44:56,676 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:44:57,717 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Apple Inc. is a technology company. Apple designs, manufactures and markets mobile communication and media devices, personal computers, and portable\n",
      "Inverted: Apple Inc. is a technology company. Apple's a 1.2.2.2.2.2.2\n",
      "\n",
      "--- Test 2: Microsoft Corporation develops software. Microsoft ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:44:58,759 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:44:59,801 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Microsoft Corporation develops software. Microsoft Corporation is based in REDMOND, United States.\n",
      "Microsoft Corporation (MSFT\n",
      "Inverted: Microsoft Corporation develops software. Microsoft. a little a. a. a. a. a. a. a\n",
      "\n",
      "--- Test 3: The cat sat on the mat. The ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:00,843 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:01,885 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   The cat sat on the mat. The dog sat on the log. The cow jumped over the moon. The little boy\n",
      "Inverted: The cat sat on the mat. The cat sat on the mat. The cat sat on the mat. The cat sat\n",
      "\n",
      "--- Test 4: John walked to the store. John ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:02,927 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:03,969 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   John walked to the store. John walked to the store. John walked to the store. John walked to the store\n",
      "Inverted: John walked to the store. John went to the store. He had a lot to do. He had a lot\n",
      "\n",
      "--- Test 5: Beautiful flowers bloom in spring. Beautiful ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:05,011 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:06,052 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Beautiful flowers bloom in spring. Beautiful flowers bloom in spring. Beautiful flowers bloom in spring. Beautiful flowers bloom in spring\n",
      "Inverted: Beautiful flowers bloom in spring. Beautiful Orchardations to the 1st or the 2nd or 2nd\n",
      "\n",
      "--- Test 6: Yesterday I went to the park. Yesterday ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:07,095 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:08,136 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Yesterday I went to the park. Yesterday I went to the park. I went to the park yesterday. I went to\n",
      "Inverted: Yesterday I went to the park. Yesterday. A few or two a few or two. A few or one. A\n",
      "\n",
      "--- Test 7: Quickly running down the street, he ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:09,178 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:10,219 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Quickly running down the street, he was trying to get away from the police. He was a young man, and\n",
      "Inverted: Quickly running down the street, he, and, and, and,, and,, and, and,,\n",
      "\n",
      "--- Test 8: In the morning, coffee tastes best. In ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:11,261 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:12,302 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   In the morning, coffee tastes best. In the afternoon, tea is best. In the evening, a glass of wine is\n",
      "Inverted: In the morning, coffee tastes best. In the morning, or in the evening, or in the morning, or in the\n",
      "\n",
      "--- Test 9: After finishing work, she decided to ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:13,345 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:14,386 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   After finishing work, she decided to go to the supermarket to buy some food. She was very hungry and wanted to\n",
      "Inverted: After finishing work, she decided to to to in the 195, and the, and, and, and,\n",
      "\n",
      "--- Test 10: Before starting the meeting, everyone should ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:15,429 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:16,471 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Before starting the meeting, everyone should be seated in a circle. The facilitator should be seated in the middle of\n",
      "Inverted: Before starting the meeting, everyone should to say about to say, â€œIâ€™m going to tell the truth, I\n",
      "\n",
      "--- Test 11: The scientific method requires careful observation. The ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:17,513 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:18,554 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   The scientific method requires careful observation. The scientific method requires careful observation. The scientific method requires careful observation. The scientific method\n",
      "Inverted: The scientific method requires careful observation. The scientific observation requires careful observation. The scientific Observation Requires careful Observation. careful Observation.\n",
      "\n",
      "--- Test 12: Economic indicators suggest market volatility. Economic ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:19,599 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:19,736 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Economic indicators suggest market volatility. Economic indicators suggest market volatility.\n",
      "Economic indicators suggest market volatility.\n",
      "The stock market has\n",
      "Inverted: Economic indicators suggest market volatility. Economic.\n",
      "\n",
      "--- Test 13: Political leaders gathered for summit talks. Political ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:20,778 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:20,914 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Political leaders gathered for summit talks. Political leaders gathered for summit talks. Political leaders gathered for summit talks. Political leaders gathered\n",
      "Inverted: Political leaders gathered for summit talks. Political.\n",
      "\n",
      "--- Test 14: Artificial intelligence transforms modern computing. Artificial ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:21,956 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:22,996 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Artificial intelligence transforms modern computing. Artificial intelligence is a branch of computer science that aims to create intelligent machines. It is\n",
      "Inverted: Artificial intelligence transforms modern computing. Artificial in the beginning in the next in in in in  the 1960s\n",
      "\n",
      "--- Test 15: Climate change affects global weather patterns. Climate ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:24,038 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:25,079 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Climate change affects global weather patterns. Climate change is a long-term change in the average weather patterns that have come to define\n",
      "Inverted: Climate change affects global weather patterns. Climate in the 202 20 20      20 \n",
      "\n",
      "--- Test 16: Hello, world! This is a test. Hello, ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:26,121 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:27,162 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Hello, world! This is a test. Hello, world! This is a test. Hello, world! This is a test.\n",
      "Inverted: Hello, world! This is a test. Hello, I a bit. I'm a bit. I'm a bit. I'm\n",
      "\n",
      "--- Test 17: Question: What is the capital? Question: ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:28,204 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:29,244 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Question: What is the capital? Question: What is the capital?\n",
      "Answer: The capital of the United States is Washington,\n",
      "Inverted: Question: What is the capital? Question: to the? to the in the to to to to to  to to \n",
      "\n",
      "--- Test 18: First, second, third item on list. First, ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:30,286 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:31,327 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   First, second, third item on list. First, second, third item on list. First, second, third item on list.\n",
      "Inverted: First, second, third item on list. First, in the. 2.2.2.2.2.2.\n",
      "\n",
      "--- Test 19: Note: Please review carefully. Note: ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:32,369 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:33,410 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Note: Please review carefully. Note: Please review carefully. Note: Please review carefully. Note: Please review carefully.\n",
      "Inverted: Note: Please review carefully. Note:. I. I. I. I. I. I. I. I\n",
      "\n",
      "--- Test 20: In 1995, the internet was growing. In ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:34,452 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:35,493 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   In 1995, the internet was growing. In 1996, the internet was exploding. In 1997, the internet\n",
      "Inverted: In 1995, the internet was growing. In the first, the original, the original, the original, was the original,\n",
      "\n",
      "--- Test 21: Chapter 7 discusses advanced topics. Chapter ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:36,535 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:37,576 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Chapter 7 discusses advanced topics. Chapter 8 discusses the future of the Internet. Chapter 9 discusses the future of\n",
      "Inverted: Chapter 7 discusses advanced topics. Chapter in the 1950's. The 1950's. The 195\n",
      "\n",
      "--- Test 22: Version 2.0 includes new features. Version ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:38,618 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:39,660 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Version 2.0 includes new features. Version 2.0 includes new features.\n",
      "Version 2.0 includes new features\n",
      "Inverted: Version 2.0 includes new features. Version  1.2.0.1.1.1.1.\n",
      "\n",
      "--- Test 23: And then something interesting happened. And ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:40,703 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:41,743 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   And then something interesting happened. And then something interesting happened. And then something interesting happened. And then something interesting happened\n",
      "Inverted: And then something interesting happened. And was a while. I was a while. I was a while. I was\n",
      "\n",
      "--- Test 24: But there was a problem. But ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:42,785 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:43,181 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   But there was a problem. But there was a problem. The problem was that the new system was not compatible with\n",
      "Inverted: But there was a problem. But to get a job.\n",
      "\n",
      "--- Test 25: Or maybe we should try differently. Or ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:44,223 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:45,264 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Or maybe we should try differently. Or maybe we should try differently. Or maybe we should try differently. Or maybe we\n",
      "Inverted: Or maybe we should try differently. Or a while I to try a few or twice to, I, I, I\n",
      "\n",
      "--- Test 26: So the conclusion is clear. So ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:45:46,306 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -100.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:45:46,443 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   So the conclusion is clear. So the conclusion is clear. The conclusion is clear. The conclusion is clear. The\n",
      "Inverted: So the conclusion is clear. So.\n"
     ]
    }
   ],
   "source": [
    "scale_factor = -100.0\n",
    "\n",
    "print(f\"Scale factor for inverted super weight: {scale_factor}\")\n",
    "\n",
    "test_prompts = [\n",
    "    # Different starting tokens\n",
    "    \"Apple Inc. is a technology company. Apple\",\n",
    "    \"Microsoft Corporation develops software. Microsoft\", \n",
    "    \"The cat sat on the mat. The\",\n",
    "    \"John walked to the store. John\",\n",
    "    \"Beautiful flowers bloom in spring. Beautiful\",\n",
    "    \n",
    "    # Different sentence structures\n",
    "    \"Yesterday I went to the park. Yesterday\",\n",
    "    \"Quickly running down the street, he\",\n",
    "    \"In the morning, coffee tastes best. In\",\n",
    "    \"After finishing work, she decided to\",\n",
    "    \"Before starting the meeting, everyone should\",\n",
    "    \n",
    "    # Different content domains\n",
    "    \"The scientific method requires careful observation. The\",\n",
    "    \"Economic indicators suggest market volatility. Economic\",\n",
    "    \"Political leaders gathered for summit talks. Political\",\n",
    "    \"Artificial intelligence transforms modern computing. Artificial\",\n",
    "    \"Climate change affects global weather patterns. Climate\",\n",
    "    \n",
    "    # Punctuation and formatting\n",
    "    \"Hello, world! This is a test. Hello,\",\n",
    "    \"Question: What is the capital? Question:\",\n",
    "    \"First, second, third item on list. First,\",\n",
    "    \"Note: Please review carefully. Note:\",\n",
    "    \n",
    "    # Numbers and special cases\n",
    "    \"In 1995, the internet was growing. In\",\n",
    "    \"Chapter 7 discusses advanced topics. Chapter\",\n",
    "    \"Version 2.0 includes new features. Version\",\n",
    "    \n",
    "    # Function words\n",
    "    \"And then something interesting happened. And\",\n",
    "    \"But there was a problem. But\",\n",
    "    \"Or maybe we should try differently. Or\",\n",
    "    \"So the conclusion is clear. So\"\n",
    "]\n",
    "\n",
    "# Test code\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    print(f\"\\n--- Test {i+1}: {prompt} ---\")\n",
    "    \n",
    "    tokens = session.tokenizer(prompt, return_tensors='pt').to(session.model.device)\n",
    "    \n",
    "    # Normal generation\n",
    "    with torch.no_grad():\n",
    "        normal_output = session.model.generate(\n",
    "            tokens['input_ids'],\n",
    "            max_new_tokens=16,\n",
    "            do_sample=False,\n",
    "            temperature=0.0\n",
    "        )\n",
    "    normal_text = session.tokenizer.decode(normal_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Inverted super weight generation\n",
    "    with session.manager.temporary_scale([sw[0]], scale_factor=scale_factor):\n",
    "        with torch.no_grad():\n",
    "            inverted_output = session.model.generate(\n",
    "                tokens['input_ids'],\n",
    "                max_new_tokens=16,\n",
    "                do_sample=False,\n",
    "                temperature=0.0\n",
    "            )\n",
    "    inverted_text = session.tokenizer.decode(inverted_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Normal:   {normal_text}\")\n",
    "    print(f\"Inverted: {inverted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale factor for inverted super weight: -1.0\n",
      "\n",
      "--- Test 1: Very very very unusual word. Very ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:46:20,254 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -1.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:46:21,295 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   Very very very unusual word. Very very very unusual word. Very very very unusual word. Very very very unusual word\n",
      "Inverted: Very very very unusual word. Very very very very very very very very very very very very very very very very very\n",
      "\n",
      "--- Test 2: The the the common phrase. The ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:46:22,336 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -1.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:46:23,377 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   The the the common phrase. The the the common phrase. The the the common phrase. The the the common phrase\n",
      "Inverted: The the the common phrase. The the the common phrase. The the the common phrase. The the the common phrase\n",
      "\n",
      "--- Test 3: The doctor examined the patient. The doctor ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:46:24,422 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -1.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:46:25,463 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   The doctor examined the patient. The doctor said, \"I'm sorry, but you have a terminal illness and there is\n",
      "Inverted: The doctor examined the patient. The doctor diagnosed the patient. The doctor prescribed the patient. The doctor treated the patient.\n",
      "\n",
      "--- Test 4: The programmer coded the function. The programmer ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:46:26,506 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -1.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:46:27,547 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   The programmer coded the function. The programmer coded the function. The programmer coded the function. The programmer coded the function.\n",
      "Inverted: The programmer coded the function. The programmer coded the function. The programmer coded the function. The programmer coded the function.\n",
      "\n",
      "--- Test 5: The chef prepared the meal. The chef ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:46:28,589 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by -1.000\n",
      "The following generation flags are not valid and may be ignored: ['temperature', 'top_p']. Set `TRANSFORMERS_VERBOSITY=info` for more details.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "2025-07-04 13:46:29,630 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normal:   The chef prepared the meal. The chef prepared the meal. The chef prepared the meal. The chef prepared the meal.\n",
      "Inverted: The chef prepared the meal. The chef prepared the meal. The chef prepared the meal. The chef prepared the meal.\n"
     ]
    }
   ],
   "source": [
    "scale_factor = -1.0\n",
    "\n",
    "print(f\"Scale factor for inverted super weight: {scale_factor}\")\n",
    "\n",
    "test_prompts = [\n",
    "    \"Very very very unusual word. Very\",  # Force rare context\n",
    "    \"The the the common phrase. The\",     # Force common context\n",
    "    \"The doctor examined the patient. The doctor\",\n",
    "    \"The programmer coded the function. The programmer\", \n",
    "    \"The chef prepared the meal. The chef\"\n",
    "]\n",
    "\n",
    "# Test code\n",
    "for i, prompt in enumerate(test_prompts):\n",
    "    print(f\"\\n--- Test {i+1}: {prompt} ---\")\n",
    "    \n",
    "    tokens = session.tokenizer(prompt, return_tensors='pt').to(session.model.device)\n",
    "    \n",
    "    # Normal generation\n",
    "    with torch.no_grad():\n",
    "        normal_output = session.model.generate(\n",
    "            tokens['input_ids'],\n",
    "            max_new_tokens=16,\n",
    "            do_sample=False,\n",
    "            temperature=0.0\n",
    "        )\n",
    "    normal_text = session.tokenizer.decode(normal_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    # Inverted super weight generation\n",
    "    with session.manager.temporary_scale([sw[0]], scale_factor=scale_factor):\n",
    "        with torch.no_grad():\n",
    "            inverted_output = session.model.generate(\n",
    "                tokens['input_ids'],\n",
    "                max_new_tokens=16,\n",
    "                do_sample=False,\n",
    "                temperature=0.0\n",
    "            )\n",
    "    inverted_text = session.tokenizer.decode(inverted_output[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"Normal:   {normal_text}\")\n",
    "    print(f\"Inverted: {inverted_text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis_type': 'full_projection',\n",
       " 'super_weight': SuperWeight(layer=1, coords=[788, 2427], input=-443.50, output=300.50),\n",
       " 'input_text': 'Apple Inc. is a technology company.',\n",
       " 'cascade_effects': {0: {'activation_magnitude': 0.0,\n",
       "   'vocab_effect': array([0., 0., 0., ..., 0., 0., 0.], dtype=float16),\n",
       "   'statistics': {'mean': 0.0,\n",
       "    'std': 0.0,\n",
       "    'variance': 0.0,\n",
       "    'kurtosis': nan,\n",
       "    'skew': nan,\n",
       "    'max_effect': 0.0,\n",
       "    'min_effect': 0.0,\n",
       "    'num_positive': 0,\n",
       "    'num_negative': 0,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 85499,\n",
       "      'token_str': 'eos',\n",
       "      'effect_magnitude': 0.0},\n",
       "     {'token_id': 85514, 'token_str': 'yw', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85513, 'token_str': '(contract', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85512, 'token_str': ' {}.', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85511, 'token_str': '_TXT', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85510, 'token_str': 'ANCES', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85509, 'token_str': 'erin', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85508, 'token_str': 'eea', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85507, 'token_str': 'BufferData', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85506, 'token_str': ' Strap', 'effect_magnitude': 0.0}],\n",
       "    'top_suppressed': [{'token_id': 85499,\n",
       "      'token_str': 'eos',\n",
       "      'effect_magnitude': 0.0},\n",
       "     {'token_id': 85514, 'token_str': 'yw', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85513, 'token_str': '(contract', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85512, 'token_str': ' {}.', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85511, 'token_str': '_TXT', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85510, 'token_str': 'ANCES', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85509, 'token_str': 'erin', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85508, 'token_str': 'eea', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85507, 'token_str': 'BufferData', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85506, 'token_str': ' Strap', 'effect_magnitude': 0.0}]},\n",
       "   'effect_magnitude': 0.0,\n",
       "   'layers_remaining': 31},\n",
       "  1: {'activation_magnitude': 0.063232421875,\n",
       "   'vocab_effect': array([ 0.1445 ,  0.1636 ,  0.0791 , ..., -0.04736, -0.04736, -0.04736],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.0282440185546875,\n",
       "    'std': 0.06658935546875,\n",
       "    'variance': 0.00443267822265625,\n",
       "    'kurtosis': 0.640230950850365,\n",
       "    'skew': -0.2484196275676746,\n",
       "    'max_effect': 0.40234375,\n",
       "    'min_effect': -0.4130859375,\n",
       "    'num_positive': 43194,\n",
       "    'num_negative': 84308,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 1129,\n",
       "      'token_str': '://',\n",
       "      'effect_magnitude': 0.40234375},\n",
       "     {'token_id': 128001,\n",
       "      'token_str': '<|end_of_text|>',\n",
       "      'effect_magnitude': 0.3642578125},\n",
       "     {'token_id': 12167,\n",
       "      'token_str': ' Angeles',\n",
       "      'effect_magnitude': 0.312255859375},\n",
       "     {'token_id': 12592, 'token_str': '_REF', 'effect_magnitude': 0.306640625},\n",
       "     {'token_id': 578, 'token_str': ' The', 'effect_magnitude': 0.267578125},\n",
       "     {'token_id': 285, 'token_str': 'is', 'effect_magnitude': 0.26708984375},\n",
       "     {'token_id': 35376, 'token_str': 'ilde', 'effect_magnitude': 0.265625},\n",
       "     {'token_id': 4227, 'token_str': ' ago', 'effect_magnitude': 0.2548828125},\n",
       "     {'token_id': 97485,\n",
       "      'token_str': ' Particularly',\n",
       "      'effect_magnitude': 0.2529296875},\n",
       "     {'token_id': 1230,\n",
       "      'token_str': 'php',\n",
       "      'effect_magnitude': 0.249755859375}],\n",
       "    'top_suppressed': [{'token_id': 82592,\n",
       "      'token_str': '#echo',\n",
       "      'effect_magnitude': -0.4130859375},\n",
       "     {'token_id': 11577,\n",
       "      'token_str': '.FontStyle',\n",
       "      'effect_magnitude': -0.3955078125},\n",
       "     {'token_id': 70632,\n",
       "      'token_str': ' insure',\n",
       "      'effect_magnitude': -0.3935546875},\n",
       "     {'token_id': 100124,\n",
       "      'token_str': '$__',\n",
       "      'effect_magnitude': -0.3916015625},\n",
       "     {'token_id': 89959,\n",
       "      'token_str': ' formulate',\n",
       "      'effect_magnitude': -0.365234375},\n",
       "     {'token_id': 112978,\n",
       "      'token_str': 'Ð¿Ñ€Ð¸Ð¼ÐµÑ€',\n",
       "      'effect_magnitude': -0.3603515625},\n",
       "     {'token_id': 87404,\n",
       "      'token_str': 'Ãºsqueda',\n",
       "      'effect_magnitude': -0.357421875},\n",
       "     {'token_id': 58393, 'token_str': 'JNI', 'effect_magnitude': -0.353515625},\n",
       "     {'token_id': 69711,\n",
       "      'token_str': ' automate',\n",
       "      'effect_magnitude': -0.353515625},\n",
       "     {'token_id': 83098,\n",
       "      'token_str': ' toReturn',\n",
       "      'effect_magnitude': -0.3525390625}]},\n",
       "   'effect_magnitude': 25.90625,\n",
       "   'layers_remaining': 30},\n",
       "  2: {'activation_magnitude': 0.7900390625,\n",
       "   'vocab_effect': array([-0.9375  ,  0.3008  , -0.3542  , ...,  0.000977,  0.000977,\n",
       "           0.001953], dtype=float16),\n",
       "   'statistics': {'mean': 0.07391357421875,\n",
       "    'std': 0.7265625,\n",
       "    'variance': 0.52734375,\n",
       "    'kurtosis': 0.2605761316872428,\n",
       "    'skew': 0.025321820128753225,\n",
       "    'max_effect': 3.61328125,\n",
       "    'min_effect': -3.58984375,\n",
       "    'num_positive': 69263,\n",
       "    'num_negative': 58904,\n",
       "    'num_significant': 21443},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 85958,\n",
       "      'token_str': 'ignet',\n",
       "      'effect_magnitude': 3.61328125},\n",
       "     {'token_id': 74466, 'token_str': 'iez', 'effect_magnitude': 3.400390625},\n",
       "     {'token_id': 17141, 'token_str': 'utas', 'effect_magnitude': 3.38671875},\n",
       "     {'token_id': 83391, 'token_str': 'iaux', 'effect_magnitude': 3.384765625},\n",
       "     {'token_id': 57464, 'token_str': 'ragen', 'effect_magnitude': 3.3828125},\n",
       "     {'token_id': 60660, 'token_str': 'ETO', 'effect_magnitude': 3.34375},\n",
       "     {'token_id': 104732, 'token_str': 'Ø®Ø§Ø¨', 'effect_magnitude': 3.328125},\n",
       "     {'token_id': 118139, 'token_str': 'ç´', 'effect_magnitude': 3.296875},\n",
       "     {'token_id': 67152,\n",
       "      'token_str': '_skin',\n",
       "      'effect_magnitude': 3.294921875},\n",
       "     {'token_id': 55808,\n",
       "      'token_str': 'lagen',\n",
       "      'effect_magnitude': 3.26171875}],\n",
       "    'top_suppressed': [{'token_id': 70986,\n",
       "      'token_str': 'uhan',\n",
       "      'effect_magnitude': -3.58984375},\n",
       "     {'token_id': 117214,\n",
       "      'token_str': ' Mez',\n",
       "      'effect_magnitude': -3.40234375},\n",
       "     {'token_id': 28881,\n",
       "      'token_str': 'aptive',\n",
       "      'effect_magnitude': -3.275390625},\n",
       "     {'token_id': 83312,\n",
       "      'token_str': 'MainThread',\n",
       "      'effect_magnitude': -3.09375},\n",
       "     {'token_id': 78484,\n",
       "      'token_str': ' Becker',\n",
       "      'effect_magnitude': -3.07421875},\n",
       "     {'token_id': 122550,\n",
       "      'token_str': ' Vak',\n",
       "      'effect_magnitude': -3.017578125},\n",
       "     {'token_id': 90337, 'token_str': '.Compute', 'effect_magnitude': -3.0},\n",
       "     {'token_id': 71629, 'token_str': 'bate', 'effect_magnitude': -2.98828125},\n",
       "     {'token_id': 89391, 'token_str': 'lea', 'effect_magnitude': -2.96875},\n",
       "     {'token_id': 44774, 'token_str': 'mith', 'effect_magnitude': -2.953125}]},\n",
       "   'effect_magnitude': 261.5,\n",
       "   'layers_remaining': 29},\n",
       "  3: {'activation_magnitude': 1.13671875,\n",
       "   'vocab_effect': array([-0.573  ,  0.1719 , -0.662  , ..., -0.00293, -0.00293, -0.00293],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0662841796875,\n",
       "    'std': 0.77099609375,\n",
       "    'variance': 0.59423828125,\n",
       "    'kurtosis': 0.23014214540787226,\n",
       "    'skew': 0.029413034616202968,\n",
       "    'max_effect': 3.966796875,\n",
       "    'min_effect': -4.03515625,\n",
       "    'num_positive': 68028,\n",
       "    'num_negative': 60154,\n",
       "    'num_significant': 24578},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 14166,\n",
       "      'token_str': 'ernet',\n",
       "      'effect_magnitude': 3.966796875},\n",
       "     {'token_id': 84264, 'token_str': 'ï¿½', 'effect_magnitude': 3.900390625},\n",
       "     {'token_id': 92614, 'token_str': '\\').\"', 'effect_magnitude': 3.6171875},\n",
       "     {'token_id': 47987, 'token_str': 'etre', 'effect_magnitude': 3.5390625},\n",
       "     {'token_id': 90420,\n",
       "      'token_str': 'ernals',\n",
       "      'effect_magnitude': 3.517578125},\n",
       "     {'token_id': 109462, 'token_str': 'deme', 'effect_magnitude': 3.5078125},\n",
       "     {'token_id': 20554, 'token_str': 'rac', 'effect_magnitude': 3.482421875},\n",
       "     {'token_id': 28523, 'token_str': 'ogue', 'effect_magnitude': 3.4296875},\n",
       "     {'token_id': 86250, 'token_str': 'ipa', 'effect_magnitude': 3.396484375},\n",
       "     {'token_id': 83391, 'token_str': 'iaux', 'effect_magnitude': 3.36328125}],\n",
       "    'top_suppressed': [{'token_id': 70986,\n",
       "      'token_str': 'uhan',\n",
       "      'effect_magnitude': -4.03515625},\n",
       "     {'token_id': 35179,\n",
       "      'token_str': 'borough',\n",
       "      'effect_magnitude': -3.775390625},\n",
       "     {'token_id': 1981, 'token_str': 'â€¦', 'effect_magnitude': -3.52734375},\n",
       "     {'token_id': 53676, 'token_str': 'â€¦and', 'effect_magnitude': -3.42578125},\n",
       "     {'token_id': 5548, 'token_str': 'aries', 'effect_magnitude': -3.3984375},\n",
       "     {'token_id': 112644, 'token_str': 'eru', 'effect_magnitude': -3.3671875},\n",
       "     {'token_id': 21794, 'token_str': ' ///<', 'effect_magnitude': -3.328125},\n",
       "     {'token_id': 100614, 'token_str': 'Ù„Ù‡', 'effect_magnitude': -3.294921875},\n",
       "     {'token_id': 94156,\n",
       "      'token_str': ' Pearce',\n",
       "      'effect_magnitude': -3.283203125},\n",
       "     {'token_id': 10481,\n",
       "      'token_str': 'burg',\n",
       "      'effect_magnitude': -3.2734375}]},\n",
       "   'effect_magnitude': 277.0,\n",
       "   'layers_remaining': 28},\n",
       "  4: {'activation_magnitude': 1.244140625,\n",
       "   'vocab_effect': array([ 0.1094 , -0.6973 , -0.1533 , ...,  0.04395,  0.04297,  0.04297],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.039215087890625,\n",
       "    'std': 0.6689453125,\n",
       "    'variance': 0.447509765625,\n",
       "    'kurtosis': 0.21839203616548053,\n",
       "    'skew': 0.005963512798302788,\n",
       "    'max_effect': 3.35546875,\n",
       "    'min_effect': -3.41015625,\n",
       "    'num_positive': 61007,\n",
       "    'num_negative': 67153,\n",
       "    'num_significant': 17154},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 13842,\n",
       "      'token_str': ' Gre',\n",
       "      'effect_magnitude': 3.35546875},\n",
       "     {'token_id': 34795, 'token_str': 'ottage', 'effect_magnitude': 3.34375},\n",
       "     {'token_id': 69950,\n",
       "      'token_str': 'idend',\n",
       "      'effect_magnitude': 3.173828125},\n",
       "     {'token_id': 12649, 'token_str': ' Bur', 'effect_magnitude': 3.013671875},\n",
       "     {'token_id': 15619, 'token_str': 'iph', 'effect_magnitude': 2.921875},\n",
       "     {'token_id': 64777,\n",
       "      'token_str': 'CString',\n",
       "      'effect_magnitude': 2.888671875},\n",
       "     {'token_id': 1430, 'token_str': 'eter', 'effect_magnitude': 2.873046875},\n",
       "     {'token_id': 92440, 'token_str': 'IVA', 'effect_magnitude': 2.8203125},\n",
       "     {'token_id': 4673, 'token_str': ' Gu', 'effect_magnitude': 2.7578125},\n",
       "     {'token_id': 115195, 'token_str': 'è¾º', 'effect_magnitude': 2.669921875}],\n",
       "    'top_suppressed': [{'token_id': 12747,\n",
       "      'token_str': 'olec',\n",
       "      'effect_magnitude': -3.41015625},\n",
       "     {'token_id': 53676,\n",
       "      'token_str': 'â€¦and',\n",
       "      'effect_magnitude': -3.314453125},\n",
       "     {'token_id': 72313, 'token_str': ' Urb', 'effect_magnitude': -3.1875},\n",
       "     {'token_id': 71958, 'token_str': 'olem', 'effect_magnitude': -3.0546875},\n",
       "     {'token_id': 1981, 'token_str': 'â€¦', 'effect_magnitude': -3.05078125},\n",
       "     {'token_id': 111335, 'token_str': ' ï¿½', 'effect_magnitude': -3.025390625},\n",
       "     {'token_id': 31374, 'token_str': 'ï¿½', 'effect_magnitude': -2.943359375},\n",
       "     {'token_id': 113535, 'token_str': ' edin', 'effect_magnitude': -2.9375},\n",
       "     {'token_id': 51701,\n",
       "      'token_str': 'andin',\n",
       "      'effect_magnitude': -2.916015625},\n",
       "     {'token_id': 91279,\n",
       "      'token_str': '.twitch',\n",
       "      'effect_magnitude': -2.90234375}]},\n",
       "   'effect_magnitude': 240.0,\n",
       "   'layers_remaining': 27},\n",
       "  5: {'activation_magnitude': 1.318359375,\n",
       "   'vocab_effect': array([-0.1953, -0.746 , -0.3008, ...,  0.1211,  0.1211,  0.1211],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.048431396484375,\n",
       "    'std': 0.62890625,\n",
       "    'variance': 0.395751953125,\n",
       "    'kurtosis': 0.2984475428721045,\n",
       "    'skew': 0.009737355650532126,\n",
       "    'max_effect': 3.111328125,\n",
       "    'min_effect': -4.1796875,\n",
       "    'num_positive': 60214,\n",
       "    'num_negative': 67946,\n",
       "    'num_significant': 14318},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 91099,\n",
       "      'token_str': 'dorf',\n",
       "      'effect_magnitude': 3.111328125},\n",
       "     {'token_id': 4673, 'token_str': ' Gu', 'effect_magnitude': 3.046875},\n",
       "     {'token_id': 118801, 'token_str': 'ä¸˜', 'effect_magnitude': 2.8828125},\n",
       "     {'token_id': 72995, 'token_str': ' Jal', 'effect_magnitude': 2.880859375},\n",
       "     {'token_id': 52513, 'token_str': 'aju', 'effect_magnitude': 2.787109375},\n",
       "     {'token_id': 1430, 'token_str': 'eter', 'effect_magnitude': 2.75},\n",
       "     {'token_id': 61330, 'token_str': 'iphy', 'effect_magnitude': 2.7421875},\n",
       "     {'token_id': 17198, 'token_str': 'Gu', 'effect_magnitude': 2.73046875},\n",
       "     {'token_id': 4122, 'token_str': 'ACK', 'effect_magnitude': 2.73046875},\n",
       "     {'token_id': 104658, 'token_str': 'Ä±zÄ±', 'effect_magnitude': 2.72265625}],\n",
       "    'top_suppressed': [{'token_id': 76877,\n",
       "      'token_str': 'akis',\n",
       "      'effect_magnitude': -4.1796875},\n",
       "     {'token_id': 17885, 'token_str': 'ï¿½', 'effect_magnitude': -3.390625},\n",
       "     {'token_id': 31520, 'token_str': 'hole', 'effect_magnitude': -3.1484375},\n",
       "     {'token_id': 20767, 'token_str': '521', 'effect_magnitude': -3.1015625},\n",
       "     {'token_id': 4578, 'token_str': '89', 'effect_magnitude': -3.02734375},\n",
       "     {'token_id': 91279,\n",
       "      'token_str': '.twitch',\n",
       "      'effect_magnitude': -2.908203125},\n",
       "     {'token_id': 84067,\n",
       "      'token_str': ' Brewer',\n",
       "      'effect_magnitude': -2.83203125},\n",
       "     {'token_id': 97234, 'token_str': 'ryo', 'effect_magnitude': -2.8125},\n",
       "     {'token_id': 67491,\n",
       "      'token_str': ' derp',\n",
       "      'effect_magnitude': -2.802734375},\n",
       "     {'token_id': 31374, 'token_str': 'ï¿½', 'effect_magnitude': -2.80078125}]},\n",
       "   'effect_magnitude': 226.0,\n",
       "   'layers_remaining': 26},\n",
       "  6: {'activation_magnitude': 1.359375,\n",
       "   'vocab_effect': array([ 0.1094, -1.26  , -0.3066, ...,  0.2324,  0.2324,  0.2324],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0465087890625,\n",
       "    'std': 0.5869140625,\n",
       "    'variance': 0.34423828125,\n",
       "    'kurtosis': 0.27375081736331186,\n",
       "    'skew': -0.02617788534857277,\n",
       "    'max_effect': 2.84375,\n",
       "    'min_effect': -3.0078125,\n",
       "    'num_positive': 68741,\n",
       "    'num_negative': 59415,\n",
       "    'num_significant': 11465},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 32973,\n",
       "      'token_str': 'uti',\n",
       "      'effect_magnitude': 2.84375},\n",
       "     {'token_id': 25240, 'token_str': 'ippi', 'effect_magnitude': 2.78515625},\n",
       "     {'token_id': 84177, 'token_str': ' Banc', 'effect_magnitude': 2.66796875},\n",
       "     {'token_id': 57166, 'token_str': '-pencil', 'effect_magnitude': 2.65625},\n",
       "     {'token_id': 95857, 'token_str': 'lamp', 'effect_magnitude': 2.6484375},\n",
       "     {'token_id': 34795, 'token_str': 'ottage', 'effect_magnitude': 2.6015625},\n",
       "     {'token_id': 68887,\n",
       "      'token_str': 'vertise',\n",
       "      'effect_magnitude': 2.5390625},\n",
       "     {'token_id': 60622,\n",
       "      'token_str': 'utzer',\n",
       "      'effect_magnitude': 2.529296875},\n",
       "     {'token_id': 49624, 'token_str': 'utan', 'effect_magnitude': 2.478515625},\n",
       "     {'token_id': 74517,\n",
       "      'token_str': 'indice',\n",
       "      'effect_magnitude': 2.4765625}],\n",
       "    'top_suppressed': [{'token_id': 30149,\n",
       "      'token_str': 'asil',\n",
       "      'effect_magnitude': -3.0078125},\n",
       "     {'token_id': 76877, 'token_str': 'akis', 'effect_magnitude': -3.00390625},\n",
       "     {'token_id': 31520,\n",
       "      'token_str': 'hole',\n",
       "      'effect_magnitude': -2.978515625},\n",
       "     {'token_id': 125211, 'token_str': 'å²³', 'effect_magnitude': -2.84765625},\n",
       "     {'token_id': 15027,\n",
       "      'token_str': 'ooks',\n",
       "      'effect_magnitude': -2.708984375},\n",
       "     {'token_id': 93568,\n",
       "      'token_str': ' Overnight',\n",
       "      'effect_magnitude': -2.68359375},\n",
       "     {'token_id': 48660,\n",
       "      'token_str': 'iscard',\n",
       "      'effect_magnitude': -2.634765625},\n",
       "     {'token_id': 4281, 'token_str': ' cred', 'effect_magnitude': -2.58203125},\n",
       "     {'token_id': 25188, 'token_str': 'borg', 'effect_magnitude': -2.56640625},\n",
       "     {'token_id': 91254,\n",
       "      'token_str': ' Antoine',\n",
       "      'effect_magnitude': -2.564453125}]},\n",
       "   'effect_magnitude': 210.75,\n",
       "   'layers_remaining': 25},\n",
       "  7: {'activation_magnitude': 1.4541015625,\n",
       "   'vocab_effect': array([ 0.2656, -0.66  ,  0.2031, ...,  0.1494,  0.1494,  0.1494],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.0216217041015625,\n",
       "    'std': 0.5341796875,\n",
       "    'variance': 0.28515625,\n",
       "    'kurtosis': 0.20660536686057407,\n",
       "    'skew': 0.01592030159313805,\n",
       "    'max_effect': 2.78125,\n",
       "    'min_effect': -3.25,\n",
       "    'num_positive': 61891,\n",
       "    'num_negative': 66239,\n",
       "    'num_significant': 8042},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 19246,\n",
       "      'token_str': ' addCriterion',\n",
       "      'effect_magnitude': 2.78125},\n",
       "     {'token_id': 34259,\n",
       "      'token_str': 'tered',\n",
       "      'effect_magnitude': 2.408203125},\n",
       "     {'token_id': 125041, 'token_str': 'ãƒ«ã‚¯', 'effect_magnitude': 2.40234375},\n",
       "     {'token_id': 66582,\n",
       "      'token_str': 'ulumi',\n",
       "      'effect_magnitude': 2.361328125},\n",
       "     {'token_id': 35178, 'token_str': 'ulla', 'effect_magnitude': 2.2890625},\n",
       "     {'token_id': 102371, 'token_str': 'Ñ€ÑƒÐ¶', 'effect_magnitude': 2.27734375},\n",
       "     {'token_id': 10429, 'token_str': 'vertis', 'effect_magnitude': 2.2265625},\n",
       "     {'token_id': 13900,\n",
       "      'token_str': 'ounding',\n",
       "      'effect_magnitude': 2.2265625},\n",
       "     {'token_id': 27034, 'token_str': 'IPS', 'effect_magnitude': 2.224609375},\n",
       "     {'token_id': 19195, 'token_str': 'icit', 'effect_magnitude': 2.22265625}],\n",
       "    'top_suppressed': [{'token_id': 31520,\n",
       "      'token_str': 'hole',\n",
       "      'effect_magnitude': -3.25},\n",
       "     {'token_id': 11283, 'token_str': 'andon', 'effect_magnitude': -2.625},\n",
       "     {'token_id': 25402,\n",
       "      'token_str': ' overnight',\n",
       "      'effect_magnitude': -2.62109375},\n",
       "     {'token_id': 93568,\n",
       "      'token_str': ' Overnight',\n",
       "      'effect_magnitude': -2.484375},\n",
       "     {'token_id': 51960,\n",
       "      'token_str': ' CWE',\n",
       "      'effect_magnitude': -2.388671875},\n",
       "     {'token_id': 24758, 'token_str': '719', 'effect_magnitude': -2.375},\n",
       "     {'token_id': 53977, 'token_str': 'inski', 'effect_magnitude': -2.359375},\n",
       "     {'token_id': 114457, 'token_str': 'ç›¤', 'effect_magnitude': -2.31640625},\n",
       "     {'token_id': 14512,\n",
       "      'token_str': ' hole',\n",
       "      'effect_magnitude': -2.30859375},\n",
       "     {'token_id': 17172, 'token_str': 'erk', 'effect_magnitude': -2.2734375}]},\n",
       "   'effect_magnitude': 191.375,\n",
       "   'layers_remaining': 24},\n",
       "  8: {'activation_magnitude': 1.4912109375,\n",
       "   'vocab_effect': array([ 0.2617, -0.5273,  0.4746, ...,  0.1172,  0.1172,  0.1172],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0007848739624023438,\n",
       "    'std': 0.49609375,\n",
       "    'variance': 0.2462158203125,\n",
       "    'kurtosis': 0.23387841915852103,\n",
       "    'skew': 0.019077758919310708,\n",
       "    'max_effect': 2.27734375,\n",
       "    'min_effect': -2.294921875,\n",
       "    'num_positive': 64291,\n",
       "    'num_negative': 63829,\n",
       "    'num_significant': 5996},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 83745,\n",
       "      'token_str': 'lus',\n",
       "      'effect_magnitude': 2.27734375},\n",
       "     {'token_id': 61330, 'token_str': 'iphy', 'effect_magnitude': 2.271484375},\n",
       "     {'token_id': 71070, 'token_str': 'igor', 'effect_magnitude': 2.21875},\n",
       "     {'token_id': 39265, 'token_str': 'aban', 'effect_magnitude': 2.20703125},\n",
       "     {'token_id': 88520, 'token_str': ' MUT', 'effect_magnitude': 2.14453125},\n",
       "     {'token_id': 43771,\n",
       "      'token_str': ' Lens',\n",
       "      'effect_magnitude': 2.123046875},\n",
       "     {'token_id': 9438, 'token_str': 'lers', 'effect_magnitude': 2.107421875},\n",
       "     {'token_id': 117304, 'token_str': 'ÑˆÐµÐ¼', 'effect_magnitude': 2.1015625},\n",
       "     {'token_id': 52196, 'token_str': 'loid', 'effect_magnitude': 2.087890625},\n",
       "     {'token_id': 82129, 'token_str': 'woods', 'effect_magnitude': 2.0859375}],\n",
       "    'top_suppressed': [{'token_id': 23964,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': -2.294921875},\n",
       "     {'token_id': 12747,\n",
       "      'token_str': 'olec',\n",
       "      'effect_magnitude': -2.177734375},\n",
       "     {'token_id': 5164, 'token_str': 'alle', 'effect_magnitude': -2.103515625},\n",
       "     {'token_id': 87112,\n",
       "      'token_str': 'angkan',\n",
       "      'effect_magnitude': -2.1015625},\n",
       "     {'token_id': 74843, 'token_str': 'å‚', 'effect_magnitude': -2.041015625},\n",
       "     {'token_id': 100871, 'token_str': 'Å™e', 'effect_magnitude': -2.03515625},\n",
       "     {'token_id': 123693, 'token_str': 'Ì§', 'effect_magnitude': -2.01953125},\n",
       "     {'token_id': 25828, 'token_str': '918', 'effect_magnitude': -2.017578125},\n",
       "     {'token_id': 8458, 'token_str': 'ela', 'effect_magnitude': -2.01171875},\n",
       "     {'token_id': 31520,\n",
       "      'token_str': 'hole',\n",
       "      'effect_magnitude': -2.005859375}]},\n",
       "   'effect_magnitude': 177.75,\n",
       "   'layers_remaining': 23},\n",
       "  9: {'activation_magnitude': 1.5244140625,\n",
       "   'vocab_effect': array([0.03906, 0.1562 , 0.2383 , ..., 0.11914, 0.11816, 0.11816],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0229644775390625,\n",
       "    'std': 0.478515625,\n",
       "    'variance': 0.22900390625,\n",
       "    'kurtosis': 0.2447933951927843,\n",
       "    'skew': 0.0217558351695209,\n",
       "    'max_effect': 2.529296875,\n",
       "    'min_effect': -2.2421875,\n",
       "    'num_positive': 66653,\n",
       "    'num_negative': 61483,\n",
       "    'num_significant': 5106},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 22660,\n",
       "      'token_str': 'ifice',\n",
       "      'effect_magnitude': 2.529296875},\n",
       "     {'token_id': 28121,\n",
       "      'token_str': ' bash',\n",
       "      'effect_magnitude': 2.255859375},\n",
       "     {'token_id': 19342,\n",
       "      'token_str': 'lings',\n",
       "      'effect_magnitude': 2.201171875},\n",
       "     {'token_id': 80631, 'token_str': 'ï¿½', 'effect_magnitude': 2.185546875},\n",
       "     {'token_id': 67063, 'token_str': ' Tut', 'effect_magnitude': 2.181640625},\n",
       "     {'token_id': 17606, 'token_str': 'aro', 'effect_magnitude': 2.146484375},\n",
       "     {'token_id': 79960,\n",
       "      'token_str': 'indsight',\n",
       "      'effect_magnitude': 2.111328125},\n",
       "     {'token_id': 49624, 'token_str': 'utan', 'effect_magnitude': 2.09765625},\n",
       "     {'token_id': 82707,\n",
       "      'token_str': ' uninsured',\n",
       "      'effect_magnitude': 2.01953125},\n",
       "     {'token_id': 61724,\n",
       "      'token_str': '\\\\Command',\n",
       "      'effect_magnitude': 2.015625}],\n",
       "    'top_suppressed': [{'token_id': 48099,\n",
       "      'token_str': 'Ã¨ne',\n",
       "      'effect_magnitude': -2.2421875},\n",
       "     {'token_id': 20412,\n",
       "      'token_str': ' Hind',\n",
       "      'effect_magnitude': -2.224609375},\n",
       "     {'token_id': 100673, 'token_str': 'vÃ­', 'effect_magnitude': -2.208984375},\n",
       "     {'token_id': 16933,\n",
       "      'token_str': 'earning',\n",
       "      'effect_magnitude': -2.03515625},\n",
       "     {'token_id': 106158,\n",
       "      'token_str': 'à¹€à¸«à¸¥',\n",
       "      'effect_magnitude': -2.033203125},\n",
       "     {'token_id': 59952,\n",
       "      'token_str': 'eking',\n",
       "      'effect_magnitude': -2.025390625},\n",
       "     {'token_id': 123693, 'token_str': 'Ì§', 'effect_magnitude': -1.9765625},\n",
       "     {'token_id': 126305, 'token_str': ' vitam', 'effect_magnitude': -1.96875},\n",
       "     {'token_id': 21670,\n",
       "      'token_str': ' Hur',\n",
       "      'effect_magnitude': -1.966796875},\n",
       "     {'token_id': 58197,\n",
       "      'token_str': 'zin',\n",
       "      'effect_magnitude': -1.9404296875}]},\n",
       "   'effect_magnitude': 171.5,\n",
       "   'layers_remaining': 22},\n",
       "  10: {'activation_magnitude': 1.5537109375,\n",
       "   'vocab_effect': array([0.547 , 0.379 , 0.2637, ..., 0.1846, 0.1846, 0.1846], dtype=float16),\n",
       "   'statistics': {'mean': 0.030670166015625,\n",
       "    'std': 0.473876953125,\n",
       "    'variance': 0.2244873046875,\n",
       "    'kurtosis': 0.2531380833555841,\n",
       "    'skew': 0.0010036632248839063,\n",
       "    'max_effect': 2.447265625,\n",
       "    'min_effect': -2.263671875,\n",
       "    'num_positive': 67607,\n",
       "    'num_negative': 60511,\n",
       "    'num_significant': 4900},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 9663,\n",
       "      'token_str': 'utors',\n",
       "      'effect_magnitude': 2.447265625},\n",
       "     {'token_id': 100494, 'token_str': 'Æ°á»›c', 'effect_magnitude': 2.37109375},\n",
       "     {'token_id': 17323, 'token_str': 'ths', 'effect_magnitude': 2.220703125},\n",
       "     {'token_id': 68137,\n",
       "      'token_str': 'ThreadPool',\n",
       "      'effect_magnitude': 2.16015625},\n",
       "     {'token_id': 115811, 'token_str': ' ÑÐ²ÐµÑ€', 'effect_magnitude': 2.140625},\n",
       "     {'token_id': 20346, 'token_str': 'Ñ€Ñƒ', 'effect_magnitude': 2.0625},\n",
       "     {'token_id': 16541, 'token_str': 'refs', 'effect_magnitude': 2.02734375},\n",
       "     {'token_id': 109593, 'token_str': 'Î»Î»Î·', 'effect_magnitude': 2.01953125},\n",
       "     {'token_id': 81935,\n",
       "      'token_str': 'FindObject',\n",
       "      'effect_magnitude': 1.9755859375},\n",
       "     {'token_id': 88252,\n",
       "      'token_str': ' Vish',\n",
       "      'effect_magnitude': 1.97265625}],\n",
       "    'top_suppressed': [{'token_id': 225,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': -2.263671875},\n",
       "     {'token_id': 30250, 'token_str': 'ï¿½', 'effect_magnitude': -2.185546875},\n",
       "     {'token_id': 57862,\n",
       "      'token_str': 'campo',\n",
       "      'effect_magnitude': -2.173828125},\n",
       "     {'token_id': 1415, 'token_str': 'arent', 'effect_magnitude': -2.078125},\n",
       "     {'token_id': 21878, 'token_str': 'wick', 'effect_magnitude': -1.9921875},\n",
       "     {'token_id': 104257, 'token_str': 'ä¸', 'effect_magnitude': -1.9912109375},\n",
       "     {'token_id': 24272,\n",
       "      'token_str': 'PACE',\n",
       "      'effect_magnitude': -1.982421875},\n",
       "     {'token_id': 93006, 'token_str': 'amedi', 'effect_magnitude': -1.9765625},\n",
       "     {'token_id': 74843, 'token_str': 'å‚', 'effect_magnitude': -1.96875},\n",
       "     {'token_id': 100673,\n",
       "      'token_str': 'vÃ­',\n",
       "      'effect_magnitude': -1.958984375}]},\n",
       "   'effect_magnitude': 170.0,\n",
       "   'layers_remaining': 21},\n",
       "  11: {'activation_magnitude': 1.6318359375,\n",
       "   'vocab_effect': array([ 0.5625, -0.1406,  0.2793, ...,  0.2246,  0.2246,  0.2246],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0280914306640625,\n",
       "    'std': 0.4658203125,\n",
       "    'variance': 0.2169189453125,\n",
       "    'kurtosis': 0.21170562768369283,\n",
       "    'skew': 0.02437306228872515,\n",
       "    'max_effect': 2.640625,\n",
       "    'min_effect': -2.037109375,\n",
       "    'num_positive': 67104,\n",
       "    'num_negative': 61011,\n",
       "    'num_significant': 4433},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 65225,\n",
       "      'token_str': 'uÃ­',\n",
       "      'effect_magnitude': 2.640625},\n",
       "     {'token_id': 54362,\n",
       "      'token_str': '-upper',\n",
       "      'effect_magnitude': 2.37109375},\n",
       "     {'token_id': 22026, 'token_str': 'aran', 'effect_magnitude': 2.234375},\n",
       "     {'token_id': 82000,\n",
       "      'token_str': '.scalablytyped',\n",
       "      'effect_magnitude': 2.2109375},\n",
       "     {'token_id': 70975, 'token_str': 'eldorf', 'effect_magnitude': 2.2109375},\n",
       "     {'token_id': 68137,\n",
       "      'token_str': 'ThreadPool',\n",
       "      'effect_magnitude': 2.203125},\n",
       "     {'token_id': 93386, 'token_str': 'isci', 'effect_magnitude': 2.189453125},\n",
       "     {'token_id': 5565, 'token_str': 'llum', 'effect_magnitude': 2.13671875},\n",
       "     {'token_id': 9663, 'token_str': 'utors', 'effect_magnitude': 2.125},\n",
       "     {'token_id': 122393, 'token_str': 'æµ', 'effect_magnitude': 2.0625}],\n",
       "    'top_suppressed': [{'token_id': 11428,\n",
       "      'token_str': '.Empty',\n",
       "      'effect_magnitude': -2.037109375},\n",
       "     {'token_id': 97645,\n",
       "      'token_str': ' Bender',\n",
       "      'effect_magnitude': -1.9921875},\n",
       "     {'token_id': 39035, 'token_str': 'deb', 'effect_magnitude': -1.935546875},\n",
       "     {'token_id': 112490,\n",
       "      'token_str': ' Ð»ÐµÐ¶',\n",
       "      'effect_magnitude': -1.9169921875},\n",
       "     {'token_id': 23180,\n",
       "      'token_str': 'ullet',\n",
       "      'effect_magnitude': -1.916015625},\n",
       "     {'token_id': 15564,\n",
       "      'token_str': 'ennes',\n",
       "      'effect_magnitude': -1.896484375},\n",
       "     {'token_id': 111038,\n",
       "      'token_str': 'anlar',\n",
       "      'effect_magnitude': -1.89453125},\n",
       "     {'token_id': 580, 'token_str': 'ace', 'effect_magnitude': -1.888671875},\n",
       "     {'token_id': 47579,\n",
       "      'token_str': ' GetEnumerator',\n",
       "      'effect_magnitude': -1.869140625},\n",
       "     {'token_id': 30149,\n",
       "      'token_str': 'asil',\n",
       "      'effect_magnitude': -1.845703125}]},\n",
       "   'effect_magnitude': 167.125,\n",
       "   'layers_remaining': 20},\n",
       "  12: {'activation_magnitude': 1.6416015625,\n",
       "   'vocab_effect': array([ 0.3164 , -0.11914, -0.0586 , ...,  0.1572 ,  0.1572 ,  0.1572 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.00836181640625,\n",
       "    'std': 0.418701171875,\n",
       "    'variance': 0.1754150390625,\n",
       "    'kurtosis': 0.2153586809293504,\n",
       "    'skew': 0.04319994238310381,\n",
       "    'max_effect': 2.126953125,\n",
       "    'min_effect': -1.8046875,\n",
       "    'num_positive': 64897,\n",
       "    'num_negative': 63214,\n",
       "    'num_significant': 2462},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 9623,\n",
       "      'token_str': 'stances',\n",
       "      'effect_magnitude': 2.126953125},\n",
       "     {'token_id': 93386, 'token_str': 'isci', 'effect_magnitude': 2.111328125},\n",
       "     {'token_id': 90459, 'token_str': 'ilan', 'effect_magnitude': 2.044921875},\n",
       "     {'token_id': 65225, 'token_str': 'uÃ­', 'effect_magnitude': 1.9677734375},\n",
       "     {'token_id': 103290, 'token_str': 'á»“n', 'effect_magnitude': 1.9658203125},\n",
       "     {'token_id': 68137,\n",
       "      'token_str': 'ThreadPool',\n",
       "      'effect_magnitude': 1.8427734375},\n",
       "     {'token_id': 54362,\n",
       "      'token_str': '-upper',\n",
       "      'effect_magnitude': 1.83984375},\n",
       "     {'token_id': 22026, 'token_str': 'aran', 'effect_magnitude': 1.8125},\n",
       "     {'token_id': 27279,\n",
       "      'token_str': 'amation',\n",
       "      'effect_magnitude': 1.79296875},\n",
       "     {'token_id': 96546,\n",
       "      'token_str': '.lesson',\n",
       "      'effect_magnitude': 1.7568359375}],\n",
       "    'top_suppressed': [{'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -1.8046875},\n",
       "     {'token_id': 39035,\n",
       "      'token_str': 'deb',\n",
       "      'effect_magnitude': -1.7998046875},\n",
       "     {'token_id': 38060, 'token_str': 'uga', 'effect_magnitude': -1.78125},\n",
       "     {'token_id': 11283,\n",
       "      'token_str': 'andon',\n",
       "      'effect_magnitude': -1.72265625},\n",
       "     {'token_id': 97916, 'token_str': '/small', 'effect_magnitude': -1.703125},\n",
       "     {'token_id': 96295,\n",
       "      'token_str': 'maj',\n",
       "      'effect_magnitude': -1.6923828125},\n",
       "     {'token_id': 44412,\n",
       "      'token_str': 'completion',\n",
       "      'effect_magnitude': -1.689453125},\n",
       "     {'token_id': 84787,\n",
       "      'token_str': '.dep',\n",
       "      'effect_magnitude': -1.685546875},\n",
       "     {'token_id': 2458,\n",
       "      'token_str': ' tot',\n",
       "      'effect_magnitude': -1.6787109375},\n",
       "     {'token_id': 27349,\n",
       "      'token_str': 'atum',\n",
       "      'effect_magnitude': -1.6787109375}]},\n",
       "   'effect_magnitude': 150.0,\n",
       "   'layers_remaining': 19},\n",
       "  13: {'activation_magnitude': 1.771484375,\n",
       "   'vocab_effect': array([ 0.1367, -0.2217,  0.1504, ...,  0.2012,  0.2012,  0.2012],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0435791015625,\n",
       "    'std': 0.424560546875,\n",
       "    'variance': 0.1802978515625,\n",
       "    'kurtosis': 0.1994000538154661,\n",
       "    'skew': 0.015596192540745409,\n",
       "    'max_effect': 2.220703125,\n",
       "    'min_effect': -2.51953125,\n",
       "    'num_positive': 69610,\n",
       "    'num_negative': 58512,\n",
       "    'num_significant': 2761},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 54362,\n",
       "      'token_str': '-upper',\n",
       "      'effect_magnitude': 2.220703125},\n",
       "     {'token_id': 45012, 'token_str': 'ipay', 'effect_magnitude': 2.080078125},\n",
       "     {'token_id': 84782, 'token_str': 'sdale', 'effect_magnitude': 2.03125},\n",
       "     {'token_id': 119622, 'token_str': 'Ð¸Ñ‡Ð½Ñ–', 'effect_magnitude': 1.98046875},\n",
       "     {'token_id': 79921,\n",
       "      'token_str': ' Grip',\n",
       "      'effect_magnitude': 1.9755859375},\n",
       "     {'token_id': 27279,\n",
       "      'token_str': 'amation',\n",
       "      'effect_magnitude': 1.91015625},\n",
       "     {'token_id': 83388,\n",
       "      'token_str': 'ongan',\n",
       "      'effect_magnitude': 1.900390625},\n",
       "     {'token_id': 83159,\n",
       "      'token_str': ' Boyle',\n",
       "      'effect_magnitude': 1.8720703125},\n",
       "     {'token_id': 30321,\n",
       "      'token_str': 'esian',\n",
       "      'effect_magnitude': 1.845703125},\n",
       "     {'token_id': 93861,\n",
       "      'token_str': 'GameData',\n",
       "      'effect_magnitude': 1.8271484375}],\n",
       "    'top_suppressed': [{'token_id': 30086,\n",
       "      'token_str': 'owie',\n",
       "      'effect_magnitude': -2.51953125},\n",
       "     {'token_id': 49551, 'token_str': 'afia', 'effect_magnitude': -1.890625},\n",
       "     {'token_id': 59657, 'token_str': 'ï¿½', 'effect_magnitude': -1.796875},\n",
       "     {'token_id': 26976, 'token_str': ' mant', 'effect_magnitude': -1.7734375},\n",
       "     {'token_id': 38060, 'token_str': 'uga', 'effect_magnitude': -1.6796875},\n",
       "     {'token_id': 200, 'token_str': '\\x0c', 'effect_magnitude': -1.6689453125},\n",
       "     {'token_id': 96875,\n",
       "      'token_str': ' gratuita',\n",
       "      'effect_magnitude': -1.666015625},\n",
       "     {'token_id': 107608, 'token_str': 'å›º', 'effect_magnitude': -1.65234375},\n",
       "     {'token_id': 10184,\n",
       "      'token_str': ' nut',\n",
       "      'effect_magnitude': -1.623046875},\n",
       "     {'token_id': 92577,\n",
       "      'token_str': 'shima',\n",
       "      'effect_magnitude': -1.6123046875}]},\n",
       "   'effect_magnitude': 152.875,\n",
       "   'layers_remaining': 18},\n",
       "  14: {'activation_magnitude': 1.884765625,\n",
       "   'vocab_effect': array([-0.1641 ,  0.1445 , -0.10547, ...,  0.06152,  0.06152,  0.06055],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0004634857177734375,\n",
       "    'std': 0.39990234375,\n",
       "    'variance': 0.159912109375,\n",
       "    'kurtosis': 0.24844472932812778,\n",
       "    'skew': -0.03003568388628685,\n",
       "    'max_effect': 2.025390625,\n",
       "    'min_effect': -2.044921875,\n",
       "    'num_positive': 64513,\n",
       "    'num_negative': 63595,\n",
       "    'num_significant': 1879},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 23402,\n",
       "      'token_str': '574',\n",
       "      'effect_magnitude': 2.025390625},\n",
       "     {'token_id': 27279,\n",
       "      'token_str': 'amation',\n",
       "      'effect_magnitude': 2.021484375},\n",
       "     {'token_id': 23906, 'token_str': '557', 'effect_magnitude': 1.923828125},\n",
       "     {'token_id': 82000,\n",
       "      'token_str': '.scalablytyped',\n",
       "      'effect_magnitude': 1.853515625},\n",
       "     {'token_id': 24792, 'token_str': '969', 'effect_magnitude': 1.810546875},\n",
       "     {'token_id': 43966, 'token_str': 'azor', 'effect_magnitude': 1.80078125},\n",
       "     {'token_id': 21228, 'token_str': '575', 'effect_magnitude': 1.6630859375},\n",
       "     {'token_id': 82616, 'token_str': 'mounted', 'effect_magnitude': 1.625},\n",
       "     {'token_id': 75869,\n",
       "      'token_str': 'ItemCount',\n",
       "      'effect_magnitude': 1.619140625},\n",
       "     {'token_id': 127552,\n",
       "      'token_str': '\\xadn',\n",
       "      'effect_magnitude': 1.6123046875}],\n",
       "    'top_suppressed': [{'token_id': 77468,\n",
       "      'token_str': 'pert',\n",
       "      'effect_magnitude': -2.044921875},\n",
       "     {'token_id': 80998, 'token_str': 'emann', 'effect_magnitude': -1.8828125},\n",
       "     {'token_id': 15010, 'token_str': 'iten', 'effect_magnitude': -1.8046875},\n",
       "     {'token_id': 91544,\n",
       "      'token_str': ' responseType',\n",
       "      'effect_magnitude': -1.783203125},\n",
       "     {'token_id': 18713,\n",
       "      'token_str': ' pert',\n",
       "      'effect_magnitude': -1.783203125},\n",
       "     {'token_id': 91227,\n",
       "      'token_str': 'attles',\n",
       "      'effect_magnitude': -1.763671875},\n",
       "     {'token_id': 22532, 'token_str': 'illo', 'effect_magnitude': -1.73046875},\n",
       "     {'token_id': 75222,\n",
       "      'token_str': 'inka',\n",
       "      'effect_magnitude': -1.712890625},\n",
       "     {'token_id': 34202,\n",
       "      'token_str': ' Mills',\n",
       "      'effect_magnitude': -1.69921875},\n",
       "     {'token_id': 82884,\n",
       "      'token_str': ' Pert',\n",
       "      'effect_magnitude': -1.6923828125}]},\n",
       "   'effect_magnitude': 143.25,\n",
       "   'layers_remaining': 17},\n",
       "  15: {'activation_magnitude': 2.01953125,\n",
       "   'vocab_effect': array([-0.1797 ,  0.1895 , -0.09424, ...,  0.0664 ,  0.0664 ,  0.0664 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.0093841552734375,\n",
       "    'std': 0.3798828125,\n",
       "    'variance': 0.144287109375,\n",
       "    'kurtosis': 0.2043884436886061,\n",
       "    'skew': -0.035635982718472105,\n",
       "    'max_effect': 2.373046875,\n",
       "    'min_effect': -2.025390625,\n",
       "    'num_positive': 63222,\n",
       "    'num_negative': 64883,\n",
       "    'num_significant': 1310},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 23906,\n",
       "      'token_str': '557',\n",
       "      'effect_magnitude': 2.373046875},\n",
       "     {'token_id': 82000,\n",
       "      'token_str': '.scalablytyped',\n",
       "      'effect_magnitude': 1.890625},\n",
       "     {'token_id': 23402, 'token_str': '574', 'effect_magnitude': 1.7919921875},\n",
       "     {'token_id': 102895, 'token_str': 'ã‚·ãƒ§', 'effect_magnitude': 1.7294921875},\n",
       "     {'token_id': 24130, 'token_str': '052', 'effect_magnitude': 1.6953125},\n",
       "     {'token_id': 100774, 'token_str': 'Ã¶y', 'effect_magnitude': 1.6328125},\n",
       "     {'token_id': 85263,\n",
       "      'token_str': ' Welch',\n",
       "      'effect_magnitude': 1.6259765625},\n",
       "     {'token_id': 77812,\n",
       "      'token_str': 'bern',\n",
       "      'effect_magnitude': 1.5771484375},\n",
       "     {'token_id': 86360,\n",
       "      'token_str': 'raquo',\n",
       "      'effect_magnitude': 1.564453125},\n",
       "     {'token_id': 67871,\n",
       "      'token_str': 'riott',\n",
       "      'effect_magnitude': 1.5517578125}],\n",
       "    'top_suppressed': [{'token_id': 77468,\n",
       "      'token_str': 'pert',\n",
       "      'effect_magnitude': -2.025390625},\n",
       "     {'token_id': 12785, 'token_str': 'okie', 'effect_magnitude': -1.95703125},\n",
       "     {'token_id': 25748,\n",
       "      'token_str': ' DISCLAIM',\n",
       "      'effect_magnitude': -1.8203125},\n",
       "     {'token_id': 19131, 'token_str': 'umes', 'effect_magnitude': -1.703125},\n",
       "     {'token_id': 73245,\n",
       "      'token_str': 'FIELDS',\n",
       "      'effect_magnitude': -1.701171875},\n",
       "     {'token_id': 1293, 'token_str': 'erson', 'effect_magnitude': -1.6875},\n",
       "     {'token_id': 5693, 'token_str': 'ACE', 'effect_magnitude': -1.66796875},\n",
       "     {'token_id': 22769,\n",
       "      'token_str': ' glyphicon',\n",
       "      'effect_magnitude': -1.6640625},\n",
       "     {'token_id': 39027,\n",
       "      'token_str': '(strict',\n",
       "      'effect_magnitude': -1.6328125},\n",
       "     {'token_id': 91544,\n",
       "      'token_str': ' responseType',\n",
       "      'effect_magnitude': -1.6171875}]},\n",
       "   'effect_magnitude': 136.125,\n",
       "   'layers_remaining': 16},\n",
       "  16: {'activation_magnitude': 2.193359375,\n",
       "   'vocab_effect': array([ 0.09375,  0.338  ,  0.2532 , ..., -0.0586 , -0.0586 , -0.0581 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.06512451171875,\n",
       "    'std': 0.370849609375,\n",
       "    'variance': 0.1375732421875,\n",
       "    'kurtosis': 0.17972111494186827,\n",
       "    'skew': -0.03408976144334293,\n",
       "    'max_effect': 1.6005859375,\n",
       "    'min_effect': -2.01953125,\n",
       "    'num_positive': 54886,\n",
       "    'num_negative': 73221,\n",
       "    'num_significant': 1260},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 23906,\n",
       "      'token_str': '557',\n",
       "      'effect_magnitude': 1.6005859375},\n",
       "     {'token_id': 65674, 'token_str': 'andi', 'effect_magnitude': 1.583984375},\n",
       "     {'token_id': 24359,\n",
       "      'token_str': ' corners',\n",
       "      'effect_magnitude': 1.4736328125},\n",
       "     {'token_id': 81351,\n",
       "      'token_str': 'Absent',\n",
       "      'effect_magnitude': 1.42578125},\n",
       "     {'token_id': 89440,\n",
       "      'token_str': 'irate',\n",
       "      'effect_magnitude': 1.412109375},\n",
       "     {'token_id': 106925, 'token_str': ' ï¿½', 'effect_magnitude': 1.4013671875},\n",
       "     {'token_id': 12160, 'token_str': 'elly', 'effect_magnitude': 1.388671875},\n",
       "     {'token_id': 55166,\n",
       "      'token_str': ' Surre',\n",
       "      'effect_magnitude': 1.380859375},\n",
       "     {'token_id': 38843,\n",
       "      'token_str': '_EXTERN',\n",
       "      'effect_magnitude': 1.373046875},\n",
       "     {'token_id': 90037,\n",
       "      'token_str': ' Licht',\n",
       "      'effect_magnitude': 1.369140625}],\n",
       "    'top_suppressed': [{'token_id': 77468,\n",
       "      'token_str': 'pert',\n",
       "      'effect_magnitude': -2.01953125},\n",
       "     {'token_id': 55843,\n",
       "      'token_str': ' Revel',\n",
       "      'effect_magnitude': -1.7587890625},\n",
       "     {'token_id': 100800,\n",
       "      'token_str': 'Ú¯Ø§Ù‡',\n",
       "      'effect_magnitude': -1.7353515625},\n",
       "     {'token_id': 70741,\n",
       "      'token_str': 'XMLLoader',\n",
       "      'effect_magnitude': -1.732421875},\n",
       "     {'token_id': 35259,\n",
       "      'token_str': 'aggio',\n",
       "      'effect_magnitude': -1.697265625},\n",
       "     {'token_id': 78029, 'token_str': 'ensburg', 'effect_magnitude': -1.6875},\n",
       "     {'token_id': 47506,\n",
       "      'token_str': ' illum',\n",
       "      'effect_magnitude': -1.59765625},\n",
       "     {'token_id': 121040, 'token_str': 'å®™', 'effect_magnitude': -1.5947265625},\n",
       "     {'token_id': 18713,\n",
       "      'token_str': ' pert',\n",
       "      'effect_magnitude': -1.58984375},\n",
       "     {'token_id': 55653,\n",
       "      'token_str': '.APP',\n",
       "      'effect_magnitude': -1.5888671875}]},\n",
       "   'effect_magnitude': 134.875,\n",
       "   'layers_remaining': 15},\n",
       "  17: {'activation_magnitude': 2.3671875,\n",
       "   'vocab_effect': array([-0.01172,  0.552  , -0.0752 , ..., -0.06152, -0.06152, -0.06055],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.0491943359375,\n",
       "    'std': 0.346435546875,\n",
       "    'variance': 0.11993408203125,\n",
       "    'kurtosis': 0.19513936639279006,\n",
       "    'skew': -0.046449607266675144,\n",
       "    'max_effect': 1.6689453125,\n",
       "    'min_effect': -1.67578125,\n",
       "    'num_positive': 56927,\n",
       "    'num_negative': 71171,\n",
       "    'num_significant': 754},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 23906,\n",
       "      'token_str': '557',\n",
       "      'effect_magnitude': 1.6689453125},\n",
       "     {'token_id': 109089, 'token_str': 'ãƒ¼ãƒ„', 'effect_magnitude': 1.66796875},\n",
       "     {'token_id': 46970, 'token_str': 'opus', 'effect_magnitude': 1.447265625},\n",
       "     {'token_id': 54542, 'token_str': 'ëž˜', 'effect_magnitude': 1.4150390625},\n",
       "     {'token_id': 94611,\n",
       "      'token_str': ' Seymour',\n",
       "      'effect_magnitude': 1.4140625},\n",
       "     {'token_id': 103169, 'token_str': 'Ñ€Ð¾Ð·', 'effect_magnitude': 1.41015625},\n",
       "     {'token_id': 61134, 'token_str': ' Sirius', 'effect_magnitude': 1.40625},\n",
       "     {'token_id': 55166,\n",
       "      'token_str': ' Surre',\n",
       "      'effect_magnitude': 1.4013671875},\n",
       "     {'token_id': 100902,\n",
       "      'token_str': 'Ñ€Ð¾Ð´',\n",
       "      'effect_magnitude': 1.3720703125},\n",
       "     {'token_id': 51349, 'token_str': 'ADM', 'effect_magnitude': 1.361328125}],\n",
       "    'top_suppressed': [{'token_id': 117764,\n",
       "      'token_str': 'aklÄ±',\n",
       "      'effect_magnitude': -1.67578125},\n",
       "     {'token_id': 43783,\n",
       "      'token_str': 'olla',\n",
       "      'effect_magnitude': -1.642578125},\n",
       "     {'token_id': 35259,\n",
       "      'token_str': 'aggio',\n",
       "      'effect_magnitude': -1.5673828125},\n",
       "     {'token_id': 70741,\n",
       "      'token_str': 'XMLLoader',\n",
       "      'effect_magnitude': -1.5087890625},\n",
       "     {'token_id': 121040, 'token_str': 'å®™', 'effect_magnitude': -1.5068359375},\n",
       "     {'token_id': 80402, 'token_str': ' ï¿½', 'effect_magnitude': -1.4931640625},\n",
       "     {'token_id': 12785,\n",
       "      'token_str': 'okie',\n",
       "      'effect_magnitude': -1.482421875},\n",
       "     {'token_id': 28502,\n",
       "      'token_str': ' sticky',\n",
       "      'effect_magnitude': -1.47265625},\n",
       "     {'token_id': 87303,\n",
       "      'token_str': 'OffsetTable',\n",
       "      'effect_magnitude': -1.466796875},\n",
       "     {'token_id': 93024,\n",
       "      'token_str': ' keer',\n",
       "      'effect_magnitude': -1.458984375}]},\n",
       "   'effect_magnitude': 125.3125,\n",
       "   'layers_remaining': 14},\n",
       "  18: {'activation_magnitude': 2.66796875,\n",
       "   'vocab_effect': array([ 0.007812,  0.3694  , -0.01514 , ...,  0.02441 ,  0.02393 ,\n",
       "           0.02393 ], dtype=float16),\n",
       "   'statistics': {'mean': -0.0169219970703125,\n",
       "    'std': 0.342529296875,\n",
       "    'variance': 0.11737060546875,\n",
       "    'kurtosis': 0.21217632896683503,\n",
       "    'skew': -0.0403901733641993,\n",
       "    'max_effect': 1.830078125,\n",
       "    'min_effect': -1.5888671875,\n",
       "    'num_positive': 62136,\n",
       "    'num_negative': 65953,\n",
       "    'num_significant': 602},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 4372,\n",
       "      'token_str': 'elves',\n",
       "      'effect_magnitude': 1.830078125},\n",
       "     {'token_id': 31182,\n",
       "      'token_str': ' predecess',\n",
       "      'effect_magnitude': 1.62890625},\n",
       "     {'token_id': 91216, 'token_str': 'Ð»Ð¸Ñ‡', 'effect_magnitude': 1.58203125},\n",
       "     {'token_id': 23906, 'token_str': '557', 'effect_magnitude': 1.52734375},\n",
       "     {'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.4677734375},\n",
       "     {'token_id': 109089, 'token_str': 'ãƒ¼ãƒ„', 'effect_magnitude': 1.466796875},\n",
       "     {'token_id': 18994,\n",
       "      'token_str': 'opper',\n",
       "      'effect_magnitude': 1.4365234375},\n",
       "     {'token_id': 40870,\n",
       "      'token_str': ' Pont',\n",
       "      'effect_magnitude': 1.423828125},\n",
       "     {'token_id': 103169,\n",
       "      'token_str': 'Ñ€Ð¾Ð·',\n",
       "      'effect_magnitude': 1.4208984375},\n",
       "     {'token_id': 4916, 'token_str': 'ï¿½', 'effect_magnitude': 1.3984375}],\n",
       "    'top_suppressed': [{'token_id': 44785,\n",
       "      'token_str': 'orgot',\n",
       "      'effect_magnitude': -1.5888671875},\n",
       "     {'token_id': 125767, 'token_str': 'ç›‘ç£', 'effect_magnitude': -1.58203125},\n",
       "     {'token_id': 82107,\n",
       "      'token_str': '_marshall',\n",
       "      'effect_magnitude': -1.4921875},\n",
       "     {'token_id': 1894,\n",
       "      'token_str': 'ather',\n",
       "      'effect_magnitude': -1.458984375},\n",
       "     {'token_id': 94655,\n",
       "      'token_str': ' Vaults',\n",
       "      'effect_magnitude': -1.4453125},\n",
       "     {'token_id': 98683,\n",
       "      'token_str': '\\\\core',\n",
       "      'effect_magnitude': -1.42578125},\n",
       "     {'token_id': 84448,\n",
       "      'token_str': 'ynamodb',\n",
       "      'effect_magnitude': -1.42578125},\n",
       "     {'token_id': 89488, 'token_str': '.nlm', 'effect_magnitude': -1.41015625},\n",
       "     {'token_id': 70741,\n",
       "      'token_str': 'XMLLoader',\n",
       "      'effect_magnitude': -1.404296875},\n",
       "     {'token_id': 78029,\n",
       "      'token_str': 'ensburg',\n",
       "      'effect_magnitude': -1.3984375}]},\n",
       "   'effect_magnitude': 122.8125,\n",
       "   'layers_remaining': 13},\n",
       "  19: {'activation_magnitude': 2.943359375,\n",
       "   'vocab_effect': array([-0.2734,  0.341 , -0.3955, ...,  0.1685,  0.169 ,  0.169 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.053314208984375,\n",
       "    'std': 0.34326171875,\n",
       "    'variance': 0.1177978515625,\n",
       "    'kurtosis': 0.2241058820371018,\n",
       "    'skew': -0.030475900417561305,\n",
       "    'max_effect': 1.892578125,\n",
       "    'min_effect': -1.580078125,\n",
       "    'num_positive': 72702,\n",
       "    'num_negative': 55403,\n",
       "    'num_significant': 669},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 31182,\n",
       "      'token_str': ' predecess',\n",
       "      'effect_magnitude': 1.892578125},\n",
       "     {'token_id': 4372, 'token_str': 'elves', 'effect_magnitude': 1.802734375},\n",
       "     {'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.7685546875},\n",
       "     {'token_id': 65859, 'token_str': 'nist', 'effect_magnitude': 1.65234375},\n",
       "     {'token_id': 12160, 'token_str': 'elly', 'effect_magnitude': 1.6015625},\n",
       "     {'token_id': 57942, 'token_str': 'ï¿½', 'effect_magnitude': 1.5078125},\n",
       "     {'token_id': 103169, 'token_str': 'Ñ€Ð¾Ð·', 'effect_magnitude': 1.5},\n",
       "     {'token_id': 81881, 'token_str': 'iets', 'effect_magnitude': 1.4765625},\n",
       "     {'token_id': 114262, 'token_str': 'ç·’', 'effect_magnitude': 1.47265625},\n",
       "     {'token_id': 45533,\n",
       "      'token_str': 'utenberg',\n",
       "      'effect_magnitude': 1.4423828125}],\n",
       "    'top_suppressed': [{'token_id': 44785,\n",
       "      'token_str': 'orgot',\n",
       "      'effect_magnitude': -1.580078125},\n",
       "     {'token_id': 23576, 'token_str': 'rob', 'effect_magnitude': -1.490234375},\n",
       "     {'token_id': 63940, 'token_str': 'dre', 'effect_magnitude': -1.462890625},\n",
       "     {'token_id': 27236, 'token_str': 'imen', 'effect_magnitude': -1.42578125},\n",
       "     {'token_id': 1672, 'token_str': ' ins', 'effect_magnitude': -1.419921875},\n",
       "     {'token_id': 94655,\n",
       "      'token_str': ' Vaults',\n",
       "      'effect_magnitude': -1.416015625},\n",
       "     {'token_id': 13136,\n",
       "      'token_str': 'ulp',\n",
       "      'effect_magnitude': -1.4072265625},\n",
       "     {'token_id': 12222,\n",
       "      'token_str': ' till',\n",
       "      'effect_magnitude': -1.388671875},\n",
       "     {'token_id': 104068,\n",
       "      'token_str': 'Ð¾Ð¶Ð´',\n",
       "      'effect_magnitude': -1.365234375},\n",
       "     {'token_id': 79065,\n",
       "      'token_str': ' trough',\n",
       "      'effect_magnitude': -1.359375}]},\n",
       "   'effect_magnitude': 124.375,\n",
       "   'layers_remaining': 12},\n",
       "  20: {'activation_magnitude': 3.287109375,\n",
       "   'vocab_effect': array([-0.1406,  0.5176, -0.4316, ...,  0.1533,  0.1543,  0.1543],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.06585693359375,\n",
       "    'std': 0.348388671875,\n",
       "    'variance': 0.12139892578125,\n",
       "    'kurtosis': 0.24688147809432515,\n",
       "    'skew': -0.013178389411457839,\n",
       "    'max_effect': 1.9453125,\n",
       "    'min_effect': -1.818359375,\n",
       "    'num_positive': 74352,\n",
       "    'num_negative': 53745,\n",
       "    'num_significant': 853},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 4372,\n",
       "      'token_str': 'elves',\n",
       "      'effect_magnitude': 1.9453125},\n",
       "     {'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.8955078125},\n",
       "     {'token_id': 31182,\n",
       "      'token_str': ' predecess',\n",
       "      'effect_magnitude': 1.720703125},\n",
       "     {'token_id': 96385, 'token_str': 'liches', 'effect_magnitude': 1.6875},\n",
       "     {'token_id': 86156,\n",
       "      'token_str': '/bower',\n",
       "      'effect_magnitude': 1.58203125},\n",
       "     {'token_id': 88197,\n",
       "      'token_str': '.Brand',\n",
       "      'effect_magnitude': 1.5771484375},\n",
       "     {'token_id': 114262, 'token_str': 'ç·’', 'effect_magnitude': 1.572265625},\n",
       "     {'token_id': 16541,\n",
       "      'token_str': 'refs',\n",
       "      'effect_magnitude': 1.5439453125},\n",
       "     {'token_id': 52683, 'token_str': ' Gut', 'effect_magnitude': 1.53515625},\n",
       "     {'token_id': 45533,\n",
       "      'token_str': 'utenberg',\n",
       "      'effect_magnitude': 1.5341796875}],\n",
       "    'top_suppressed': [{'token_id': 5639,\n",
       "      'token_str': 'azon',\n",
       "      'effect_magnitude': -1.818359375},\n",
       "     {'token_id': 23576,\n",
       "      'token_str': 'rob',\n",
       "      'effect_magnitude': -1.6728515625},\n",
       "     {'token_id': 1525, 'token_str': 'ason', 'effect_magnitude': -1.662109375},\n",
       "     {'token_id': 65334,\n",
       "      'token_str': 'jeta',\n",
       "      'effect_magnitude': -1.564453125},\n",
       "     {'token_id': 6901, 'token_str': 'ened', 'effect_magnitude': -1.5},\n",
       "     {'token_id': 88050,\n",
       "      'token_str': ' tumble',\n",
       "      'effect_magnitude': -1.4833984375},\n",
       "     {'token_id': 94655,\n",
       "      'token_str': ' Vaults',\n",
       "      'effect_magnitude': -1.47265625},\n",
       "     {'token_id': 99644,\n",
       "      'token_str': ' IOCTL',\n",
       "      'effect_magnitude': -1.435546875},\n",
       "     {'token_id': 79065,\n",
       "      'token_str': ' trough',\n",
       "      'effect_magnitude': -1.419921875},\n",
       "     {'token_id': 39249,\n",
       "      'token_str': '.removeEventListener',\n",
       "      'effect_magnitude': -1.39453125}]},\n",
       "   'effect_magnitude': 127.0,\n",
       "   'layers_remaining': 11},\n",
       "  21: {'activation_magnitude': 3.6171875,\n",
       "   'vocab_effect': array([-0.0703,  0.3906, -0.3809, ...,  0.1631,  0.1631,  0.1631],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.06597900390625,\n",
       "    'std': 0.3525390625,\n",
       "    'variance': 0.12432861328125,\n",
       "    'kurtosis': 0.23386423333282735,\n",
       "    'skew': -0.031674139647457106,\n",
       "    'max_effect': 1.8828125,\n",
       "    'min_effect': -1.880859375,\n",
       "    'num_positive': 74260,\n",
       "    'num_negative': 53837,\n",
       "    'num_significant': 866},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 4372,\n",
       "      'token_str': 'elves',\n",
       "      'effect_magnitude': 1.8828125},\n",
       "     {'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.7900390625},\n",
       "     {'token_id': 31182,\n",
       "      'token_str': ' predecess',\n",
       "      'effect_magnitude': 1.603515625},\n",
       "     {'token_id': 65646,\n",
       "      'token_str': ' Ramsey',\n",
       "      'effect_magnitude': 1.5810546875},\n",
       "     {'token_id': 67818,\n",
       "      'token_str': 'quake',\n",
       "      'effect_magnitude': 1.5576171875},\n",
       "     {'token_id': 124719, 'token_str': ' jich', 'effect_magnitude': 1.546875},\n",
       "     {'token_id': 92688, 'token_str': '.bill', 'effect_magnitude': 1.53515625},\n",
       "     {'token_id': 61492, 'token_str': 'lys', 'effect_magnitude': 1.5126953125},\n",
       "     {'token_id': 85893,\n",
       "      'token_str': 'ettel',\n",
       "      'effect_magnitude': 1.5087890625},\n",
       "     {'token_id': 16541, 'token_str': 'refs', 'effect_magnitude': 1.5}],\n",
       "    'top_suppressed': [{'token_id': 5639,\n",
       "      'token_str': 'azon',\n",
       "      'effect_magnitude': -1.880859375},\n",
       "     {'token_id': 1525,\n",
       "      'token_str': 'ason',\n",
       "      'effect_magnitude': -1.5615234375},\n",
       "     {'token_id': 88050,\n",
       "      'token_str': ' tumble',\n",
       "      'effect_magnitude': -1.5078125},\n",
       "     {'token_id': 73369,\n",
       "      'token_str': 'olon',\n",
       "      'effect_magnitude': -1.416015625},\n",
       "     {'token_id': 55148,\n",
       "      'token_str': 'olle',\n",
       "      'effect_magnitude': -1.408203125},\n",
       "     {'token_id': 68946,\n",
       "      'token_str': ' Turnbull',\n",
       "      'effect_magnitude': -1.3828125},\n",
       "     {'token_id': 31967,\n",
       "      'token_str': 'umar',\n",
       "      'effect_magnitude': -1.3798828125},\n",
       "     {'token_id': 84083,\n",
       "      'token_str': 'vault',\n",
       "      'effect_magnitude': -1.376953125},\n",
       "     {'token_id': 6910, 'token_str': 'eds', 'effect_magnitude': -1.376953125},\n",
       "     {'token_id': 86682,\n",
       "      'token_str': 'fov',\n",
       "      'effect_magnitude': -1.361328125}]},\n",
       "   'effect_magnitude': 128.5,\n",
       "   'layers_remaining': 10},\n",
       "  22: {'activation_magnitude': 3.92578125,\n",
       "   'vocab_effect': array([-0.0625 ,  0.11035, -0.311  , ...,  0.11816,  0.1177 ,  0.1177 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.043914794921875,\n",
       "    'std': 0.358642578125,\n",
       "    'variance': 0.128662109375,\n",
       "    'kurtosis': 0.23907118089936574,\n",
       "    'skew': -0.013524889848353013,\n",
       "    'max_effect': 1.8203125,\n",
       "    'min_effect': -1.64453125,\n",
       "    'num_positive': 70864,\n",
       "    'num_negative': 57267,\n",
       "    'num_significant': 979},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.8203125},\n",
       "     {'token_id': 4372, 'token_str': 'elves', 'effect_magnitude': 1.80859375},\n",
       "     {'token_id': 84128, 'token_str': 'legg', 'effect_magnitude': 1.666015625},\n",
       "     {'token_id': 124719,\n",
       "      'token_str': ' jich',\n",
       "      'effect_magnitude': 1.638671875},\n",
       "     {'token_id': 101083, 'token_str': 'ä¸–', 'effect_magnitude': 1.6123046875},\n",
       "     {'token_id': 85958, 'token_str': 'ignet', 'effect_magnitude': 1.5703125},\n",
       "     {'token_id': 68027, 'token_str': ' Sax', 'effect_magnitude': 1.5390625},\n",
       "     {'token_id': 33298,\n",
       "      'token_str': 'amped',\n",
       "      'effect_magnitude': 1.537109375},\n",
       "     {'token_id': 88865,\n",
       "      'token_str': 'agedList',\n",
       "      'effect_magnitude': 1.5224609375},\n",
       "     {'token_id': 94611,\n",
       "      'token_str': ' Seymour',\n",
       "      'effect_magnitude': 1.5126953125}],\n",
       "    'top_suppressed': [{'token_id': 88050,\n",
       "      'token_str': ' tumble',\n",
       "      'effect_magnitude': -1.64453125},\n",
       "     {'token_id': 90373,\n",
       "      'token_str': 'kening',\n",
       "      'effect_magnitude': -1.595703125},\n",
       "     {'token_id': 5639,\n",
       "      'token_str': 'azon',\n",
       "      'effect_magnitude': -1.5751953125},\n",
       "     {'token_id': 65334, 'token_str': 'jeta', 'effect_magnitude': -1.546875},\n",
       "     {'token_id': 55148, 'token_str': 'olle', 'effect_magnitude': -1.5390625},\n",
       "     {'token_id': 84083, 'token_str': 'vault', 'effect_magnitude': -1.5078125},\n",
       "     {'token_id': 86682, 'token_str': 'fov', 'effect_magnitude': -1.501953125},\n",
       "     {'token_id': 97264, 'token_str': 'achat', 'effect_magnitude': -1.4921875},\n",
       "     {'token_id': 54721,\n",
       "      'token_str': 'vak',\n",
       "      'effect_magnitude': -1.4892578125},\n",
       "     {'token_id': 94655,\n",
       "      'token_str': ' Vaults',\n",
       "      'effect_magnitude': -1.48046875}]},\n",
       "   'effect_magnitude': 129.375,\n",
       "   'layers_remaining': 9},\n",
       "  23: {'activation_magnitude': 4.265625,\n",
       "   'vocab_effect': array([ 0.0742,  0.2079, -0.2456, ...,  0.1292,  0.1292,  0.1292],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.041107177734375,\n",
       "    'std': 0.35888671875,\n",
       "    'variance': 0.12890625,\n",
       "    'kurtosis': 0.22865013774104703,\n",
       "    'skew': 0.0002537087048951858,\n",
       "    'max_effect': 1.9609375,\n",
       "    'min_effect': -1.671875,\n",
       "    'num_positive': 70230,\n",
       "    'num_negative': 57855,\n",
       "    'num_significant': 938},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.9609375},\n",
       "     {'token_id': 124719, 'token_str': ' jich', 'effect_magnitude': 1.78125},\n",
       "     {'token_id': 84128, 'token_str': 'legg', 'effect_magnitude': 1.732421875},\n",
       "     {'token_id': 4372, 'token_str': 'elves', 'effect_magnitude': 1.7265625},\n",
       "     {'token_id': 101083, 'token_str': 'ä¸–', 'effect_magnitude': 1.68359375},\n",
       "     {'token_id': 70135, 'token_str': '_MISC', 'effect_magnitude': 1.625},\n",
       "     {'token_id': 48301,\n",
       "      'token_str': ' theirs',\n",
       "      'effect_magnitude': 1.6015625},\n",
       "     {'token_id': 100286, 'token_str': 'ÑÑŒ', 'effect_magnitude': 1.55859375},\n",
       "     {'token_id': 872, 'token_str': ' their', 'effect_magnitude': 1.55859375},\n",
       "     {'token_id': 71736,\n",
       "      'token_str': 'ItemImage',\n",
       "      'effect_magnitude': 1.541015625}],\n",
       "    'top_suppressed': [{'token_id': 86682,\n",
       "      'token_str': 'fov',\n",
       "      'effect_magnitude': -1.671875},\n",
       "     {'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.58984375},\n",
       "     {'token_id': 5639, 'token_str': 'azon', 'effect_magnitude': -1.57421875},\n",
       "     {'token_id': 88050,\n",
       "      'token_str': ' tumble',\n",
       "      'effect_magnitude': -1.54296875},\n",
       "     {'token_id': 94655,\n",
       "      'token_str': ' Vaults',\n",
       "      'effect_magnitude': -1.529296875},\n",
       "     {'token_id': 21772,\n",
       "      'token_str': ' NSMutable',\n",
       "      'effect_magnitude': -1.5146484375},\n",
       "     {'token_id': 39619, 'token_str': 'obo', 'effect_magnitude': -1.48046875},\n",
       "     {'token_id': 39249,\n",
       "      'token_str': '.removeEventListener',\n",
       "      'effect_magnitude': -1.470703125},\n",
       "     {'token_id': 82857,\n",
       "      'token_str': 'GEST',\n",
       "      'effect_magnitude': -1.439453125},\n",
       "     {'token_id': 99644,\n",
       "      'token_str': ' IOCTL',\n",
       "      'effect_magnitude': -1.431640625}]},\n",
       "   'effect_magnitude': 129.375,\n",
       "   'layers_remaining': 8},\n",
       "  24: {'activation_magnitude': 4.52734375,\n",
       "   'vocab_effect': array([-0.2227, -0.165 , -0.3428, ...,  0.24  ,  0.2405,  0.24  ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.111328125,\n",
       "    'std': 0.363037109375,\n",
       "    'variance': 0.1318359375,\n",
       "    'kurtosis': 0.22370370370370374,\n",
       "    'skew': 0.014424073779085236,\n",
       "    'max_effect': 2.158203125,\n",
       "    'min_effect': -1.4833984375,\n",
       "    'num_positive': 79844,\n",
       "    'num_negative': 48286,\n",
       "    'num_significant': 1289},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 124719,\n",
       "      'token_str': ' jich',\n",
       "      'effect_magnitude': 2.158203125},\n",
       "     {'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 2.009765625},\n",
       "     {'token_id': 101083, 'token_str': 'ä¸–', 'effect_magnitude': 1.7255859375},\n",
       "     {'token_id': 75386,\n",
       "      'token_str': 'ahkan',\n",
       "      'effect_magnitude': 1.705078125},\n",
       "     {'token_id': 79920, 'token_str': 'á»Ÿ', 'effect_magnitude': 1.705078125},\n",
       "     {'token_id': 113222, 'token_str': 'ï¿½', 'effect_magnitude': 1.6875},\n",
       "     {'token_id': 71736,\n",
       "      'token_str': 'ItemImage',\n",
       "      'effect_magnitude': 1.66796875},\n",
       "     {'token_id': 109329, 'token_str': 'Ñ€Ð¸Ð½', 'effect_magnitude': 1.666015625},\n",
       "     {'token_id': 95570, 'token_str': 'ÑƒÐ³', 'effect_magnitude': 1.65625},\n",
       "     {'token_id': 62753,\n",
       "      'token_str': 'aravel',\n",
       "      'effect_magnitude': 1.6396484375}],\n",
       "    'top_suppressed': [{'token_id': 13,\n",
       "      'token_str': '.',\n",
       "      'effect_magnitude': -1.4833984375},\n",
       "     {'token_id': 82857, 'token_str': 'GEST', 'effect_magnitude': -1.44921875},\n",
       "     {'token_id': 71220, 'token_str': 'uala', 'effect_magnitude': -1.44140625},\n",
       "     {'token_id': 86682,\n",
       "      'token_str': 'fov',\n",
       "      'effect_magnitude': -1.4345703125},\n",
       "     {'token_id': 40398,\n",
       "      'token_str': '/runtime',\n",
       "      'effect_magnitude': -1.431640625},\n",
       "     {'token_id': 110433,\n",
       "      'token_str': 'Î½Î¿Î¼',\n",
       "      'effect_magnitude': -1.4150390625},\n",
       "     {'token_id': 12127,\n",
       "      'token_str': 'pling',\n",
       "      'effect_magnitude': -1.4150390625},\n",
       "     {'token_id': 4381, 'token_str': 'ua', 'effect_magnitude': -1.361328125},\n",
       "     {'token_id': 19498,\n",
       "      'token_str': '395',\n",
       "      'effect_magnitude': -1.3544921875},\n",
       "     {'token_id': 433, 'token_str': ' it', 'effect_magnitude': -1.3515625}]},\n",
       "   'effect_magnitude': 136.0,\n",
       "   'layers_remaining': 7},\n",
       "  25: {'activation_magnitude': 4.8125,\n",
       "   'vocab_effect': array([-0.332 , -0.1641, -0.2632, ...,  0.2676,  0.2676,  0.2676],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.0877685546875,\n",
       "    'std': 0.360595703125,\n",
       "    'variance': 0.1300048828125,\n",
       "    'kurtosis': 0.2104247393594747,\n",
       "    'skew': -0.007329335129285567,\n",
       "    'max_effect': 1.81640625,\n",
       "    'min_effect': -1.640625,\n",
       "    'num_positive': 76972,\n",
       "    'num_negative': 51123,\n",
       "    'num_significant': 1104},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 43858,\n",
       "      'token_str': 'askell',\n",
       "      'effect_magnitude': 1.81640625},\n",
       "     {'token_id': 124719,\n",
       "      'token_str': ' jich',\n",
       "      'effect_magnitude': 1.783203125},\n",
       "     {'token_id': 70135,\n",
       "      'token_str': '_MISC',\n",
       "      'effect_magnitude': 1.775390625},\n",
       "     {'token_id': 28234,\n",
       "      'token_str': 'ernational',\n",
       "      'effect_magnitude': 1.7099609375},\n",
       "     {'token_id': 108755,\n",
       "      'token_str': 'Å¯st',\n",
       "      'effect_magnitude': 1.7041015625},\n",
       "     {'token_id': 17034,\n",
       "      'token_str': '.onCreate',\n",
       "      'effect_magnitude': 1.63671875},\n",
       "     {'token_id': 101083, 'token_str': 'ä¸–', 'effect_magnitude': 1.583984375},\n",
       "     {'token_id': 11205,\n",
       "      'token_str': ' Their',\n",
       "      'effect_magnitude': 1.56640625},\n",
       "     {'token_id': 95570, 'token_str': 'ÑƒÐ³', 'effect_magnitude': 1.5556640625},\n",
       "     {'token_id': 86179, 'token_str': '+\",\"+', 'effect_magnitude': 1.5546875}],\n",
       "    'top_suppressed': [{'token_id': 110433,\n",
       "      'token_str': 'Î½Î¿Î¼',\n",
       "      'effect_magnitude': -1.640625},\n",
       "     {'token_id': 71220,\n",
       "      'token_str': 'uala',\n",
       "      'effect_magnitude': -1.6220703125},\n",
       "     {'token_id': 18727,\n",
       "      'token_str': 'Canvas',\n",
       "      'effect_magnitude': -1.611328125},\n",
       "     {'token_id': 21778,\n",
       "      'token_str': 'vens',\n",
       "      'effect_magnitude': -1.552734375},\n",
       "     {'token_id': 10200,\n",
       "      'token_str': 'rep',\n",
       "      'effect_magnitude': -1.5361328125},\n",
       "     {'token_id': 82857,\n",
       "      'token_str': 'GEST',\n",
       "      'effect_magnitude': -1.4970703125},\n",
       "     {'token_id': 100701, 'token_str': 'ï¿½ï¿½', 'effect_magnitude': -1.490234375},\n",
       "     {'token_id': 4381, 'token_str': 'ua', 'effect_magnitude': -1.4609375},\n",
       "     {'token_id': 90373,\n",
       "      'token_str': 'kening',\n",
       "      'effect_magnitude': -1.435546875},\n",
       "     {'token_id': 61373, 'token_str': 'cke', 'effect_magnitude': -1.4140625}]},\n",
       "   'effect_magnitude': 132.875,\n",
       "   'layers_remaining': 6},\n",
       "  26: {'activation_magnitude': 5.15234375,\n",
       "   'vocab_effect': array([-0.1875, -0.0293, -0.3267, ...,  0.153 ,  0.153 ,  0.1531],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.048492431640625,\n",
       "    'std': 0.348876953125,\n",
       "    'variance': 0.12176513671875,\n",
       "    'kurtosis': 0.21503106136268002,\n",
       "    'skew': 0.0015893720551294417,\n",
       "    'max_effect': 1.7109375,\n",
       "    'min_effect': -1.6328125,\n",
       "    'num_positive': 71384,\n",
       "    'num_negative': 56721,\n",
       "    'num_significant': 751},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 17034,\n",
       "      'token_str': '.onCreate',\n",
       "      'effect_magnitude': 1.7109375},\n",
       "     {'token_id': 95570, 'token_str': 'ÑƒÐ³', 'effect_magnitude': 1.69140625},\n",
       "     {'token_id': 124719, 'token_str': ' jich', 'effect_magnitude': 1.6875},\n",
       "     {'token_id': 28234,\n",
       "      'token_str': 'ernational',\n",
       "      'effect_magnitude': 1.630859375},\n",
       "     {'token_id': 14795,\n",
       "      'token_str': 'atten',\n",
       "      'effect_magnitude': 1.6259765625},\n",
       "     {'token_id': 70135,\n",
       "      'token_str': '_MISC',\n",
       "      'effect_magnitude': 1.5673828125},\n",
       "     {'token_id': 108755,\n",
       "      'token_str': 'Å¯st',\n",
       "      'effect_magnitude': 1.5517578125},\n",
       "     {'token_id': 62717, 'token_str': 'ï¿½å', 'effect_magnitude': 1.482421875},\n",
       "     {'token_id': 85227,\n",
       "      'token_str': 'itemid',\n",
       "      'effect_magnitude': 1.4755859375},\n",
       "     {'token_id': 33675,\n",
       "      'token_str': ' Lic',\n",
       "      'effect_magnitude': 1.474609375}],\n",
       "    'top_suppressed': [{'token_id': 110433,\n",
       "      'token_str': 'Î½Î¿Î¼',\n",
       "      'effect_magnitude': -1.6328125},\n",
       "     {'token_id': 123332, 'token_str': 'ç¸®', 'effect_magnitude': -1.5888671875},\n",
       "     {'token_id': 18727,\n",
       "      'token_str': 'Canvas',\n",
       "      'effect_magnitude': -1.587890625},\n",
       "     {'token_id': 26100, 'token_str': 'MLE', 'effect_magnitude': -1.5703125},\n",
       "     {'token_id': 71220,\n",
       "      'token_str': 'uala',\n",
       "      'effect_magnitude': -1.5419921875},\n",
       "     {'token_id': 68946,\n",
       "      'token_str': ' Turnbull',\n",
       "      'effect_magnitude': -1.5322265625},\n",
       "     {'token_id': 108589, 'token_str': 'vÅ¯', 'effect_magnitude': -1.53125},\n",
       "     {'token_id': 10200, 'token_str': 'rep', 'effect_magnitude': -1.5234375},\n",
       "     {'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.521484375},\n",
       "     {'token_id': 112604,\n",
       "      'token_str': 'è®¢',\n",
       "      'effect_magnitude': -1.462890625}]},\n",
       "   'effect_magnitude': 126.1875,\n",
       "   'layers_remaining': 5},\n",
       "  27: {'activation_magnitude': 5.75,\n",
       "   'vocab_effect': array([-0.08594, -0.10205, -0.28   , ...,  0.0835 ,  0.0835 ,  0.0834 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.01934814453125,\n",
       "    'std': 0.361083984375,\n",
       "    'variance': 0.13037109375,\n",
       "    'kurtosis': 0.2319151622269917,\n",
       "    'skew': -0.01222659136578544,\n",
       "    'max_effect': 1.755859375,\n",
       "    'min_effect': -1.8369140625,\n",
       "    'num_positive': 67175,\n",
       "    'num_negative': 60935,\n",
       "    'num_significant': 909},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 77812,\n",
       "      'token_str': 'bern',\n",
       "      'effect_magnitude': 1.755859375},\n",
       "     {'token_id': 17034,\n",
       "      'token_str': '.onCreate',\n",
       "      'effect_magnitude': 1.7314453125},\n",
       "     {'token_id': 124719, 'token_str': ' jich', 'effect_magnitude': 1.6796875},\n",
       "     {'token_id': 81810, 'token_str': '_via', 'effect_magnitude': 1.6796875},\n",
       "     {'token_id': 85227, 'token_str': 'itemid', 'effect_magnitude': 1.6484375},\n",
       "     {'token_id': 79920, 'token_str': 'á»Ÿ', 'effect_magnitude': 1.642578125},\n",
       "     {'token_id': 35601,\n",
       "      'token_str': 'ampler',\n",
       "      'effect_magnitude': 1.6142578125},\n",
       "     {'token_id': 108755, 'token_str': 'Å¯st', 'effect_magnitude': 1.595703125},\n",
       "     {'token_id': 28234,\n",
       "      'token_str': 'ernational',\n",
       "      'effect_magnitude': 1.587890625},\n",
       "     {'token_id': 33675,\n",
       "      'token_str': ' Lic',\n",
       "      'effect_magnitude': 1.544921875}],\n",
       "    'top_suppressed': [{'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.8369140625},\n",
       "     {'token_id': 34856, 'token_str': 'agh', 'effect_magnitude': -1.828125},\n",
       "     {'token_id': 71220,\n",
       "      'token_str': 'uala',\n",
       "      'effect_magnitude': -1.7353515625},\n",
       "     {'token_id': 41077,\n",
       "      'token_str': 'alars',\n",
       "      'effect_magnitude': -1.728515625},\n",
       "     {'token_id': 68946,\n",
       "      'token_str': ' Turnbull',\n",
       "      'effect_magnitude': -1.7080078125},\n",
       "     {'token_id': 110433, 'token_str': 'Î½Î¿Î¼', 'effect_magnitude': -1.703125},\n",
       "     {'token_id': 10200, 'token_str': 'rep', 'effect_magnitude': -1.697265625},\n",
       "     {'token_id': 18727,\n",
       "      'token_str': 'Canvas',\n",
       "      'effect_magnitude': -1.6669921875},\n",
       "     {'token_id': 90595, 'token_str': 'uraa', 'effect_magnitude': -1.65625},\n",
       "     {'token_id': 112604, 'token_str': 'è®¢', 'effect_magnitude': -1.62890625}]},\n",
       "   'effect_magnitude': 129.5,\n",
       "   'layers_remaining': 4},\n",
       "  28: {'activation_magnitude': 6.234375,\n",
       "   'vocab_effect': array([-0.1172 , -0.0415 , -0.2773 , ...,  0.0418 ,  0.04184,  0.04184],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': 0.006175994873046875,\n",
       "    'std': 0.350341796875,\n",
       "    'variance': 0.122802734375,\n",
       "    'kurtosis': 0.22973491061582774,\n",
       "    'skew': -0.022227415305860487,\n",
       "    'max_effect': 1.87109375,\n",
       "    'min_effect': -1.8896484375,\n",
       "    'num_positive': 65365,\n",
       "    'num_negative': 62759,\n",
       "    'num_significant': 716},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 35601,\n",
       "      'token_str': 'ampler',\n",
       "      'effect_magnitude': 1.87109375},\n",
       "     {'token_id': 17034,\n",
       "      'token_str': '.onCreate',\n",
       "      'effect_magnitude': 1.818359375},\n",
       "     {'token_id': 79920, 'token_str': 'á»Ÿ', 'effect_magnitude': 1.666015625},\n",
       "     {'token_id': 75869,\n",
       "      'token_str': 'ItemCount',\n",
       "      'effect_magnitude': 1.58984375},\n",
       "     {'token_id': 81810, 'token_str': '_via', 'effect_magnitude': 1.5859375},\n",
       "     {'token_id': 77812,\n",
       "      'token_str': 'bern',\n",
       "      'effect_magnitude': 1.5712890625},\n",
       "     {'token_id': 124719,\n",
       "      'token_str': ' jich',\n",
       "      'effect_magnitude': 1.541015625},\n",
       "     {'token_id': 80300,\n",
       "      'token_str': 'levator',\n",
       "      'effect_magnitude': 1.5068359375},\n",
       "     {'token_id': 95570, 'token_str': 'ÑƒÐ³', 'effect_magnitude': 1.4990234375},\n",
       "     {'token_id': 4437,\n",
       "      'token_str': 'stract',\n",
       "      'effect_magnitude': 1.474609375}],\n",
       "    'top_suppressed': [{'token_id': 71220,\n",
       "      'token_str': 'uala',\n",
       "      'effect_magnitude': -1.8896484375},\n",
       "     {'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.7841796875},\n",
       "     {'token_id': 41077,\n",
       "      'token_str': 'alars',\n",
       "      'effect_magnitude': -1.751953125},\n",
       "     {'token_id': 112604, 'token_str': 'è®¢', 'effect_magnitude': -1.671875},\n",
       "     {'token_id': 123332, 'token_str': 'ç¸®', 'effect_magnitude': -1.650390625},\n",
       "     {'token_id': 90373,\n",
       "      'token_str': 'kening',\n",
       "      'effect_magnitude': -1.63671875},\n",
       "     {'token_id': 118504, 'token_str': 'ç¼©', 'effect_magnitude': -1.5947265625},\n",
       "     {'token_id': 34856, 'token_str': 'agh', 'effect_magnitude': -1.56640625},\n",
       "     {'token_id': 15111,\n",
       "      'token_str': 'atin',\n",
       "      'effect_magnitude': -1.5654296875},\n",
       "     {'token_id': 110433,\n",
       "      'token_str': 'Î½Î¿Î¼',\n",
       "      'effect_magnitude': -1.564453125}]},\n",
       "   'effect_magnitude': 125.5,\n",
       "   'layers_remaining': 3},\n",
       "  29: {'activation_magnitude': 6.8359375,\n",
       "   'vocab_effect': array([-0.04297, -0.09766, -0.331  , ..., -0.04395, -0.04395, -0.04395],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.045867919921875,\n",
       "    'std': 0.338134765625,\n",
       "    'variance': 0.1143798828125,\n",
       "    'kurtosis': 0.22139847762278642,\n",
       "    'skew': -0.04048077035701915,\n",
       "    'max_effect': 1.63671875,\n",
       "    'min_effect': -1.7177734375,\n",
       "    'num_positive': 57148,\n",
       "    'num_negative': 70956,\n",
       "    'num_significant': 643},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 35601,\n",
       "      'token_str': 'ampler',\n",
       "      'effect_magnitude': 1.63671875},\n",
       "     {'token_id': 79920, 'token_str': 'á»Ÿ', 'effect_magnitude': 1.505859375},\n",
       "     {'token_id': 14795,\n",
       "      'token_str': 'atten',\n",
       "      'effect_magnitude': 1.474609375},\n",
       "     {'token_id': 38008, 'token_str': 'elda', 'effect_magnitude': 1.431640625},\n",
       "     {'token_id': 789, 'token_str': 'eld', 'effect_magnitude': 1.423828125},\n",
       "     {'token_id': 17034,\n",
       "      'token_str': '.onCreate',\n",
       "      'effect_magnitude': 1.4033203125},\n",
       "     {'token_id': 4437, 'token_str': 'stract', 'effect_magnitude': 1.390625},\n",
       "     {'token_id': 80300,\n",
       "      'token_str': 'levator',\n",
       "      'effect_magnitude': 1.38671875},\n",
       "     {'token_id': 75869, 'token_str': 'ItemCount', 'effect_magnitude': 1.375},\n",
       "     {'token_id': 4669,\n",
       "      'token_str': ' via',\n",
       "      'effect_magnitude': 1.3740234375}],\n",
       "    'top_suppressed': [{'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.7177734375},\n",
       "     {'token_id': 96005,\n",
       "      'token_str': 'ntag',\n",
       "      'effect_magnitude': -1.7158203125},\n",
       "     {'token_id': 41077,\n",
       "      'token_str': 'alars',\n",
       "      'effect_magnitude': -1.69140625},\n",
       "     {'token_id': 121233,\n",
       "      'token_str': ' ì¶œìž¥',\n",
       "      'effect_magnitude': -1.623046875},\n",
       "     {'token_id': 51481,\n",
       "      'token_str': 'uur',\n",
       "      'effect_magnitude': -1.5732421875},\n",
       "     {'token_id': 90595, 'token_str': 'uraa', 'effect_magnitude': -1.5546875},\n",
       "     {'token_id': 98501, 'token_str': 'akit', 'effect_magnitude': -1.5390625},\n",
       "     {'token_id': 69484, 'token_str': 'ETY', 'effect_magnitude': -1.521484375},\n",
       "     {'token_id': 112604, 'token_str': 'è®¢', 'effect_magnitude': -1.5048828125},\n",
       "     {'token_id': 21511,\n",
       "      'token_str': '486',\n",
       "      'effect_magnitude': -1.4892578125}]},\n",
       "   'effect_magnitude': 122.25,\n",
       "   'layers_remaining': 2},\n",
       "  30: {'activation_magnitude': 7.6953125,\n",
       "   'vocab_effect': array([ 0.003906,  0.2373  , -0.298   , ..., -0.1094  , -0.1094  ,\n",
       "          -0.1094  ], dtype=float16),\n",
       "   'statistics': {'mean': -0.10040283203125,\n",
       "    'std': 0.349609375,\n",
       "    'variance': 0.1221923828125,\n",
       "    'kurtosis': 0.20600918930839418,\n",
       "    'skew': -0.05438510064867999,\n",
       "    'max_effect': 1.48046875,\n",
       "    'min_effect': -1.89453125,\n",
       "    'num_positive': 49461,\n",
       "    'num_negative': 78624,\n",
       "    'num_significant': 968},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 4669,\n",
       "      'token_str': ' via',\n",
       "      'effect_magnitude': 1.48046875},\n",
       "     {'token_id': 228, 'token_str': 'ï¿½', 'effect_magnitude': 1.4375},\n",
       "     {'token_id': 35601,\n",
       "      'token_str': 'ampler',\n",
       "      'effect_magnitude': 1.361328125},\n",
       "     {'token_id': 14795,\n",
       "      'token_str': 'atten',\n",
       "      'effect_magnitude': 1.345703125},\n",
       "     {'token_id': 30727, 'token_str': ' Myst', 'effect_magnitude': 1.34375},\n",
       "     {'token_id': 54311, 'token_str': ' erfol', 'effect_magnitude': 1.3359375},\n",
       "     {'token_id': 118490,\n",
       "      'token_str': ' slav',\n",
       "      'effect_magnitude': 1.3017578125},\n",
       "     {'token_id': 18803, 'token_str': ' ray', 'effect_magnitude': 1.30078125},\n",
       "     {'token_id': 45596,\n",
       "      'token_str': ' Pist',\n",
       "      'effect_magnitude': 1.2998046875},\n",
       "     {'token_id': 80300,\n",
       "      'token_str': 'levator',\n",
       "      'effect_magnitude': 1.294921875}],\n",
       "    'top_suppressed': [{'token_id': 51481,\n",
       "      'token_str': 'uur',\n",
       "      'effect_magnitude': -1.89453125},\n",
       "     {'token_id': 96274,\n",
       "      'token_str': 'uhl',\n",
       "      'effect_magnitude': -1.7919921875},\n",
       "     {'token_id': 90595, 'token_str': 'uraa', 'effect_magnitude': -1.76171875},\n",
       "     {'token_id': 96005,\n",
       "      'token_str': 'ntag',\n",
       "      'effect_magnitude': -1.7490234375},\n",
       "     {'token_id': 123155,\n",
       "      'token_str': 'Ø§ÙˆÛŒØ±',\n",
       "      'effect_magnitude': -1.7333984375},\n",
       "     {'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.7265625},\n",
       "     {'token_id': 118504, 'token_str': 'ç¼©', 'effect_magnitude': -1.712890625},\n",
       "     {'token_id': 3484, 'token_str': 'ï¿½', 'effect_magnitude': -1.69140625},\n",
       "     {'token_id': 98501,\n",
       "      'token_str': 'akit',\n",
       "      'effect_magnitude': -1.6787109375},\n",
       "     {'token_id': 103435, 'token_str': 'ï¿½', 'effect_magnitude': -1.67578125}]},\n",
       "   'effect_magnitude': 130.25,\n",
       "   'layers_remaining': 1},\n",
       "  31: {'activation_magnitude': 10.1953125,\n",
       "   'vocab_effect': array([-0.02148,  0.02686, -0.2324 , ..., -0.3574 , -0.3574 , -0.3574 ],\n",
       "         dtype=float16),\n",
       "   'statistics': {'mean': -0.06854248046875,\n",
       "    'std': 0.324462890625,\n",
       "    'variance': 0.1053466796875,\n",
       "    'kurtosis': 0.1568231223372618,\n",
       "    'skew': 0.04309206362008129,\n",
       "    'max_effect': 1.4345703125,\n",
       "    'min_effect': -1.771484375,\n",
       "    'num_positive': 52776,\n",
       "    'num_negative': 75228,\n",
       "    'num_significant': 419},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 84704,\n",
       "      'token_str': ' THEIR',\n",
       "      'effect_magnitude': 1.4345703125},\n",
       "     {'token_id': 118490,\n",
       "      'token_str': ' slav',\n",
       "      'effect_magnitude': 1.3955078125},\n",
       "     {'token_id': 63593,\n",
       "      'token_str': ' THEY',\n",
       "      'effect_magnitude': 1.3896484375},\n",
       "     {'token_id': 814, 'token_str': ' they', 'effect_magnitude': 1.38671875},\n",
       "     {'token_id': 71002,\n",
       "      'token_str': ' HARD',\n",
       "      'effect_magnitude': 1.3681640625},\n",
       "     {'token_id': 39419, 'token_str': ' CASE', 'effect_magnitude': 1.36328125},\n",
       "     {'token_id': 78725,\n",
       "      'token_str': ' EAST',\n",
       "      'effect_magnitude': 1.345703125},\n",
       "     {'token_id': 48630,\n",
       "      'token_str': ' JUST',\n",
       "      'effect_magnitude': 1.3369140625},\n",
       "     {'token_id': 228, 'token_str': 'ï¿½', 'effect_magnitude': 1.3359375},\n",
       "     {'token_id': 46289,\n",
       "      'token_str': ' CONF',\n",
       "      'effect_magnitude': 1.306640625}],\n",
       "    'top_suppressed': [{'token_id': 96274,\n",
       "      'token_str': 'uhl',\n",
       "      'effect_magnitude': -1.771484375},\n",
       "     {'token_id': 51481, 'token_str': 'uur', 'effect_magnitude': -1.580078125},\n",
       "     {'token_id': 89818,\n",
       "      'token_str': 'chnitt',\n",
       "      'effect_magnitude': -1.576171875},\n",
       "     {'token_id': 41077,\n",
       "      'token_str': 'alars',\n",
       "      'effect_magnitude': -1.560546875},\n",
       "     {'token_id': 90595,\n",
       "      'token_str': 'uraa',\n",
       "      'effect_magnitude': -1.4716796875},\n",
       "     {'token_id': 3484, 'token_str': 'ï¿½', 'effect_magnitude': -1.431640625},\n",
       "     {'token_id': 52676,\n",
       "      'token_str': 'acha',\n",
       "      'effect_magnitude': -1.419921875},\n",
       "     {'token_id': 86558,\n",
       "      'token_str': 'ooke',\n",
       "      'effect_magnitude': -1.396484375},\n",
       "     {'token_id': 110433,\n",
       "      'token_str': 'Î½Î¿Î¼',\n",
       "      'effect_magnitude': -1.388671875},\n",
       "     {'token_id': 81565,\n",
       "      'token_str': 'etag',\n",
       "      'effect_magnitude': -1.38671875}]},\n",
       "   'effect_magnitude': 118.8125,\n",
       "   'layers_remaining': 0}},\n",
       " 'propagation_analysis': {'propagation_pattern': 'amplifying',\n",
       "  'magnitude_trajectory': [0.0,\n",
       "   25.90625,\n",
       "   261.5,\n",
       "   277.0,\n",
       "   240.0,\n",
       "   226.0,\n",
       "   210.75,\n",
       "   191.375,\n",
       "   177.75,\n",
       "   171.5,\n",
       "   170.0,\n",
       "   167.125,\n",
       "   150.0,\n",
       "   152.875,\n",
       "   143.25,\n",
       "   136.125,\n",
       "   134.875,\n",
       "   125.3125,\n",
       "   122.8125,\n",
       "   124.375,\n",
       "   127.0,\n",
       "   128.5,\n",
       "   129.375,\n",
       "   129.375,\n",
       "   136.0,\n",
       "   132.875,\n",
       "   126.1875,\n",
       "   129.5,\n",
       "   125.5,\n",
       "   122.25,\n",
       "   130.25,\n",
       "   118.8125],\n",
       "  'activation_trajectory': [0.0,\n",
       "   0.063232421875,\n",
       "   0.7900390625,\n",
       "   1.13671875,\n",
       "   1.244140625,\n",
       "   1.318359375,\n",
       "   1.359375,\n",
       "   1.4541015625,\n",
       "   1.4912109375,\n",
       "   1.5244140625,\n",
       "   1.5537109375,\n",
       "   1.6318359375,\n",
       "   1.6416015625,\n",
       "   1.771484375,\n",
       "   1.884765625,\n",
       "   2.01953125,\n",
       "   2.193359375,\n",
       "   2.3671875,\n",
       "   2.66796875,\n",
       "   2.943359375,\n",
       "   3.287109375,\n",
       "   3.6171875,\n",
       "   3.92578125,\n",
       "   4.265625,\n",
       "   4.52734375,\n",
       "   4.8125,\n",
       "   5.15234375,\n",
       "   5.75,\n",
       "   6.234375,\n",
       "   6.8359375,\n",
       "   7.6953125,\n",
       "   10.1953125],\n",
       "  'critical_layers': [1, 2],\n",
       "  'amplification_ratio': 0.0,\n",
       "  'peak_layer': 3},\n",
       " 'convergence_analysis': {'convergence_scores': {0: nan,\n",
       "   1: 0.1317138671875,\n",
       "   2: -0.01311492919921875,\n",
       "   3: -0.027008056640625,\n",
       "   4: 0.0171966552734375,\n",
       "   5: 0.00010323524475097656,\n",
       "   6: -0.03607177734375,\n",
       "   7: 0.015838623046875,\n",
       "   8: 0.0046539306640625,\n",
       "   9: 0.011932373046875,\n",
       "   10: -0.01102447509765625,\n",
       "   11: -0.0121917724609375,\n",
       "   12: 0.01424407958984375,\n",
       "   13: -0.0079345703125,\n",
       "   14: 0.07464599609375,\n",
       "   15: 0.1314697265625,\n",
       "   16: 0.1995849609375,\n",
       "   17: 0.23095703125,\n",
       "   18: 0.241943359375,\n",
       "   19: 0.193359375,\n",
       "   20: 0.200439453125,\n",
       "   21: 0.23095703125,\n",
       "   22: 0.29443359375,\n",
       "   23: 0.328857421875,\n",
       "   24: 0.29150390625,\n",
       "   25: 0.35009765625,\n",
       "   26: 0.4375,\n",
       "   27: 0.51904296875,\n",
       "   28: 0.57958984375,\n",
       "   29: 0.69921875,\n",
       "   30: 0.79296875,\n",
       "   31: 1.0},\n",
       "  'convergence_layer': 31,\n",
       "  'stable_tokens': [' CONF',\n",
       "   ' JUST',\n",
       "   ' EAST',\n",
       "   ' slav',\n",
       "   ' THEY',\n",
       "   ' THEIR',\n",
       "   ' HARD',\n",
       "   'ï¿½',\n",
       "   ' they',\n",
       "   ' CASE'],\n",
       "  'final_similarity': 1.0},\n",
       " 'summary': {'analysis_type': 'full_projection',\n",
       "  'total_layers_analyzed': 32,\n",
       "  'peak_effect_layer': 3,\n",
       "  'final_effect_magnitude': 118.8125,\n",
       "  'magnitude_range': [0.0, 277.0],\n",
       "  'effect_evolution': 'increasing'}}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cascade_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:47:36,991 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:47:37,087 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cascade method comparison for Layer 1 mlp.down_proj.weight[788, 2427]...\n",
      "Running cascade analysis using full_projection method...\n",
      "Capturing baseline activations...\n",
      "Capturing modified activations...\n",
      "Projecting activations through 32 layers...\n",
      "  Processing layer 31/31\n",
      "Running cascade analysis using residual_stream method...\n",
      "Capturing residual stream...\n",
      "Capturing residual stream using universal layer capture...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:47:39,091 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 13:47:39,186 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing residual stream using universal layer capture...\n",
      "Analyzing residual differences across 32 layers...\n",
      "  Processing layer 31/31\n",
      "\n",
      "============================================================\n",
      "CASCADE METHODS COMPARISON: Layer 1 mlp.down_proj.weight[788, 2427]\n",
      "============================================================\n",
      "\n",
      "ðŸ“Š COMPARISON METRICS:\n",
      "  Final effects correlation: 0.612\n",
      "  Final effects cosine similarity: 0.742\n",
      "  Magnitude trajectory correlation: -0.228\n",
      "  Full projection final magnitude: 182.8750\n",
      "  Residual stream final magnitude: 579.1070\n",
      "\n",
      "ðŸŽ¯ SUMMARY:\n",
      "  Methods agree: False\n",
      "  Preferred method: residual_stream\n",
      "  Consistency score: 0.192\n",
      "\n",
      "ðŸ’¡ INTERPRETATION:\n",
      "  âš ï¸  Methods show different results\n",
      "  â†’ Super weight effects may be context-dependent or method-sensitive\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Compare both methods\n",
    "comparison = session.analyzer.vocabulary_analyzer.compare_cascade_methods(sw[0])\n",
    "session.analyzer.vocabulary_analyzer.display_cascade_comparison(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:49:58,901 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:49:58,998 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running cascade analysis using residual_stream method...\n",
      "Capturing residual stream...\n",
      "Capturing residual stream using universal layer capture...\n",
      "Capturing residual stream using universal layer capture...\n",
      "Analyzing residual differences across 32 layers...\n",
      "  Processing layer 31/31\n"
     ]
    }
   ],
   "source": [
    "residual_stream = session.analyzer.vocabulary_analyzer.analyze_vocabulary_cascade(sw[0], input_text, \"residual_stream\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'analysis_type': 'residual_stream',\n",
       " 'super_weight': SuperWeight(layer=1, coords=[788, 2427], input=-443.50, output=300.50),\n",
       " 'input_text': 'The company is great. The company is',\n",
       " 'residual_effects': {0: {'residual_magnitude': 0.0,\n",
       "   'direct_vocab_effect': array([0., 0., 0., ..., 0., 0., 0.], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0., 0., 0., ..., 0., 0., 0.], dtype=float32),\n",
       "   'statistics': {'mean': 0.0,\n",
       "    'std': 0.0,\n",
       "    'variance': 0.0,\n",
       "    'kurtosis': nan,\n",
       "    'skew': nan,\n",
       "    'max_effect': 0.0,\n",
       "    'min_effect': 0.0,\n",
       "    'num_positive': 0,\n",
       "    'num_negative': 0,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 85499,\n",
       "      'token_str': 'eos',\n",
       "      'effect_magnitude': 0.0},\n",
       "     {'token_id': 85514, 'token_str': 'yw', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85513, 'token_str': '(contract', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85512, 'token_str': ' {}.', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85511, 'token_str': '_TXT', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85510, 'token_str': 'ANCES', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85509, 'token_str': 'erin', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85508, 'token_str': 'eea', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85507, 'token_str': 'BufferData', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85506, 'token_str': ' Strap', 'effect_magnitude': 0.0}],\n",
       "    'top_suppressed': [{'token_id': 85499,\n",
       "      'token_str': 'eos',\n",
       "      'effect_magnitude': 0.0},\n",
       "     {'token_id': 85514, 'token_str': 'yw', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85513, 'token_str': '(contract', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85512, 'token_str': ' {}.', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85511, 'token_str': '_TXT', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85510, 'token_str': 'ANCES', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85509, 'token_str': 'erin', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85508, 'token_str': 'eea', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85507, 'token_str': 'BufferData', 'effect_magnitude': 0.0},\n",
       "     {'token_id': 85506, 'token_str': ' Strap', 'effect_magnitude': 0.0}]},\n",
       "   'effect_magnitude': 0.0,\n",
       "   'cumulative_magnitude': 0.0,\n",
       "   'amplification_factor': 0.0},\n",
       "  1: {'residual_magnitude': 0.08428955078125,\n",
       "   'direct_vocab_effect': array([ 0.003355,  0.003807,  0.001873, ..., -0.001085, -0.001085,\n",
       "          -0.001085], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.00335503,  0.00380707,  0.00187302, ..., -0.00108528,\n",
       "          -0.00108528, -0.00108528], dtype=float32),\n",
       "   'statistics': {'mean': -0.0006494522094726562,\n",
       "    'std': 0.0015439987182617188,\n",
       "    'variance': 2.384185791015625e-06,\n",
       "    'kurtosis': -3.0,\n",
       "    'skew': -0.0,\n",
       "    'max_effect': 0.00934600830078125,\n",
       "    'min_effect': -0.00959014892578125,\n",
       "    'num_positive': 43731,\n",
       "    'num_negative': 84525,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 1129,\n",
       "      'token_str': '://',\n",
       "      'effect_magnitude': 0.00934600830078125},\n",
       "     {'token_id': 128001,\n",
       "      'token_str': '<|end_of_text|>',\n",
       "      'effect_magnitude': 0.00847625732421875},\n",
       "     {'token_id': 12167,\n",
       "      'token_str': ' Angeles',\n",
       "      'effect_magnitude': 0.007244110107421875},\n",
       "     {'token_id': 12592,\n",
       "      'token_str': '_REF',\n",
       "      'effect_magnitude': 0.007160186767578125},\n",
       "     {'token_id': 35376,\n",
       "      'token_str': 'ilde',\n",
       "      'effect_magnitude': 0.00617218017578125},\n",
       "     {'token_id': 578,\n",
       "      'token_str': ' The',\n",
       "      'effect_magnitude': 0.00617218017578125},\n",
       "     {'token_id': 285,\n",
       "      'token_str': 'is',\n",
       "      'effect_magnitude': 0.00617218017578125},\n",
       "     {'token_id': 4227,\n",
       "      'token_str': ' ago',\n",
       "      'effect_magnitude': 0.005886077880859375},\n",
       "     {'token_id': 97485,\n",
       "      'token_str': ' Particularly',\n",
       "      'effect_magnitude': 0.0058441162109375},\n",
       "     {'token_id': 1230,\n",
       "      'token_str': 'php',\n",
       "      'effect_magnitude': 0.005802154541015625}],\n",
       "    'top_suppressed': [{'token_id': 82592,\n",
       "      'token_str': '#echo',\n",
       "      'effect_magnitude': -0.00959014892578125},\n",
       "     {'token_id': 11577,\n",
       "      'token_str': '.FontStyle',\n",
       "      'effect_magnitude': -0.00917816162109375},\n",
       "     {'token_id': 70632,\n",
       "      'token_str': ' insure',\n",
       "      'effect_magnitude': -0.0091400146484375},\n",
       "     {'token_id': 100124,\n",
       "      'token_str': '$__',\n",
       "      'effect_magnitude': -0.00909423828125},\n",
       "     {'token_id': 89959,\n",
       "      'token_str': ' formulate',\n",
       "      'effect_magnitude': -0.00847625732421875},\n",
       "     {'token_id': 112978,\n",
       "      'token_str': 'Ð¿Ñ€Ð¸Ð¼ÐµÑ€',\n",
       "      'effect_magnitude': -0.00835418701171875},\n",
       "     {'token_id': 58393,\n",
       "      'token_str': 'JNI',\n",
       "      'effect_magnitude': -0.00823211669921875},\n",
       "     {'token_id': 87404,\n",
       "      'token_str': 'Ãºsqueda',\n",
       "      'effect_magnitude': -0.00823211669921875},\n",
       "     {'token_id': 74704,\n",
       "      'token_str': ' dedicate',\n",
       "      'effect_magnitude': -0.0081939697265625},\n",
       "     {'token_id': 69711,\n",
       "      'token_str': ' automate',\n",
       "      'effect_magnitude': -0.0081939697265625}]},\n",
       "   'effect_magnitude': 0.599609375,\n",
       "   'cumulative_magnitude': 0.5997748970985413,\n",
       "   'amplification_factor': 7.11328125},\n",
       "  2: {'residual_magnitude': 0.60595703125,\n",
       "   'direct_vocab_effect': array([ 0.003496,  0.005535, -0.001692, ...,  0.005714,  0.005714,\n",
       "           0.00572 ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.0068512 , 0.00934219, 0.0001812 , ..., 0.00462914, 0.00462914,\n",
       "          0.00463295], dtype=float32),\n",
       "   'statistics': {'mean': 0.0018062591552734375,\n",
       "    'std': 0.0085906982421875,\n",
       "    'variance': 7.37309455871582e-05,\n",
       "    'kurtosis': -3.0,\n",
       "    'skew': -0.0,\n",
       "    'max_effect': 0.04083251953125,\n",
       "    'min_effect': -0.048431396484375,\n",
       "    'num_positive': 75328,\n",
       "    'num_negative': 52928,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 107755,\n",
       "      'token_str': 'Ä›r',\n",
       "      'effect_magnitude': 0.04083251953125},\n",
       "     {'token_id': 28516,\n",
       "      'token_str': 'NotEmpty',\n",
       "      'effect_magnitude': 0.0406494140625},\n",
       "     {'token_id': 93407,\n",
       "      'token_str': 'artner',\n",
       "      'effect_magnitude': 0.039886474609375},\n",
       "     {'token_id': 103815,\n",
       "      'token_str': 'ÑÐ¸Ð¼',\n",
       "      'effect_magnitude': 0.039825439453125},\n",
       "     {'token_id': 75182,\n",
       "      'token_str': ' BaseEntity',\n",
       "      'effect_magnitude': 0.03851318359375},\n",
       "     {'token_id': 96390,\n",
       "      'token_str': 'ERICA',\n",
       "      'effect_magnitude': 0.03826904296875},\n",
       "     {'token_id': 71017,\n",
       "      'token_str': 'omorphic',\n",
       "      'effect_magnitude': 0.038177490234375},\n",
       "     {'token_id': 59940,\n",
       "      'token_str': 'uitka',\n",
       "      'effect_magnitude': 0.03729248046875},\n",
       "     {'token_id': 116477,\n",
       "      'token_str': 'etler',\n",
       "      'effect_magnitude': 0.036834716796875},\n",
       "     {'token_id': 28470,\n",
       "      'token_str': 'isper',\n",
       "      'effect_magnitude': 0.03662109375}],\n",
       "    'top_suppressed': [{'token_id': 6048,\n",
       "      'token_str': 'ober',\n",
       "      'effect_magnitude': -0.048431396484375},\n",
       "     {'token_id': 72464,\n",
       "      'token_str': ' McLaren',\n",
       "      'effect_magnitude': -0.0394287109375},\n",
       "     {'token_id': 95945,\n",
       "      'token_str': 'plr',\n",
       "      'effect_magnitude': -0.038818359375},\n",
       "     {'token_id': 8997,\n",
       "      'token_str': 'arian',\n",
       "      'effect_magnitude': -0.0386962890625},\n",
       "     {'token_id': 20165,\n",
       "      'token_str': '434',\n",
       "      'effect_magnitude': -0.036712646484375},\n",
       "     {'token_id': 79334,\n",
       "      'token_str': ' Thornton',\n",
       "      'effect_magnitude': -0.035858154296875},\n",
       "     {'token_id': 8067,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': -0.035797119140625},\n",
       "     {'token_id': 49720,\n",
       "      'token_str': ' Gust',\n",
       "      'effect_magnitude': -0.034820556640625},\n",
       "     {'token_id': 77247,\n",
       "      'token_str': 'hausen',\n",
       "      'effect_magnitude': -0.0347900390625},\n",
       "     {'token_id': 78889,\n",
       "      'token_str': 'ricks',\n",
       "      'effect_magnitude': -0.0347900390625}]},\n",
       "   'effect_magnitude': 3.142578125,\n",
       "   'cumulative_magnitude': 3.228803873062134,\n",
       "   'amplification_factor': 5.1875},\n",
       "  3: {'residual_magnitude': 1.1494140625,\n",
       "   'direct_vocab_effect': array([ 0.01862 , -0.000787,  0.008575, ...,  0.00226 ,  0.002258,\n",
       "           0.002258], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.02546692, 0.00855541, 0.00875664, ..., 0.00688934, 0.00688744,\n",
       "          0.00689125], dtype=float32),\n",
       "   'statistics': {'mean': -0.0027103424072265625,\n",
       "    'std': 0.0158538818359375,\n",
       "    'variance': 0.0002512931823730469,\n",
       "    'kurtosis': -0.16834756183185773,\n",
       "    'skew': -0.01496266817174825,\n",
       "    'max_effect': 0.07501220703125,\n",
       "    'min_effect': -0.082763671875,\n",
       "    'num_positive': 55425,\n",
       "    'num_negative': 72830,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 78685,\n",
       "      'token_str': '#ab',\n",
       "      'effect_magnitude': 0.07501220703125},\n",
       "     {'token_id': 17224,\n",
       "      'token_str': '<tag',\n",
       "      'effect_magnitude': 0.0682373046875},\n",
       "     {'token_id': 78794,\n",
       "      'token_str': '#ac',\n",
       "      'effect_magnitude': 0.0672607421875},\n",
       "     {'token_id': 37164, 'token_str': 'onaut', 'effect_magnitude': 0.06640625},\n",
       "     {'token_id': 123766,\n",
       "      'token_str': 'Ð’Ð¡',\n",
       "      'effect_magnitude': 0.0655517578125},\n",
       "     {'token_id': 77436,\n",
       "      'token_str': '#af',\n",
       "      'effect_magnitude': 0.0655517578125},\n",
       "     {'token_id': 38391,\n",
       "      'token_str': ' hottest',\n",
       "      'effect_magnitude': 0.06549072265625},\n",
       "     {'token_id': 117750,\n",
       "      'token_str': 'ozÃ­',\n",
       "      'effect_magnitude': 0.06494140625},\n",
       "     {'token_id': 49718,\n",
       "      'token_str': '_Checked',\n",
       "      'effect_magnitude': 0.06268310546875},\n",
       "     {'token_id': 108017,\n",
       "      'token_str': 'vatel',\n",
       "      'effect_magnitude': 0.060943603515625}],\n",
       "    'top_suppressed': [{'token_id': 53676,\n",
       "      'token_str': 'â€¦and',\n",
       "      'effect_magnitude': -0.082763671875},\n",
       "     {'token_id': 62017,\n",
       "      'token_str': 'eson',\n",
       "      'effect_magnitude': -0.081298828125},\n",
       "     {'token_id': 26775,\n",
       "      'token_str': ' Ry',\n",
       "      'effect_magnitude': -0.08001708984375},\n",
       "     {'token_id': 70678,\n",
       "      'token_str': 'qv',\n",
       "      'effect_magnitude': -0.07598876953125},\n",
       "     {'token_id': 83823,\n",
       "      'token_str': '.assignment',\n",
       "      'effect_magnitude': -0.07379150390625},\n",
       "     {'token_id': 74460,\n",
       "      'token_str': ' Bau',\n",
       "      'effect_magnitude': -0.07373046875},\n",
       "     {'token_id': 73648,\n",
       "      'token_str': '.appspot',\n",
       "      'effect_magnitude': -0.07330322265625},\n",
       "     {'token_id': 94934,\n",
       "      'token_str': 'esco',\n",
       "      'effect_magnitude': -0.0711669921875},\n",
       "     {'token_id': 50931,\n",
       "      'token_str': 'orio',\n",
       "      'effect_magnitude': -0.07110595703125},\n",
       "     {'token_id': 38834,\n",
       "      'token_str': 'obl',\n",
       "      'effect_magnitude': -0.07073974609375}]},\n",
       "   'effect_magnitude': 5.76171875,\n",
       "   'cumulative_magnitude': 7.812350273132324,\n",
       "   'amplification_factor': 5.01171875},\n",
       "  4: {'residual_magnitude': 1.337890625,\n",
       "   'direct_vocab_effect': array([ 0.003727, -0.01082 , -0.002308, ..., -0.002289, -0.002287,\n",
       "          -0.002289], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.02919388, -0.00226307,  0.00644875, ...,  0.00460052,\n",
       "           0.00460052,  0.00460243], dtype=float32),\n",
       "   'statistics': {'mean': -0.0037708282470703125,\n",
       "    'std': 0.018402099609375,\n",
       "    'variance': 0.00033855438232421875,\n",
       "    'kurtosis': 0.12014282880380867,\n",
       "    'skew': -0.009568358624167217,\n",
       "    'max_effect': 0.0782470703125,\n",
       "    'min_effect': -0.117919921875,\n",
       "    'num_positive': 53354,\n",
       "    'num_negative': 74902,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 25005,\n",
       "      'token_str': 'ãƒ¼ï¿½',\n",
       "      'effect_magnitude': 0.0782470703125},\n",
       "     {'token_id': 91506,\n",
       "      'token_str': 'Enlarge',\n",
       "      'effect_magnitude': 0.0771484375},\n",
       "     {'token_id': 15988,\n",
       "      'token_str': 'rames',\n",
       "      'effect_magnitude': 0.07708740234375},\n",
       "     {'token_id': 123766,\n",
       "      'token_str': 'Ð’Ð¡',\n",
       "      'effect_magnitude': 0.07562255859375},\n",
       "     {'token_id': 78685,\n",
       "      'token_str': '#ab',\n",
       "      'effect_magnitude': 0.0733642578125},\n",
       "     {'token_id': 66439,\n",
       "      'token_str': ':Register',\n",
       "      'effect_magnitude': 0.0728759765625},\n",
       "     {'token_id': 36934,\n",
       "      'token_str': 'afa',\n",
       "      'effect_magnitude': 0.0721435546875},\n",
       "     {'token_id': 14917,\n",
       "      'token_str': 'erior',\n",
       "      'effect_magnitude': 0.07110595703125},\n",
       "     {'token_id': 105804,\n",
       "      'token_str': 'formace',\n",
       "      'effect_magnitude': 0.07073974609375},\n",
       "     {'token_id': 31106,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': 0.07000732421875}],\n",
       "    'top_suppressed': [{'token_id': 125563,\n",
       "      'token_str': 'istrovstvÃ­',\n",
       "      'effect_magnitude': -0.117919921875},\n",
       "     {'token_id': 42220,\n",
       "      'token_str': 'ullan',\n",
       "      'effect_magnitude': -0.1004638671875},\n",
       "     {'token_id': 90578,\n",
       "      'token_str': 'â€¦\\n',\n",
       "      'effect_magnitude': -0.0965576171875},\n",
       "     {'token_id': 25634,\n",
       "      'token_str': 'eo',\n",
       "      'effect_magnitude': -0.0924072265625},\n",
       "     {'token_id': 94934,\n",
       "      'token_str': 'esco',\n",
       "      'effect_magnitude': -0.09222412109375},\n",
       "     {'token_id': 53676,\n",
       "      'token_str': 'â€¦and',\n",
       "      'effect_magnitude': -0.0888671875},\n",
       "     {'token_id': 13164,\n",
       "      'token_str': 'Gap',\n",
       "      'effect_magnitude': -0.086181640625},\n",
       "     {'token_id': 79830,\n",
       "      'token_str': 'undra',\n",
       "      'effect_magnitude': -0.0845947265625},\n",
       "     {'token_id': 60282,\n",
       "      'token_str': '/oct',\n",
       "      'effect_magnitude': -0.08355712890625},\n",
       "     {'token_id': 68290,\n",
       "      'token_str': ' Levy',\n",
       "      'effect_magnitude': -0.082275390625}]},\n",
       "   'effect_magnitude': 6.7265625,\n",
       "   'cumulative_magnitude': 13.024007797241211,\n",
       "   'amplification_factor': 5.02734375},\n",
       "  5: {'residual_magnitude': 1.41796875,\n",
       "   'direct_vocab_effect': array([-0.02356 , -0.02223 , -0.001454, ...,  0.006767,  0.006763,\n",
       "           0.006763], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.00563431, -0.02449512,  0.00499439, ...,  0.0113678 ,\n",
       "           0.01136398,  0.01136589], dtype=float32),\n",
       "   'statistics': {'mean': 0.0030460357666015625,\n",
       "    'std': 0.02001953125,\n",
       "    'variance': 0.00040078163146972656,\n",
       "    'kurtosis': 0.3396964569898162,\n",
       "    'skew': 0.014857590574715978,\n",
       "    'max_effect': 0.09197998046875,\n",
       "    'min_effect': -0.09320068359375,\n",
       "    'num_positive': 72146,\n",
       "    'num_negative': 56110,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 55282,\n",
       "      'token_str': 'uat',\n",
       "      'effect_magnitude': 0.09197998046875},\n",
       "     {'token_id': 97465,\n",
       "      'token_str': 'Ã¡lez',\n",
       "      'effect_magnitude': 0.09124755859375},\n",
       "     {'token_id': 97114,\n",
       "      'token_str': '_mgmt',\n",
       "      'effect_magnitude': 0.08612060546875},\n",
       "     {'token_id': 78390,\n",
       "      'token_str': '.createServer',\n",
       "      'effect_magnitude': 0.0855712890625},\n",
       "     {'token_id': 120929,\n",
       "      'token_str': 'æž',\n",
       "      'effect_magnitude': 0.084228515625},\n",
       "     {'token_id': 62950,\n",
       "      'token_str': '_TA',\n",
       "      'effect_magnitude': 0.0841064453125},\n",
       "     {'token_id': 123731, 'token_str': 'ã‚‚ã‚Š', 'effect_magnitude': 0.083984375},\n",
       "     {'token_id': 106159,\n",
       "      'token_str': 'Ð¸Ð½Ðµ',\n",
       "      'effect_magnitude': 0.0838623046875},\n",
       "     {'token_id': 90420,\n",
       "      'token_str': 'ernals',\n",
       "      'effect_magnitude': 0.0836181640625},\n",
       "     {'token_id': 94397,\n",
       "      'token_str': '.DataTable',\n",
       "      'effect_magnitude': 0.08331298828125}],\n",
       "    'top_suppressed': [{'token_id': 79830,\n",
       "      'token_str': 'undra',\n",
       "      'effect_magnitude': -0.09320068359375},\n",
       "     {'token_id': 38733,\n",
       "      'token_str': 'licht',\n",
       "      'effect_magnitude': -0.0906982421875},\n",
       "     {'token_id': 41312,\n",
       "      'token_str': 'usan',\n",
       "      'effect_magnitude': -0.0882568359375},\n",
       "     {'token_id': 4414, 'token_str': 'oder', 'effect_magnitude': -0.087890625},\n",
       "     {'token_id': 23019,\n",
       "      'token_str': 'beat',\n",
       "      'effect_magnitude': -0.085693359375},\n",
       "     {'token_id': 90578,\n",
       "      'token_str': 'â€¦\\n',\n",
       "      'effect_magnitude': -0.08477783203125},\n",
       "     {'token_id': 14029,\n",
       "      'token_str': 'vy',\n",
       "      'effect_magnitude': -0.08404541015625},\n",
       "     {'token_id': 79936, 'token_str': 'lav', 'effect_magnitude': -0.08203125},\n",
       "     {'token_id': 53676,\n",
       "      'token_str': 'â€¦and',\n",
       "      'effect_magnitude': -0.08148193359375},\n",
       "     {'token_id': 84341,\n",
       "      'token_str': '.â€¦',\n",
       "      'effect_magnitude': -0.0810546875}]},\n",
       "   'effect_magnitude': 7.25,\n",
       "   'cumulative_magnitude': 18.205337524414062,\n",
       "   'amplification_factor': 5.11328125},\n",
       "  6: {'residual_magnitude': 1.3916015625,\n",
       "   'direct_vocab_effect': array([ 0.004395, -0.01333 ,  0.02289 , ...,  0.0091  ,  0.0091  ,\n",
       "           0.0091  ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.01002884, -0.03782368,  0.02788258, ...,  0.02046967,\n",
       "           0.02046585,  0.02046776], dtype=float32),\n",
       "   'statistics': {'mean': 0.0018396377563476562,\n",
       "    'std': 0.0193023681640625,\n",
       "    'variance': 0.0003724098205566406,\n",
       "    'kurtosis': 0.008402176532598116,\n",
       "    'skew': -0.0,\n",
       "    'max_effect': 0.096435546875,\n",
       "    'min_effect': -0.09002685546875,\n",
       "    'num_positive': 69319,\n",
       "    'num_negative': 58937,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 90420,\n",
       "      'token_str': 'ernals',\n",
       "      'effect_magnitude': 0.096435546875},\n",
       "     {'token_id': 82000,\n",
       "      'token_str': '.scalablytyped',\n",
       "      'effect_magnitude': 0.09423828125},\n",
       "     {'token_id': 29946,\n",
       "      'token_str': 'ibo',\n",
       "      'effect_magnitude': 0.0911865234375},\n",
       "     {'token_id': 24527,\n",
       "      'token_str': 'osph',\n",
       "      'effect_magnitude': 0.0877685546875},\n",
       "     {'token_id': 49458,\n",
       "      'token_str': ' retros',\n",
       "      'effect_magnitude': 0.08721923828125},\n",
       "     {'token_id': 81487,\n",
       "      'token_str': 'ombo',\n",
       "      'effect_magnitude': 0.08258056640625},\n",
       "     {'token_id': 11597,\n",
       "      'token_str': 'osoph',\n",
       "      'effect_magnitude': 0.08251953125},\n",
       "     {'token_id': 121763,\n",
       "      'token_str': 'ranÃ­',\n",
       "      'effect_magnitude': 0.08233642578125},\n",
       "     {'token_id': 86186,\n",
       "      'token_str': '.SIG',\n",
       "      'effect_magnitude': 0.0811767578125},\n",
       "     {'token_id': 66752,\n",
       "      'token_str': ' Erotische',\n",
       "      'effect_magnitude': 0.0806884765625}],\n",
       "    'top_suppressed': [{'token_id': 53533,\n",
       "      'token_str': 'bolt',\n",
       "      'effect_magnitude': -0.09002685546875},\n",
       "     {'token_id': 23014, 'token_str': 'ikan', 'effect_magnitude': -0.08984375},\n",
       "     {'token_id': 125197,\n",
       "      'token_str': 'á»',\n",
       "      'effect_magnitude': -0.08795166015625},\n",
       "     {'token_id': 45533,\n",
       "      'token_str': 'utenberg',\n",
       "      'effect_magnitude': -0.08673095703125},\n",
       "     {'token_id': 44124,\n",
       "      'token_str': ' ushort',\n",
       "      'effect_magnitude': -0.08660888671875},\n",
       "     {'token_id': 19085,\n",
       "      'token_str': 'Force',\n",
       "      'effect_magnitude': -0.08636474609375},\n",
       "     {'token_id': 41312,\n",
       "      'token_str': 'usan',\n",
       "      'effect_magnitude': -0.08514404296875},\n",
       "     {'token_id': 6465,\n",
       "      'token_str': 'bot',\n",
       "      'effect_magnitude': -0.08343505859375},\n",
       "     {'token_id': 14029,\n",
       "      'token_str': 'vy',\n",
       "      'effect_magnitude': -0.08135986328125},\n",
       "     {'token_id': 59697,\n",
       "      'token_str': 'Äƒng',\n",
       "      'effect_magnitude': -0.0811767578125}]},\n",
       "   'effect_magnitude': 6.94140625,\n",
       "   'cumulative_magnitude': 23.102645874023438,\n",
       "   'amplification_factor': 4.98828125},\n",
       "  7: {'residual_magnitude': 1.5029296875,\n",
       "   'direct_vocab_effect': array([ 0.01518, -0.01117,  0.01253, ...,  0.00609,  0.00609,  0.00609],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.02521133, -0.04899311,  0.04041004, ...,  0.02655792,\n",
       "           0.02655411,  0.02655602], dtype=float32),\n",
       "   'statistics': {'mean': -0.0017690658569335938,\n",
       "    'std': 0.0206756591796875,\n",
       "    'variance': 0.0004277229309082031,\n",
       "    'kurtosis': 0.25802967652611386,\n",
       "    'skew': 0.00673808217114664,\n",
       "    'max_effect': 0.10595703125,\n",
       "    'min_effect': -0.10760498046875,\n",
       "    'num_positive': 60016,\n",
       "    'num_negative': 68239,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 82000,\n",
       "      'token_str': '.scalablytyped',\n",
       "      'effect_magnitude': 0.10595703125},\n",
       "     {'token_id': 24527,\n",
       "      'token_str': 'osph',\n",
       "      'effect_magnitude': 0.09368896484375},\n",
       "     {'token_id': 102209,\n",
       "      'token_str': 'uyá»‡n',\n",
       "      'effect_magnitude': 0.09307861328125},\n",
       "     {'token_id': 60382,\n",
       "      'token_str': 'hardt',\n",
       "      'effect_magnitude': 0.0926513671875},\n",
       "     {'token_id': 66222,\n",
       "      'token_str': 'osphere',\n",
       "      'effect_magnitude': 0.08978271484375},\n",
       "     {'token_id': 110954,\n",
       "      'token_str': 'iverz',\n",
       "      'effect_magnitude': 0.084228515625},\n",
       "     {'token_id': 26540,\n",
       "      'token_str': 'cession',\n",
       "      'effect_magnitude': 0.0831298828125},\n",
       "     {'token_id': 53478,\n",
       "      'token_str': 'oyo',\n",
       "      'effect_magnitude': 0.0828857421875},\n",
       "     {'token_id': 29946,\n",
       "      'token_str': 'ibo',\n",
       "      'effect_magnitude': 0.0826416015625},\n",
       "     {'token_id': 125539,\n",
       "      'token_str': 'ÛŒØ´Ù†',\n",
       "      'effect_magnitude': 0.08258056640625}],\n",
       "    'top_suppressed': [{'token_id': 86363,\n",
       "      'token_str': 'utomation',\n",
       "      'effect_magnitude': -0.10760498046875},\n",
       "     {'token_id': 36443,\n",
       "      'token_str': ' Hood',\n",
       "      'effect_magnitude': -0.10400390625},\n",
       "     {'token_id': 27106,\n",
       "      'token_str': 'pbs',\n",
       "      'effect_magnitude': -0.10345458984375},\n",
       "     {'token_id': 4414,\n",
       "      'token_str': 'oder',\n",
       "      'effect_magnitude': -0.102783203125},\n",
       "     {'token_id': 120676,\n",
       "      'token_str': 'eyle',\n",
       "      'effect_magnitude': -0.1005859375},\n",
       "     {'token_id': 107435,\n",
       "      'token_str': 'kla',\n",
       "      'effect_magnitude': -0.09576416015625},\n",
       "     {'token_id': 44124,\n",
       "      'token_str': ' ushort',\n",
       "      'effect_magnitude': -0.09381103515625},\n",
       "     {'token_id': 115203,\n",
       "      'token_str': 'à¸šà¸„',\n",
       "      'effect_magnitude': -0.0931396484375},\n",
       "     {'token_id': 89079,\n",
       "      'token_str': 'createClass',\n",
       "      'effect_magnitude': -0.09259033203125},\n",
       "     {'token_id': 88585,\n",
       "      'token_str': 'ompiler',\n",
       "      'effect_magnitude': -0.0919189453125}]},\n",
       "   'effect_magnitude': 7.43359375,\n",
       "   'cumulative_magnitude': 27.643795013427734,\n",
       "   'amplification_factor': 4.9453125},\n",
       "  8: {'residual_magnitude': 1.61328125,\n",
       "   'direct_vocab_effect': array([ 6.077e-03, -1.052e-02,  1.552e-02, ..., -7.761e-05, -7.546e-05,\n",
       "          -7.665e-05], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.03128815, -0.05951405,  0.05592823, ...,  0.02648032,\n",
       "           0.02647865,  0.02647936], dtype=float32),\n",
       "   'statistics': {'mean': -0.0017147064208984375,\n",
       "    'std': 0.022216796875,\n",
       "    'variance': 0.0004930496215820312,\n",
       "    'kurtosis': 0.18128497747905437,\n",
       "    'skew': 0.016309314124572122,\n",
       "    'max_effect': 0.1016845703125,\n",
       "    'min_effect': -0.1090087890625,\n",
       "    'num_positive': 59860,\n",
       "    'num_negative': 68396,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 18177,\n",
       "      'token_str': 'inge',\n",
       "      'effect_magnitude': 0.1016845703125},\n",
       "     {'token_id': 57821,\n",
       "      'token_str': 'ritz',\n",
       "      'effect_magnitude': 0.0997314453125},\n",
       "     {'token_id': 14055,\n",
       "      'token_str': 'Inject',\n",
       "      'effect_magnitude': 0.0931396484375},\n",
       "     {'token_id': 72459,\n",
       "      'token_str': 'tmpl',\n",
       "      'effect_magnitude': 0.0931396484375},\n",
       "     {'token_id': 39882,\n",
       "      'token_str': 'ailer',\n",
       "      'effect_magnitude': 0.09259033203125},\n",
       "     {'token_id': 89427,\n",
       "      'token_str': 'objs',\n",
       "      'effect_magnitude': 0.09234619140625},\n",
       "     {'token_id': 106159,\n",
       "      'token_str': 'Ð¸Ð½Ðµ',\n",
       "      'effect_magnitude': 0.09130859375},\n",
       "     {'token_id': 100885,\n",
       "      'token_str': 'ÛŒÚ©',\n",
       "      'effect_magnitude': 0.08990478515625},\n",
       "     {'token_id': 712,\n",
       "      'token_str': ' bo',\n",
       "      'effect_magnitude': 0.0877685546875},\n",
       "     {'token_id': 92480,\n",
       "      'token_str': 'coli',\n",
       "      'effect_magnitude': 0.0863037109375}],\n",
       "    'top_suppressed': [{'token_id': 74656,\n",
       "      'token_str': ' Bien',\n",
       "      'effect_magnitude': -0.1090087890625},\n",
       "     {'token_id': 84093, 'token_str': ' Dodd', 'effect_magnitude': -0.1015625},\n",
       "     {'token_id': 78277,\n",
       "      'token_str': 'rush',\n",
       "      'effect_magnitude': -0.1007080078125},\n",
       "     {'token_id': 56371,\n",
       "      'token_str': 'least',\n",
       "      'effect_magnitude': -0.10064697265625},\n",
       "     {'token_id': 8826,\n",
       "      'token_str': 'kan',\n",
       "      'effect_magnitude': -0.09796142578125},\n",
       "     {'token_id': 51390,\n",
       "      'token_str': ' ontvangst',\n",
       "      'effect_magnitude': -0.09722900390625},\n",
       "     {'token_id': 14750,\n",
       "      'token_str': 'egr',\n",
       "      'effect_magnitude': -0.09637451171875},\n",
       "     {'token_id': 40971, 'token_str': ' Fi', 'effect_magnitude': -0.095703125},\n",
       "     {'token_id': 76753,\n",
       "      'token_str': ' mooie',\n",
       "      'effect_magnitude': -0.0953369140625},\n",
       "     {'token_id': 37731,\n",
       "      'token_str': '-fi',\n",
       "      'effect_magnitude': -0.0947265625}]},\n",
       "   'effect_magnitude': 7.9765625,\n",
       "   'cumulative_magnitude': 32.456153869628906,\n",
       "   'amplification_factor': 4.9453125},\n",
       "  9: {'residual_magnitude': 1.6748046875,\n",
       "   'direct_vocab_effect': array([ 0.003323,  0.012665,  0.0269  , ..., -0.00787 , -0.007866,\n",
       "          -0.00787 ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.03461075, -0.04684925,  0.08282948, ...,  0.01860678,\n",
       "           0.01861274,  0.01860583], dtype=float32),\n",
       "   'statistics': {'mean': -0.005565643310546875,\n",
       "    'std': 0.023101806640625,\n",
       "    'variance': 0.0005335807800292969,\n",
       "    'kurtosis': 0.14029905100063012,\n",
       "    'skew': -0.009671856255429795,\n",
       "    'max_effect': 0.10205078125,\n",
       "    'min_effect': -0.1090087890625,\n",
       "    'num_positive': 51271,\n",
       "    'num_negative': 76985,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 90368,\n",
       "      'token_str': 'isce',\n",
       "      'effect_magnitude': 0.10205078125},\n",
       "     {'token_id': 127850,\n",
       "      'token_str': ' æµ™æ±Ÿ',\n",
       "      'effect_magnitude': 0.10040283203125},\n",
       "     {'token_id': 37164,\n",
       "      'token_str': 'onaut',\n",
       "      'effect_magnitude': 0.09912109375},\n",
       "     {'token_id': 113669,\n",
       "      'token_str': 'ÐµÐ·Ð´',\n",
       "      'effect_magnitude': 0.09820556640625},\n",
       "     {'token_id': 63753,\n",
       "      'token_str': 'oscope',\n",
       "      'effect_magnitude': 0.09503173828125},\n",
       "     {'token_id': 12663,\n",
       "      'token_str': 'iams',\n",
       "      'effect_magnitude': 0.09478759765625},\n",
       "     {'token_id': 43283,\n",
       "      'token_str': ' Ads',\n",
       "      'effect_magnitude': 0.094482421875},\n",
       "     {'token_id': 93098,\n",
       "      'token_str': ' Blond',\n",
       "      'effect_magnitude': 0.0916748046875},\n",
       "     {'token_id': 89427,\n",
       "      'token_str': 'objs',\n",
       "      'effect_magnitude': 0.09161376953125},\n",
       "     {'token_id': 48013,\n",
       "      'token_str': ' suburbs',\n",
       "      'effect_magnitude': 0.08831787109375}],\n",
       "    'top_suppressed': [{'token_id': 100800,\n",
       "      'token_str': 'Ú¯Ø§Ù‡',\n",
       "      'effect_magnitude': -0.1090087890625},\n",
       "     {'token_id': 118334,\n",
       "      'token_str': 'ÏÎº',\n",
       "      'effect_magnitude': -0.10675048828125},\n",
       "     {'token_id': 89079,\n",
       "      'token_str': 'createClass',\n",
       "      'effect_magnitude': -0.10406494140625},\n",
       "     {'token_id': 65527,\n",
       "      'token_str': 'mony',\n",
       "      'effect_magnitude': -0.10400390625},\n",
       "     {'token_id': 44788,\n",
       "      'token_str': 'ocode',\n",
       "      'effect_magnitude': -0.10382080078125},\n",
       "     {'token_id': 110642,\n",
       "      'token_str': ' olsun',\n",
       "      'effect_magnitude': -0.1021728515625},\n",
       "     {'token_id': 39216,\n",
       "      'token_str': ' Canon',\n",
       "      'effect_magnitude': -0.1019287109375},\n",
       "     {'token_id': 1516,\n",
       "      'token_str': 'ution',\n",
       "      'effect_magnitude': -0.10107421875},\n",
       "     {'token_id': 2023, 'token_str': 'pany', 'effect_magnitude': -0.099609375},\n",
       "     {'token_id': 125112,\n",
       "      'token_str': ' pÄ›',\n",
       "      'effect_magnitude': -0.099609375}]},\n",
       "   'effect_magnitude': 8.5078125,\n",
       "   'cumulative_magnitude': 37.33309555053711,\n",
       "   'amplification_factor': 5.078125},\n",
       "  10: {'residual_magnitude': 1.6806640625,\n",
       "   'direct_vocab_effect': array([ 0.007133, -0.00827 ,  0.013214, ...,  0.006752,  0.006752,\n",
       "           0.006752], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.04174423, -0.05511951,  0.09604359, ...,  0.0253588 ,\n",
       "           0.02536476,  0.02535784], dtype=float32),\n",
       "   'statistics': {'mean': 0.0012159347534179688,\n",
       "    'std': 0.0232391357421875,\n",
       "    'variance': 0.0005402565002441406,\n",
       "    'kurtosis': 0.26738329922590287,\n",
       "    'skew': 0.033226006270768285,\n",
       "    'max_effect': 0.11962890625,\n",
       "    'min_effect': -0.10638427734375,\n",
       "    'num_positive': 66620,\n",
       "    'num_negative': 61636,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 12663,\n",
       "      'token_str': 'iams',\n",
       "      'effect_magnitude': 0.11962890625},\n",
       "     {'token_id': 18177,\n",
       "      'token_str': 'inge',\n",
       "      'effect_magnitude': 0.11590576171875},\n",
       "     {'token_id': 113669,\n",
       "      'token_str': 'ÐµÐ·Ð´',\n",
       "      'effect_magnitude': 0.10711669921875},\n",
       "     {'token_id': 103947,\n",
       "      'token_str': 'Ã¡Å¾',\n",
       "      'effect_magnitude': 0.10662841796875},\n",
       "     {'token_id': 63015,\n",
       "      'token_str': 'deaux',\n",
       "      'effect_magnitude': 0.1060791015625},\n",
       "     {'token_id': 65598,\n",
       "      'token_str': 'cot',\n",
       "      'effect_magnitude': 0.10443115234375},\n",
       "     {'token_id': 23439,\n",
       "      'token_str': '072',\n",
       "      'effect_magnitude': 0.10235595703125},\n",
       "     {'token_id': 51003,\n",
       "      'token_str': 'otics',\n",
       "      'effect_magnitude': 0.10223388671875},\n",
       "     {'token_id': 55485,\n",
       "      'token_str': 'enburg',\n",
       "      'effect_magnitude': 0.1021728515625},\n",
       "     {'token_id': 65490,\n",
       "      'token_str': 'oteca',\n",
       "      'effect_magnitude': 0.098388671875}],\n",
       "    'top_suppressed': [{'token_id': 536,\n",
       "      'token_str': 'ode',\n",
       "      'effect_magnitude': -0.10638427734375},\n",
       "     {'token_id': 1105,\n",
       "      'token_str': 'ors',\n",
       "      'effect_magnitude': -0.106201171875},\n",
       "     {'token_id': 25519,\n",
       "      'token_str': ' Imper',\n",
       "      'effect_magnitude': -0.10333251953125},\n",
       "     {'token_id': 17190,\n",
       "      'token_str': ' imper',\n",
       "      'effect_magnitude': -0.10162353515625},\n",
       "     {'token_id': 36654,\n",
       "      'token_str': ' clearance',\n",
       "      'effect_magnitude': -0.10150146484375},\n",
       "     {'token_id': 75137,\n",
       "      'token_str': '/sm',\n",
       "      'effect_magnitude': -0.099365234375},\n",
       "     {'token_id': 94252,\n",
       "      'token_str': 'REW',\n",
       "      'effect_magnitude': -0.09893798828125},\n",
       "     {'token_id': 114018,\n",
       "      'token_str': ' chod',\n",
       "      'effect_magnitude': -0.098388671875},\n",
       "     {'token_id': 1441,\n",
       "      'token_str': 'ets',\n",
       "      'effect_magnitude': -0.096923828125},\n",
       "     {'token_id': 18960,\n",
       "      'token_str': '.commons',\n",
       "      'effect_magnitude': -0.09515380859375}]},\n",
       "   'effect_magnitude': 8.3359375,\n",
       "   'cumulative_magnitude': 42.083133697509766,\n",
       "   'amplification_factor': 4.9609375},\n",
       "  11: {'residual_magnitude': 1.7373046875,\n",
       "   'direct_vocab_effect': array([ 0.00656 ,  0.00714 ,  0.03427 , ..., -0.005726, -0.00573 ,\n",
       "          -0.005726], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.04830551, -0.0479784 ,  0.13031483, ...,  0.01963294,\n",
       "           0.01963508,  0.01963198], dtype=float32),\n",
       "   'statistics': {'mean': -0.0013980865478515625,\n",
       "    'std': 0.024139404296875,\n",
       "    'variance': 0.0005822181701660156,\n",
       "    'kurtosis': 0.16505381861647228,\n",
       "    'skew': 0.029699525554080765,\n",
       "    'max_effect': 0.15185546875,\n",
       "    'min_effect': -0.12353515625,\n",
       "    'num_positive': 60623,\n",
       "    'num_negative': 67633,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 12663,\n",
       "      'token_str': 'iams',\n",
       "      'effect_magnitude': 0.15185546875},\n",
       "     {'token_id': 40229,\n",
       "      'token_str': 'azu',\n",
       "      'effect_magnitude': 0.12042236328125},\n",
       "     {'token_id': 22309,\n",
       "      'token_str': 'ippet',\n",
       "      'effect_magnitude': 0.10931396484375},\n",
       "     {'token_id': 51003,\n",
       "      'token_str': 'otics',\n",
       "      'effect_magnitude': 0.109130859375},\n",
       "     {'token_id': 89974,\n",
       "      'token_str': '<decltype',\n",
       "      'effect_magnitude': 0.1087646484375},\n",
       "     {'token_id': 125907,\n",
       "      'token_str': 'ÏƒÎ¿Ï…',\n",
       "      'effect_magnitude': 0.1070556640625},\n",
       "     {'token_id': 76552,\n",
       "      'token_str': '_WM',\n",
       "      'effect_magnitude': 0.1053466796875},\n",
       "     {'token_id': 56134,\n",
       "      'token_str': 'thouse',\n",
       "      'effect_magnitude': 0.1043701171875},\n",
       "     {'token_id': 100598,\n",
       "      'token_str': 'Ø±Ù',\n",
       "      'effect_magnitude': 0.10345458984375},\n",
       "     {'token_id': 1375,\n",
       "      'token_str': ' rel',\n",
       "      'effect_magnitude': 0.1024169921875}],\n",
       "    'top_suppressed': [{'token_id': 1105,\n",
       "      'token_str': 'ors',\n",
       "      'effect_magnitude': -0.12353515625},\n",
       "     {'token_id': 82479,\n",
       "      'token_str': ' Gus',\n",
       "      'effect_magnitude': -0.1099853515625},\n",
       "     {'token_id': 75068,\n",
       "      'token_str': 'CISION',\n",
       "      'effect_magnitude': -0.1085205078125},\n",
       "     {'token_id': 123707,\n",
       "      'token_str': ' dahi',\n",
       "      'effect_magnitude': -0.1077880859375},\n",
       "     {'token_id': 83522,\n",
       "      'token_str': 'Å„st',\n",
       "      'effect_magnitude': -0.1063232421875},\n",
       "     {'token_id': 6809,\n",
       "      'token_str': 'orge',\n",
       "      'effect_magnitude': -0.10296630859375},\n",
       "     {'token_id': 81148,\n",
       "      'token_str': ' BASIC',\n",
       "      'effect_magnitude': -0.102294921875},\n",
       "     {'token_id': 27305,\n",
       "      'token_str': '/watch',\n",
       "      'effect_magnitude': -0.1009521484375},\n",
       "     {'token_id': 7090,\n",
       "      'token_str': ' panel',\n",
       "      'effect_magnitude': -0.10052490234375},\n",
       "     {'token_id': 79067,\n",
       "      'token_str': ' Fighters',\n",
       "      'effect_magnitude': -0.0989990234375}]},\n",
       "   'effect_magnitude': 8.65625,\n",
       "   'cumulative_magnitude': 46.77621078491211,\n",
       "   'amplification_factor': 4.984375},\n",
       "  12: {'residual_magnitude': 1.759765625,\n",
       "   'direct_vocab_effect': array([ 0.005997,  0.01903 ,  0.02638 , ..., -0.01701 , -0.01701 ,\n",
       "          -0.01701 ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.05430222, -0.02895069,  0.15669727, ...,  0.00261939,\n",
       "           0.00262153,  0.00261843], dtype=float32),\n",
       "   'statistics': {'mean': -0.003376007080078125,\n",
       "    'std': 0.0245361328125,\n",
       "    'variance': 0.0006022453308105469,\n",
       "    'kurtosis': 0.12238765923861372,\n",
       "    'skew': 0.020164615533031546,\n",
       "    'max_effect': 0.11077880859375,\n",
       "    'min_effect': -0.1182861328125,\n",
       "    'num_positive': 56734,\n",
       "    'num_negative': 71522,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 123572,\n",
       "      'token_str': 'Ð°ÑˆÐ°',\n",
       "      'effect_magnitude': 0.11077880859375},\n",
       "     {'token_id': 73005,\n",
       "      'token_str': 'ppe',\n",
       "      'effect_magnitude': 0.107666015625},\n",
       "     {'token_id': 55880,\n",
       "      'token_str': 'toc',\n",
       "      'effect_magnitude': 0.10614013671875},\n",
       "     {'token_id': 73477,\n",
       "      'token_str': 'ldr',\n",
       "      'effect_magnitude': 0.1043701171875},\n",
       "     {'token_id': 78048,\n",
       "      'token_str': ' YE',\n",
       "      'effect_magnitude': 0.10394287109375},\n",
       "     {'token_id': 78412,\n",
       "      'token_str': 'coc',\n",
       "      'effect_magnitude': 0.1033935546875},\n",
       "     {'token_id': 12663,\n",
       "      'token_str': 'iams',\n",
       "      'effect_magnitude': 0.10162353515625},\n",
       "     {'token_id': 49187,\n",
       "      'token_str': ' Territory',\n",
       "      'effect_magnitude': 0.10125732421875},\n",
       "     {'token_id': 58043,\n",
       "      'token_str': ' pity',\n",
       "      'effect_magnitude': 0.10089111328125},\n",
       "     {'token_id': 89974,\n",
       "      'token_str': '<decltype',\n",
       "      'effect_magnitude': 0.09954833984375}],\n",
       "    'top_suppressed': [{'token_id': 1105,\n",
       "      'token_str': 'ors',\n",
       "      'effect_magnitude': -0.1182861328125},\n",
       "     {'token_id': 82479,\n",
       "      'token_str': ' Gus',\n",
       "      'effect_magnitude': -0.1158447265625},\n",
       "     {'token_id': 83522,\n",
       "      'token_str': 'Å„st',\n",
       "      'effect_magnitude': -0.11431884765625},\n",
       "     {'token_id': 4040,\n",
       "      'token_str': ' particular',\n",
       "      'effect_magnitude': -0.10968017578125},\n",
       "     {'token_id': 89089,\n",
       "      'token_str': 'ersen',\n",
       "      'effect_magnitude': -0.10858154296875},\n",
       "     {'token_id': 22663,\n",
       "      'token_str': '553',\n",
       "      'effect_magnitude': -0.10711669921875},\n",
       "     {'token_id': 105226,\n",
       "      'token_str': 'ç­–',\n",
       "      'effect_magnitude': -0.10675048828125},\n",
       "     {'token_id': 78858,\n",
       "      'token_str': '/weather',\n",
       "      'effect_magnitude': -0.10662841796875},\n",
       "     {'token_id': 27305,\n",
       "      'token_str': '/watch',\n",
       "      'effect_magnitude': -0.1064453125},\n",
       "     {'token_id': 118622,\n",
       "      'token_str': 'Ø¸Ù‡',\n",
       "      'effect_magnitude': -0.105224609375}]},\n",
       "   'effect_magnitude': 8.875,\n",
       "   'cumulative_magnitude': 51.56418228149414,\n",
       "   'amplification_factor': 5.04296875},\n",
       "  13: {'residual_magnitude': 1.8466796875,\n",
       "   'direct_vocab_effect': array([ 0.004486,  0.04193 ,  0.03412 , ..., -0.02208 , -0.02208 ,\n",
       "          -0.02208 ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.0587883 ,  0.01298046,  0.19081593, ..., -0.01946008,\n",
       "          -0.01945794, -0.01946104], dtype=float32),\n",
       "   'statistics': {'mean': -0.00928497314453125,\n",
       "    'std': 0.0263824462890625,\n",
       "    'variance': 0.0006957054138183594,\n",
       "    'kurtosis': 0.20186256183993745,\n",
       "    'skew': -0.012992778089469652,\n",
       "    'max_effect': 0.107177734375,\n",
       "    'min_effect': -0.1368408203125,\n",
       "    'num_positive': 46178,\n",
       "    'num_negative': 82078,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 79925,\n",
       "      'token_str': 'Phoenix',\n",
       "      'effect_magnitude': 0.107177734375},\n",
       "     {'token_id': 43813,\n",
       "      'token_str': 'tek',\n",
       "      'effect_magnitude': 0.1051025390625},\n",
       "     {'token_id': 71492,\n",
       "      'token_str': ' Goodman',\n",
       "      'effect_magnitude': 0.10400390625},\n",
       "     {'token_id': 1433,\n",
       "      'token_str': 'ayout',\n",
       "      'effect_magnitude': 0.10357666015625},\n",
       "     {'token_id': 49187,\n",
       "      'token_str': ' Territory',\n",
       "      'effect_magnitude': 0.10345458984375},\n",
       "     {'token_id': 100396,\n",
       "      'token_str': 'ÑƒÐ²',\n",
       "      'effect_magnitude': 0.10284423828125},\n",
       "     {'token_id': 75116,\n",
       "      'token_str': ' Alexandra',\n",
       "      'effect_magnitude': 0.10223388671875},\n",
       "     {'token_id': 55496,\n",
       "      'token_str': 'aload',\n",
       "      'effect_magnitude': 0.1007080078125},\n",
       "     {'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.100341796875},\n",
       "     {'token_id': 57821,\n",
       "      'token_str': 'ritz',\n",
       "      'effect_magnitude': 0.0982666015625}],\n",
       "    'top_suppressed': [{'token_id': 83522,\n",
       "      'token_str': 'Å„st',\n",
       "      'effect_magnitude': -0.1368408203125},\n",
       "     {'token_id': 121805,\n",
       "      'token_str': 'åœ°ä¸‹',\n",
       "      'effect_magnitude': -0.1336669921875},\n",
       "     {'token_id': 99716,\n",
       "      'token_str': 'ezier',\n",
       "      'effect_magnitude': -0.132568359375},\n",
       "     {'token_id': 95436,\n",
       "      'token_str': ' cÃ©lib',\n",
       "      'effect_magnitude': -0.1290283203125},\n",
       "     {'token_id': 107324,\n",
       "      'token_str': 'adaÅŸ',\n",
       "      'effect_magnitude': -0.1263427734375},\n",
       "     {'token_id': 24681,\n",
       "      'token_str': 'utsch',\n",
       "      'effect_magnitude': -0.12493896484375},\n",
       "     {'token_id': 58329,\n",
       "      'token_str': 'laus',\n",
       "      'effect_magnitude': -0.12103271484375},\n",
       "     {'token_id': 27305,\n",
       "      'token_str': '/watch',\n",
       "      'effect_magnitude': -0.11981201171875},\n",
       "     {'token_id': 38998,\n",
       "      'token_str': ' Ori',\n",
       "      'effect_magnitude': -0.118408203125},\n",
       "     {'token_id': 72813,\n",
       "      'token_str': ' tat',\n",
       "      'effect_magnitude': -0.11767578125}]},\n",
       "   'effect_magnitude': 10.015625,\n",
       "   'cumulative_magnitude': 56.444332122802734,\n",
       "   'amplification_factor': 5.421875},\n",
       "  14: {'residual_magnitude': 2.041015625,\n",
       "   'direct_vocab_effect': array([ 0.0363 ,  0.06805,  0.03564, ..., -0.0295 , -0.0295 , -0.02948],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.0950737 ,  0.08103466,  0.22646046, ..., -0.04895532,\n",
       "          -0.04895318, -0.04894102], dtype=float32),\n",
       "   'statistics': {'mean': -0.018310546875,\n",
       "    'std': 0.030181884765625,\n",
       "    'variance': 0.0009112358093261719,\n",
       "    'kurtosis': 0.15842976888054316,\n",
       "    'skew': -0.036836881607215974,\n",
       "    'max_effect': 0.1239013671875,\n",
       "    'min_effect': -0.162353515625,\n",
       "    'num_positive': 34589,\n",
       "    'num_negative': 93667,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 27931,\n",
       "      'token_str': 'oba',\n",
       "      'effect_magnitude': 0.1239013671875},\n",
       "     {'token_id': 9522,\n",
       "      'token_str': '...\\n',\n",
       "      'effect_magnitude': 0.1158447265625},\n",
       "     {'token_id': 46993,\n",
       "      'token_str': ' Christine',\n",
       "      'effect_magnitude': 0.1102294921875},\n",
       "     {'token_id': 198, 'token_str': '\\n', 'effect_magnitude': 0.110107421875},\n",
       "     {'token_id': 10697,\n",
       "      'token_str': '224',\n",
       "      'effect_magnitude': 0.105224609375},\n",
       "     {'token_id': 79377,\n",
       "      'token_str': ' Miscellaneous',\n",
       "      'effect_magnitude': 0.1043701171875},\n",
       "     {'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.10400390625},\n",
       "     {'token_id': 1131,\n",
       "      'token_str': '...',\n",
       "      'effect_magnitude': 0.1031494140625},\n",
       "     {'token_id': 101927,\n",
       "      'token_str': 'ì–‘',\n",
       "      'effect_magnitude': 0.10247802734375},\n",
       "     {'token_id': 68512,\n",
       "      'token_str': 'coat',\n",
       "      'effect_magnitude': 0.10186767578125}],\n",
       "    'top_suppressed': [{'token_id': 88883,\n",
       "      'token_str': 'erdem',\n",
       "      'effect_magnitude': -0.162353515625},\n",
       "     {'token_id': 107324,\n",
       "      'token_str': 'adaÅŸ',\n",
       "      'effect_magnitude': -0.159912109375},\n",
       "     {'token_id': 75056,\n",
       "      'token_str': 'ZERO',\n",
       "      'effect_magnitude': -0.158447265625},\n",
       "     {'token_id': 105978, 'token_str': 'sÄ±', 'effect_magnitude': -0.158203125},\n",
       "     {'token_id': 67022,\n",
       "      'token_str': ' norge',\n",
       "      'effect_magnitude': -0.1544189453125},\n",
       "     {'token_id': 76447,\n",
       "      'token_str': 'jerne',\n",
       "      'effect_magnitude': -0.1539306640625},\n",
       "     {'token_id': 92980,\n",
       "      'token_str': ' conseils',\n",
       "      'effect_magnitude': -0.1483154296875},\n",
       "     {'token_id': 90279,\n",
       "      'token_str': 'ï¿½ï¿½',\n",
       "      'effect_magnitude': -0.1483154296875},\n",
       "     {'token_id': 115771,\n",
       "      'token_str': 'anlÄ±',\n",
       "      'effect_magnitude': -0.147216796875},\n",
       "     {'token_id': 115952,\n",
       "      'token_str': 'Î´ÏŒÎ½',\n",
       "      'effect_magnitude': -0.1461181640625}]},\n",
       "   'effect_magnitude': 12.6484375,\n",
       "   'cumulative_magnitude': 62.60988235473633,\n",
       "   'amplification_factor': 6.1953125},\n",
       "  15: {'residual_magnitude': 2.166015625,\n",
       "   'direct_vocab_effect': array([ 0.04086,  0.04587,  0.04016, ..., -0.00844, -0.00844, -0.00844],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.13593674,  0.12690258,  0.2666216 , ..., -0.05739343,\n",
       "          -0.05739129, -0.05737913], dtype=float32),\n",
       "   'statistics': {'mean': -0.009735107421875,\n",
       "    'std': 0.0305328369140625,\n",
       "    'variance': 0.0009326934814453125,\n",
       "    'kurtosis': 0.15181017141949038,\n",
       "    'skew': -0.03766553989051755,\n",
       "    'max_effect': 0.1435546875,\n",
       "    'min_effect': -0.153076171875,\n",
       "    'num_positive': 47741,\n",
       "    'num_negative': 80515,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 3829,\n",
       "      'token_str': 'reet',\n",
       "      'effect_magnitude': 0.1435546875},\n",
       "     {'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.1295166015625},\n",
       "     {'token_id': 43860,\n",
       "      'token_str': ' PY',\n",
       "      'effect_magnitude': 0.1248779296875},\n",
       "     {'token_id': 99128,\n",
       "      'token_str': 'ennie',\n",
       "      'effect_magnitude': 0.12127685546875},\n",
       "     {'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.1212158203125},\n",
       "     {'token_id': 83322,\n",
       "      'token_str': ' Multimedia',\n",
       "      'effect_magnitude': 0.119873046875},\n",
       "     {'token_id': 33659, 'token_str': ' Mis', 'effect_magnitude': 0.1171875},\n",
       "     {'token_id': 32112,\n",
       "      'token_str': '.datab',\n",
       "      'effect_magnitude': 0.11663818359375},\n",
       "     {'token_id': 36847,\n",
       "      'token_str': 'quip',\n",
       "      'effect_magnitude': 0.11553955078125},\n",
       "     {'token_id': 101829,\n",
       "      'token_str': 'Ð¾ÑÐ¿',\n",
       "      'effect_magnitude': 0.114501953125}],\n",
       "    'top_suppressed': [{'token_id': 111293,\n",
       "      'token_str': 'rnek',\n",
       "      'effect_magnitude': -0.153076171875},\n",
       "     {'token_id': 55428,\n",
       "      'token_str': ' seins',\n",
       "      'effect_magnitude': -0.1458740234375},\n",
       "     {'token_id': 107275,\n",
       "      'token_str': 'ï¾Ÿ',\n",
       "      'effect_magnitude': -0.1427001953125},\n",
       "     {'token_id': 31413,\n",
       "      'token_str': 'inspace',\n",
       "      'effect_magnitude': -0.139892578125},\n",
       "     {'token_id': 23002,\n",
       "      'token_str': ' erotische',\n",
       "      'effect_magnitude': -0.139892578125},\n",
       "     {'token_id': 126731,\n",
       "      'token_str': ' terk',\n",
       "      'effect_magnitude': -0.1373291015625},\n",
       "     {'token_id': 105719,\n",
       "      'token_str': 'uteÄ',\n",
       "      'effect_magnitude': -0.13720703125},\n",
       "     {'token_id': 23293,\n",
       "      'token_str': 'ERRU',\n",
       "      'effect_magnitude': -0.13525390625},\n",
       "     {'token_id': 46708,\n",
       "      'token_str': '(en',\n",
       "      'effect_magnitude': -0.1351318359375},\n",
       "     {'token_id': 69898,\n",
       "      'token_str': 'oins',\n",
       "      'effect_magnitude': -0.13427734375}]},\n",
       "   'effect_magnitude': 11.4765625,\n",
       "   'cumulative_magnitude': 68.78170013427734,\n",
       "   'amplification_factor': 5.296875},\n",
       "  16: {'residual_magnitude': 2.31640625,\n",
       "   'direct_vocab_effect': array([-0.00916,  0.03168,  0.0189 , ...,  0.00888,  0.00888,  0.00888],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.12677383,  0.15857983,  0.28552723, ..., -0.04851282,\n",
       "          -0.04851067, -0.04849851], dtype=float32),\n",
       "   'statistics': {'mean': 0.00013828277587890625,\n",
       "    'std': 0.0322265625,\n",
       "    'variance': 0.0010385513305664062,\n",
       "    'kurtosis': 0.20517808521815528,\n",
       "    'skew': 0.014247154743022511,\n",
       "    'max_effect': 0.167236328125,\n",
       "    'min_effect': -0.157958984375,\n",
       "    'num_positive': 64713,\n",
       "    'num_negative': 63543,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.167236328125},\n",
       "     {'token_id': 3829,\n",
       "      'token_str': 'reet',\n",
       "      'effect_magnitude': 0.1646728515625},\n",
       "     {'token_id': 97855,\n",
       "      'token_str': 'orado',\n",
       "      'effect_magnitude': 0.16259765625},\n",
       "     {'token_id': 32112,\n",
       "      'token_str': '.datab',\n",
       "      'effect_magnitude': 0.1549072265625},\n",
       "     {'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.142333984375},\n",
       "     {'token_id': 83322,\n",
       "      'token_str': ' Multimedia',\n",
       "      'effect_magnitude': 0.1422119140625},\n",
       "     {'token_id': 36847,\n",
       "      'token_str': 'quip',\n",
       "      'effect_magnitude': 0.138916015625},\n",
       "     {'token_id': 110622,\n",
       "      'token_str': 'æµ¦',\n",
       "      'effect_magnitude': 0.1351318359375},\n",
       "     {'token_id': 62189,\n",
       "      'token_str': ' Sas',\n",
       "      'effect_magnitude': 0.135009765625},\n",
       "     {'token_id': 23927,\n",
       "      'token_str': ' Marketable',\n",
       "      'effect_magnitude': 0.134521484375}],\n",
       "    'top_suppressed': [{'token_id': 101472,\n",
       "      'token_str': ' Ð¿Ð¾Ð·',\n",
       "      'effect_magnitude': -0.157958984375},\n",
       "     {'token_id': 5888,\n",
       "      'token_str': 'iler',\n",
       "      'effect_magnitude': -0.1376953125},\n",
       "     {'token_id': 105719,\n",
       "      'token_str': 'uteÄ',\n",
       "      'effect_magnitude': -0.1351318359375},\n",
       "     {'token_id': 20102,\n",
       "      'token_str': 'DAO',\n",
       "      'effect_magnitude': -0.1339111328125},\n",
       "     {'token_id': 73304,\n",
       "      'token_str': ' labore',\n",
       "      'effect_magnitude': -0.132568359375},\n",
       "     {'token_id': 75473,\n",
       "      'token_str': 'Ã©k',\n",
       "      'effect_magnitude': -0.1307373046875},\n",
       "     {'token_id': 2210,\n",
       "      'token_str': 'ervices',\n",
       "      'effect_magnitude': -0.1302490234375},\n",
       "     {'token_id': 3299, 'token_str': 'ï¿½ï¿½', 'effect_magnitude': -0.1298828125},\n",
       "     {'token_id': 19919,\n",
       "      'token_str': 'Ã¼ck',\n",
       "      'effect_magnitude': -0.12939453125},\n",
       "     {'token_id': 33029,\n",
       "      'token_str': 'opard',\n",
       "      'effect_magnitude': -0.12841796875}]},\n",
       "   'effect_magnitude': 11.5390625,\n",
       "   'cumulative_magnitude': 74.5765380859375,\n",
       "   'amplification_factor': 4.98046875},\n",
       "  17: {'residual_magnitude': 2.35546875,\n",
       "   'direct_vocab_effect': array([0.01211 , 0.0217  , 0.02141 , ..., 0.006878, 0.006878, 0.006878],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.13888168,  0.18027782,  0.3069353 , ..., -0.04163492,\n",
       "          -0.04163277, -0.04162061], dtype=float32),\n",
       "   'statistics': {'mean': -0.00673675537109375,\n",
       "    'std': 0.03302001953125,\n",
       "    'variance': 0.00109100341796875,\n",
       "    'kurtosis': 0.1547752946354346,\n",
       "    'skew': -0.0165402068808135,\n",
       "    'max_effect': 0.159912109375,\n",
       "    'min_effect': -0.1575927734375,\n",
       "    'num_positive': 54069,\n",
       "    'num_negative': 74187,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.159912109375},\n",
       "     {'token_id': 32112,\n",
       "      'token_str': '.datab',\n",
       "      'effect_magnitude': 0.14404296875},\n",
       "     {'token_id': 23927,\n",
       "      'token_str': ' Marketable',\n",
       "      'effect_magnitude': 0.1416015625},\n",
       "     {'token_id': 83322,\n",
       "      'token_str': ' Multimedia',\n",
       "      'effect_magnitude': 0.1351318359375},\n",
       "     {'token_id': 57821,\n",
       "      'token_str': 'ritz',\n",
       "      'effect_magnitude': 0.132080078125},\n",
       "     {'token_id': 97855,\n",
       "      'token_str': 'orado',\n",
       "      'effect_magnitude': 0.128662109375},\n",
       "     {'token_id': 36847,\n",
       "      'token_str': 'quip',\n",
       "      'effect_magnitude': 0.1280517578125},\n",
       "     {'token_id': 3829,\n",
       "      'token_str': 'reet',\n",
       "      'effect_magnitude': 0.127685546875},\n",
       "     {'token_id': 68849,\n",
       "      'token_str': 'ByKey',\n",
       "      'effect_magnitude': 0.12744140625},\n",
       "     {'token_id': 93066,\n",
       "      'token_str': 'ahas',\n",
       "      'effect_magnitude': 0.1273193359375}],\n",
       "    'top_suppressed': [{'token_id': 2210,\n",
       "      'token_str': 'ervices',\n",
       "      'effect_magnitude': -0.1575927734375},\n",
       "     {'token_id': 3299,\n",
       "      'token_str': 'ï¿½ï¿½',\n",
       "      'effect_magnitude': -0.1541748046875},\n",
       "     {'token_id': 101472,\n",
       "      'token_str': ' Ð¿Ð¾Ð·',\n",
       "      'effect_magnitude': -0.15380859375},\n",
       "     {'token_id': 120372,\n",
       "      'token_str': 'Ñ‚Ð¾Ñ„',\n",
       "      'effect_magnitude': -0.1517333984375},\n",
       "     {'token_id': 28679,\n",
       "      'token_str': 'qq',\n",
       "      'effect_magnitude': -0.146728515625},\n",
       "     {'token_id': 126731,\n",
       "      'token_str': ' terk',\n",
       "      'effect_magnitude': -0.1427001953125},\n",
       "     {'token_id': 106470,\n",
       "      'token_str': ' stol',\n",
       "      'effect_magnitude': -0.140869140625},\n",
       "     {'token_id': 126720,\n",
       "      'token_str': ' dÃ¡n',\n",
       "      'effect_magnitude': -0.1390380859375},\n",
       "     {'token_id': 40617,\n",
       "      'token_str': 'him',\n",
       "      'effect_magnitude': -0.137939453125},\n",
       "     {'token_id': 73304,\n",
       "      'token_str': ' labore',\n",
       "      'effect_magnitude': -0.1365966796875}]},\n",
       "   'effect_magnitude': 12.0703125,\n",
       "   'cumulative_magnitude': 81.9898910522461,\n",
       "   'amplification_factor': 5.125},\n",
       "  18: {'residual_magnitude': 2.560546875,\n",
       "   'direct_vocab_effect': array([0.009094, 0.03078 , 0.02446 , ..., 0.00991 , 0.00991 , 0.00991 ],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.14797592,  0.2110548 ,  0.33139515, ..., -0.03172433,\n",
       "          -0.03172219, -0.03171003], dtype=float32),\n",
       "   'statistics': {'mean': -0.00981903076171875,\n",
       "    'std': 0.036468505859375,\n",
       "    'variance': 0.0013294219970703125,\n",
       "    'kurtosis': 0.17472090222417602,\n",
       "    'skew': -0.03939156883603339,\n",
       "    'max_effect': 0.166748046875,\n",
       "    'min_effect': -0.1868896484375,\n",
       "    'num_positive': 50682,\n",
       "    'num_negative': 77574,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.166748046875},\n",
       "     {'token_id': 68849,\n",
       "      'token_str': 'ByKey',\n",
       "      'effect_magnitude': 0.1651611328125},\n",
       "     {'token_id': 52206,\n",
       "      'token_str': 'ahi',\n",
       "      'effect_magnitude': 0.1478271484375},\n",
       "     {'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.1478271484375},\n",
       "     {'token_id': 57821,\n",
       "      'token_str': 'ritz',\n",
       "      'effect_magnitude': 0.1455078125},\n",
       "     {'token_id': 59598,\n",
       "      'token_str': 'uppe',\n",
       "      'effect_magnitude': 0.143798828125},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.142822265625},\n",
       "     {'token_id': 83322,\n",
       "      'token_str': ' Multimedia',\n",
       "      'effect_magnitude': 0.1422119140625},\n",
       "     {'token_id': 46431,\n",
       "      'token_str': '\\xading',\n",
       "      'effect_magnitude': 0.1396484375},\n",
       "     {'token_id': 24009,\n",
       "      'token_str': ' hiring',\n",
       "      'effect_magnitude': 0.1390380859375}],\n",
       "    'top_suppressed': [{'token_id': 126720,\n",
       "      'token_str': ' dÃ¡n',\n",
       "      'effect_magnitude': -0.1868896484375},\n",
       "     {'token_id': 105719,\n",
       "      'token_str': 'uteÄ',\n",
       "      'effect_magnitude': -0.16943359375},\n",
       "     {'token_id': 14750,\n",
       "      'token_str': 'egr',\n",
       "      'effect_magnitude': -0.167724609375},\n",
       "     {'token_id': 39722,\n",
       "      'token_str': ' prostitu',\n",
       "      'effect_magnitude': -0.1666259765625},\n",
       "     {'token_id': 120372,\n",
       "      'token_str': 'Ñ‚Ð¾Ñ„',\n",
       "      'effect_magnitude': -0.1619873046875},\n",
       "     {'token_id': 48537,\n",
       "      'token_str': ' {*}',\n",
       "      'effect_magnitude': -0.1617431640625},\n",
       "     {'token_id': 80781,\n",
       "      'token_str': ' bulls',\n",
       "      'effect_magnitude': -0.1610107421875},\n",
       "     {'token_id': 108987,\n",
       "      'token_str': 'Ð´Ð°Ð²',\n",
       "      'effect_magnitude': -0.1595458984375},\n",
       "     {'token_id': 49452,\n",
       "      'token_str': ' porr',\n",
       "      'effect_magnitude': -0.1588134765625},\n",
       "     {'token_id': 19919,\n",
       "      'token_str': 'Ã¼ck',\n",
       "      'effect_magnitude': -0.158447265625}]},\n",
       "   'effect_magnitude': 13.5234375,\n",
       "   'cumulative_magnitude': 90.71671295166016,\n",
       "   'amplification_factor': 5.28125},\n",
       "  19: {'residual_magnitude': 2.79296875,\n",
       "   'direct_vocab_effect': array([0.01371 , 0.0284  , 0.02916 , ..., 0.002522, 0.002522, 0.002522],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.16168594,  0.23945141,  0.3605547 , ..., -0.02920282,\n",
       "          -0.02920067, -0.02918851], dtype=float32),\n",
       "   'statistics': {'mean': -0.0157470703125,\n",
       "    'std': 0.040557861328125,\n",
       "    'variance': 0.0016460418701171875,\n",
       "    'kurtosis': 0.18982127344183208,\n",
       "    'skew': -0.04194852018420859,\n",
       "    'max_effect': 0.17578125,\n",
       "    'min_effect': -0.2196044921875,\n",
       "    'num_positive': 44680,\n",
       "    'num_negative': 83576,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.17578125},\n",
       "     {'token_id': 19944, 'token_str': '608', 'effect_magnitude': 0.1640625},\n",
       "     {'token_id': 23774,\n",
       "      'token_str': 'tel',\n",
       "      'effect_magnitude': 0.1553955078125},\n",
       "     {'token_id': 16803,\n",
       "      'token_str': ' Civil',\n",
       "      'effect_magnitude': 0.1539306640625},\n",
       "     {'token_id': 59598,\n",
       "      'token_str': 'uppe',\n",
       "      'effect_magnitude': 0.1529541015625},\n",
       "     {'token_id': 23927,\n",
       "      'token_str': ' Marketable',\n",
       "      'effect_magnitude': 0.152099609375},\n",
       "     {'token_id': 23505,\n",
       "      'token_str': '907',\n",
       "      'effect_magnitude': 0.150146484375},\n",
       "     {'token_id': 8431,\n",
       "      'token_str': ' civil',\n",
       "      'effect_magnitude': 0.1500244140625},\n",
       "     {'token_id': 73253,\n",
       "      'token_str': 'affer',\n",
       "      'effect_magnitude': 0.1495361328125},\n",
       "     {'token_id': 24009,\n",
       "      'token_str': ' hiring',\n",
       "      'effect_magnitude': 0.1484375}],\n",
       "    'top_suppressed': [{'token_id': 86020,\n",
       "      'token_str': 'USES',\n",
       "      'effect_magnitude': -0.2196044921875},\n",
       "     {'token_id': 39722,\n",
       "      'token_str': ' prostitu',\n",
       "      'effect_magnitude': -0.209716796875},\n",
       "     {'token_id': 77701,\n",
       "      'token_str': ' nouve',\n",
       "      'effect_magnitude': -0.203369140625},\n",
       "     {'token_id': 126720,\n",
       "      'token_str': ' dÃ¡n',\n",
       "      'effect_magnitude': -0.20166015625},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.1976318359375},\n",
       "     {'token_id': 23625,\n",
       "      'token_str': ' lesb',\n",
       "      'effect_magnitude': -0.195068359375},\n",
       "     {'token_id': 126731,\n",
       "      'token_str': ' terk',\n",
       "      'effect_magnitude': -0.192626953125},\n",
       "     {'token_id': 49452,\n",
       "      'token_str': ' porr',\n",
       "      'effect_magnitude': -0.191650390625},\n",
       "     {'token_id': 44823,\n",
       "      'token_str': 'assin',\n",
       "      'effect_magnitude': -0.1904296875},\n",
       "     {'token_id': 3299,\n",
       "      'token_str': 'ï¿½ï¿½',\n",
       "      'effect_magnitude': -0.1888427734375}]},\n",
       "   'effect_magnitude': 15.5859375,\n",
       "   'cumulative_magnitude': 101.5077133178711,\n",
       "   'amplification_factor': 5.58203125},\n",
       "  20: {'residual_magnitude': 3.048828125,\n",
       "   'direct_vocab_effect': array([-0.004192,  0.0214  ,  0.011925, ...,  0.01398 ,  0.01398 ,\n",
       "           0.01398 ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.15749359,  0.26084423,  0.37247944, ..., -0.01522577,\n",
       "          -0.01522362, -0.01521146], dtype=float32),\n",
       "   'statistics': {'mean': -0.0051116943359375,\n",
       "    'std': 0.0428466796875,\n",
       "    'variance': 0.0018358230590820312,\n",
       "    'kurtosis': 0.1833982121774329,\n",
       "    'skew': -0.042434774652607005,\n",
       "    'max_effect': 0.198974609375,\n",
       "    'min_effect': -0.201416015625,\n",
       "    'num_positive': 58365,\n",
       "    'num_negative': 69891,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.198974609375},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.1917724609375},\n",
       "     {'token_id': 14213, 'token_str': '#a', 'effect_magnitude': 0.1884765625},\n",
       "     {'token_id': 24009,\n",
       "      'token_str': ' hiring',\n",
       "      'effect_magnitude': 0.18701171875},\n",
       "     {'token_id': 125907,\n",
       "      'token_str': 'ÏƒÎ¿Ï…',\n",
       "      'effect_magnitude': 0.186767578125},\n",
       "     {'token_id': 98422,\n",
       "      'token_str': 'edBy',\n",
       "      'effect_magnitude': 0.183837890625},\n",
       "     {'token_id': 34987,\n",
       "      'token_str': 'udit',\n",
       "      'effect_magnitude': 0.1756591796875},\n",
       "     {'token_id': 23505,\n",
       "      'token_str': '907',\n",
       "      'effect_magnitude': 0.174072265625},\n",
       "     {'token_id': 115972,\n",
       "      'token_str': ' â€“\\n',\n",
       "      'effect_magnitude': 0.169677734375},\n",
       "     {'token_id': 51782,\n",
       "      'token_str': 'otope',\n",
       "      'effect_magnitude': 0.169189453125}],\n",
       "    'top_suppressed': [{'token_id': 44823,\n",
       "      'token_str': 'assin',\n",
       "      'effect_magnitude': -0.201416015625},\n",
       "     {'token_id': 3299, 'token_str': 'ï¿½ï¿½', 'effect_magnitude': -0.197265625},\n",
       "     {'token_id': 86020,\n",
       "      'token_str': 'USES',\n",
       "      'effect_magnitude': -0.1962890625},\n",
       "     {'token_id': 112096,\n",
       "      'token_str': 'Ñ€Ð¾Ñ‡',\n",
       "      'effect_magnitude': -0.1961669921875},\n",
       "     {'token_id': 117648,\n",
       "      'token_str': 'à¸±à¸™à¸—à¸£',\n",
       "      'effect_magnitude': -0.1915283203125},\n",
       "     {'token_id': 29943,\n",
       "      'token_str': ' pione',\n",
       "      'effect_magnitude': -0.19091796875},\n",
       "     {'token_id': 26518,\n",
       "      'token_str': ' bang',\n",
       "      'effect_magnitude': -0.189453125},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.189208984375},\n",
       "     {'token_id': 39722,\n",
       "      'token_str': ' prostitu',\n",
       "      'effect_magnitude': -0.185546875},\n",
       "     {'token_id': 46122,\n",
       "      'token_str': 'easy',\n",
       "      'effect_magnitude': -0.185302734375}]},\n",
       "   'effect_magnitude': 15.453125,\n",
       "   'cumulative_magnitude': 111.97415924072266,\n",
       "   'amplification_factor': 5.0703125},\n",
       "  21: {'residual_magnitude': 3.4296875,\n",
       "   'direct_vocab_effect': array([0.003283, 0.03812 , 0.0076  , ..., 0.01002 , 0.01002 , 0.01002 ],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.16077614,  0.2989607 ,  0.38007832, ..., -0.00520837,\n",
       "          -0.00520623, -0.00519407], dtype=float32),\n",
       "   'statistics': {'mean': -0.00841522216796875,\n",
       "    'std': 0.048797607421875,\n",
       "    'variance': 0.00238037109375,\n",
       "    'kurtosis': 0.2084155161078236,\n",
       "    'skew': -0.0523495887439708,\n",
       "    'max_effect': 0.23583984375,\n",
       "    'min_effect': -0.24365234375,\n",
       "    'num_positive': 55755,\n",
       "    'num_negative': 72501,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.23583984375},\n",
       "     {'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.2137451171875},\n",
       "     {'token_id': 125907,\n",
       "      'token_str': 'ÏƒÎ¿Ï…',\n",
       "      'effect_magnitude': 0.20654296875},\n",
       "     {'token_id': 24009,\n",
       "      'token_str': ' hiring',\n",
       "      'effect_magnitude': 0.20458984375},\n",
       "     {'token_id': 99376,\n",
       "      'token_str': '(\"<?',\n",
       "      'effect_magnitude': 0.202880859375},\n",
       "     {'token_id': 8899,\n",
       "      'token_str': '118',\n",
       "      'effect_magnitude': 0.2012939453125},\n",
       "     {'token_id': 79386,\n",
       "      'token_str': \"('='\",\n",
       "      'effect_magnitude': 0.1966552734375},\n",
       "     {'token_id': 17897,\n",
       "      'token_str': '287',\n",
       "      'effect_magnitude': 0.1927490234375},\n",
       "     {'token_id': 34987,\n",
       "      'token_str': 'udit',\n",
       "      'effect_magnitude': 0.1904296875},\n",
       "     {'token_id': 87856,\n",
       "      'token_str': ' Michaels',\n",
       "      'effect_magnitude': 0.1895751953125}],\n",
       "    'top_suppressed': [{'token_id': 3299,\n",
       "      'token_str': 'ï¿½ï¿½',\n",
       "      'effect_magnitude': -0.24365234375},\n",
       "     {'token_id': 86020,\n",
       "      'token_str': 'USES',\n",
       "      'effect_magnitude': -0.2388916015625},\n",
       "     {'token_id': 112096,\n",
       "      'token_str': 'Ñ€Ð¾Ñ‡',\n",
       "      'effect_magnitude': -0.222412109375},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.221923828125},\n",
       "     {'token_id': 102705,\n",
       "      'token_str': 'maz',\n",
       "      'effect_magnitude': -0.2177734375},\n",
       "     {'token_id': 31967,\n",
       "      'token_str': 'umar',\n",
       "      'effect_magnitude': -0.21630859375},\n",
       "     {'token_id': 11287,\n",
       "      'token_str': 'iginal',\n",
       "      'effect_magnitude': -0.2154541015625},\n",
       "     {'token_id': 44823,\n",
       "      'token_str': 'assin',\n",
       "      'effect_magnitude': -0.21533203125},\n",
       "     {'token_id': 27197, 'token_str': 'erie', 'effect_magnitude': -0.21484375},\n",
       "     {'token_id': 46122,\n",
       "      'token_str': 'easy',\n",
       "      'effect_magnitude': -0.2080078125}]},\n",
       "   'effect_magnitude': 17.734375,\n",
       "   'cumulative_magnitude': 124.61468505859375,\n",
       "   'amplification_factor': 5.171875},\n",
       "  22: {'residual_magnitude': 3.720703125,\n",
       "   'direct_vocab_effect': array([-0.01446 ,  0.04086 ,  0.006756, ...,  0.0113  ,  0.0113  ,\n",
       "           0.0113  ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.14631844, 0.33982372, 0.38683414, ..., 0.00609076, 0.00609291,\n",
       "          0.00610507], dtype=float32),\n",
       "   'statistics': {'mean': -0.005344390869140625,\n",
       "    'std': 0.053131103515625,\n",
       "    'variance': 0.0028228759765625,\n",
       "    'kurtosis': 0.20888239590942304,\n",
       "    'skew': -0.05722751653054504,\n",
       "    'max_effect': 0.2470703125,\n",
       "    'min_effect': -0.262451171875,\n",
       "    'num_positive': 59675,\n",
       "    'num_negative': 68580,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.2470703125},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.238525390625},\n",
       "     {'token_id': 78048,\n",
       "      'token_str': ' YE',\n",
       "      'effect_magnitude': 0.22705078125},\n",
       "     {'token_id': 24009,\n",
       "      'token_str': ' hiring',\n",
       "      'effect_magnitude': 0.22607421875},\n",
       "     {'token_id': 99376, 'token_str': '(\"<?', 'effect_magnitude': 0.22265625},\n",
       "     {'token_id': 90876,\n",
       "      'token_str': 'iguiente',\n",
       "      'effect_magnitude': 0.2225341796875},\n",
       "     {'token_id': 8899,\n",
       "      'token_str': '118',\n",
       "      'effect_magnitude': 0.220458984375},\n",
       "     {'token_id': 29365,\n",
       "      'token_str': 'HashCode',\n",
       "      'effect_magnitude': 0.216552734375},\n",
       "     {'token_id': 66187,\n",
       "      'token_str': ' Welfare',\n",
       "      'effect_magnitude': 0.2120361328125},\n",
       "     {'token_id': 125907,\n",
       "      'token_str': 'ÏƒÎ¿Ï…',\n",
       "      'effect_magnitude': 0.2056884765625}],\n",
       "    'top_suppressed': [{'token_id': 3299,\n",
       "      'token_str': 'ï¿½ï¿½',\n",
       "      'effect_magnitude': -0.262451171875},\n",
       "     {'token_id': 86020,\n",
       "      'token_str': 'USES',\n",
       "      'effect_magnitude': -0.2509765625},\n",
       "     {'token_id': 22321,\n",
       "      'token_str': 'artz',\n",
       "      'effect_magnitude': -0.247314453125},\n",
       "     {'token_id': 27197,\n",
       "      'token_str': 'erie',\n",
       "      'effect_magnitude': -0.244384765625},\n",
       "     {'token_id': 11287,\n",
       "      'token_str': 'iginal',\n",
       "      'effect_magnitude': -0.2398681640625},\n",
       "     {'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.238037109375},\n",
       "     {'token_id': 112096,\n",
       "      'token_str': 'Ñ€Ð¾Ñ‡',\n",
       "      'effect_magnitude': -0.220947265625},\n",
       "     {'token_id': 27919,\n",
       "      'token_str': 'egral',\n",
       "      'effect_magnitude': -0.220703125},\n",
       "     {'token_id': 46122,\n",
       "      'token_str': 'easy',\n",
       "      'effect_magnitude': -0.2197265625},\n",
       "     {'token_id': 4428,\n",
       "      'token_str': 'ato',\n",
       "      'effect_magnitude': -0.2183837890625}]},\n",
       "   'effect_magnitude': 19.125,\n",
       "   'cumulative_magnitude': 138.55255126953125,\n",
       "   'amplification_factor': 5.140625},\n",
       "  23: {'residual_magnitude': 4.0625,\n",
       "   'direct_vocab_effect': array([-0.03354  ,  0.03757  ,  0.0007496, ...,  0.01453  ,  0.01453  ,\n",
       "           0.01453  ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.11277962, 0.37739086, 0.38758373, ..., 0.02061713, 0.02061927,\n",
       "          0.02063143], dtype=float32),\n",
       "   'statistics': {'mean': -0.001953125,\n",
       "    'std': 0.0579833984375,\n",
       "    'variance': 0.0033626556396484375,\n",
       "    'kurtosis': 0.204932550321427,\n",
       "    'skew': -0.05563241333151686,\n",
       "    'max_effect': 0.267333984375,\n",
       "    'min_effect': -0.266845703125,\n",
       "    'num_positive': 63137,\n",
       "    'num_negative': 65119,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 99376,\n",
       "      'token_str': '(\"<?',\n",
       "      'effect_magnitude': 0.267333984375},\n",
       "     {'token_id': 71964,\n",
       "      'token_str': ' Telecom',\n",
       "      'effect_magnitude': 0.258544921875},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.252685546875},\n",
       "     {'token_id': 90876,\n",
       "      'token_str': 'iguiente',\n",
       "      'effect_magnitude': 0.250244140625},\n",
       "     {'token_id': 74144,\n",
       "      'token_str': '-commercial',\n",
       "      'effect_magnitude': 0.2493896484375},\n",
       "     {'token_id': 38491,\n",
       "      'token_str': 'leader',\n",
       "      'effect_magnitude': 0.2469482421875},\n",
       "     {'token_id': 78048,\n",
       "      'token_str': ' YE',\n",
       "      'effect_magnitude': 0.24658203125},\n",
       "     {'token_id': 29365,\n",
       "      'token_str': 'HashCode',\n",
       "      'effect_magnitude': 0.2464599609375},\n",
       "     {'token_id': 7808,\n",
       "      'token_str': ' leader',\n",
       "      'effect_magnitude': 0.2462158203125},\n",
       "     {'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.244384765625}],\n",
       "    'top_suppressed': [{'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.266845703125},\n",
       "     {'token_id': 22321,\n",
       "      'token_str': 'artz',\n",
       "      'effect_magnitude': -0.259765625},\n",
       "     {'token_id': 11287,\n",
       "      'token_str': 'iginal',\n",
       "      'effect_magnitude': -0.2548828125},\n",
       "     {'token_id': 86020,\n",
       "      'token_str': 'USES',\n",
       "      'effect_magnitude': -0.253662109375},\n",
       "     {'token_id': 67545,\n",
       "      'token_str': 'arie',\n",
       "      'effect_magnitude': -0.2498779296875},\n",
       "     {'token_id': 27919,\n",
       "      'token_str': 'egral',\n",
       "      'effect_magnitude': -0.2496337890625},\n",
       "     {'token_id': 4428,\n",
       "      'token_str': 'ato',\n",
       "      'effect_magnitude': -0.2425537109375},\n",
       "     {'token_id': 3299, 'token_str': 'ï¿½ï¿½', 'effect_magnitude': -0.2421875},\n",
       "     {'token_id': 26518,\n",
       "      'token_str': ' bang',\n",
       "      'effect_magnitude': -0.239990234375},\n",
       "     {'token_id': 27197,\n",
       "      'token_str': 'erie',\n",
       "      'effect_magnitude': -0.2392578125}]},\n",
       "   'effect_magnitude': 20.78125,\n",
       "   'cumulative_magnitude': 153.9431915283203,\n",
       "   'amplification_factor': 5.1171875},\n",
       "  24: {'residual_magnitude': 4.265625,\n",
       "   'direct_vocab_effect': array([-0.05664,  0.02016, -0.00402, ...,  0.01929,  0.01929,  0.01929],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.05613899, 0.39754772, 0.38356304, ..., 0.03990424, 0.03990638,\n",
       "          0.03991854], dtype=float32),\n",
       "   'statistics': {'mean': -0.004215240478515625,\n",
       "    'std': 0.06121826171875,\n",
       "    'variance': 0.00374603271484375,\n",
       "    'kurtosis': 0.21538404104844444,\n",
       "    'skew': -0.056673397510153725,\n",
       "    'max_effect': 0.280517578125,\n",
       "    'min_effect': -0.282958984375,\n",
       "    'num_positive': 61315,\n",
       "    'num_negative': 66941,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 38491,\n",
       "      'token_str': 'leader',\n",
       "      'effect_magnitude': 0.280517578125},\n",
       "     {'token_id': 99376,\n",
       "      'token_str': '(\"<?',\n",
       "      'effect_magnitude': 0.2802734375},\n",
       "     {'token_id': 23896,\n",
       "      'token_str': ' Leader',\n",
       "      'effect_magnitude': 0.271240234375},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.270263671875},\n",
       "     {'token_id': 7808,\n",
       "      'token_str': ' leader',\n",
       "      'effect_magnitude': 0.268798828125},\n",
       "     {'token_id': 53721,\n",
       "      'token_str': 'Leader',\n",
       "      'effect_magnitude': 0.263916015625},\n",
       "     {'token_id': 29365,\n",
       "      'token_str': 'HashCode',\n",
       "      'effect_magnitude': 0.2587890625},\n",
       "     {'token_id': 90876,\n",
       "      'token_str': 'iguiente',\n",
       "      'effect_magnitude': 0.256103515625},\n",
       "     {'token_id': 8899,\n",
       "      'token_str': '118',\n",
       "      'effect_magnitude': 0.256103515625},\n",
       "     {'token_id': 83419,\n",
       "      'token_str': '_CHARS',\n",
       "      'effect_magnitude': 0.252197265625}],\n",
       "    'top_suppressed': [{'token_id': 48385,\n",
       "      'token_str': 'nesty',\n",
       "      'effect_magnitude': -0.282958984375},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.279052734375},\n",
       "     {'token_id': 22321,\n",
       "      'token_str': 'artz',\n",
       "      'effect_magnitude': -0.27880859375},\n",
       "     {'token_id': 86020,\n",
       "      'token_str': 'USES',\n",
       "      'effect_magnitude': -0.271728515625},\n",
       "     {'token_id': 26518,\n",
       "      'token_str': ' bang',\n",
       "      'effect_magnitude': -0.270263671875},\n",
       "     {'token_id': 32015,\n",
       "      'token_str': ' nerve',\n",
       "      'effect_magnitude': -0.266357421875},\n",
       "     {'token_id': 57949,\n",
       "      'token_str': ' thumbs',\n",
       "      'effect_magnitude': -0.263671875},\n",
       "     {'token_id': 67545,\n",
       "      'token_str': 'arie',\n",
       "      'effect_magnitude': -0.261962890625},\n",
       "     {'token_id': 20670, 'token_str': 'they', 'effect_magnitude': -0.26171875},\n",
       "     {'token_id': 53743,\n",
       "      'token_str': 'ascus',\n",
       "      'effect_magnitude': -0.260986328125}]},\n",
       "   'effect_magnitude': 21.96875,\n",
       "   'cumulative_magnitude': 171.08876037597656,\n",
       "   'amplification_factor': 5.1484375},\n",
       "  25: {'residual_magnitude': 4.50390625,\n",
       "   'direct_vocab_effect': array([-0.0531  ,  0.01602 , -0.002522, ...,  0.01521 ,  0.01522 ,\n",
       "           0.01521 ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.00303841, 0.41356945, 0.38104153, ..., 0.05511725, 0.05512702,\n",
       "          0.05513155], dtype=float32),\n",
       "   'statistics': {'mean': -0.0156402587890625,\n",
       "    'std': 0.06573486328125,\n",
       "    'variance': 0.0043182373046875,\n",
       "    'kurtosis': 0.19644395609884002,\n",
       "    'skew': -0.052302168293697264,\n",
       "    'max_effect': 0.2939453125,\n",
       "    'min_effect': -0.33154296875,\n",
       "    'num_positive': 52381,\n",
       "    'num_negative': 75875,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.2939453125},\n",
       "     {'token_id': 8899, 'token_str': '118', 'effect_magnitude': 0.28369140625},\n",
       "     {'token_id': 32755,\n",
       "      'token_str': ' Led',\n",
       "      'effect_magnitude': 0.281982421875},\n",
       "     {'token_id': 29365,\n",
       "      'token_str': 'HashCode',\n",
       "      'effect_magnitude': 0.277099609375},\n",
       "     {'token_id': 90876,\n",
       "      'token_str': 'iguiente',\n",
       "      'effect_magnitude': 0.2763671875},\n",
       "     {'token_id': 19944, 'token_str': '608', 'effect_magnitude': 0.2744140625},\n",
       "     {'token_id': 24380,\n",
       "      'token_str': '591',\n",
       "      'effect_magnitude': 0.25146484375},\n",
       "     {'token_id': 71964, 'token_str': ' Telecom', 'effect_magnitude': 0.25},\n",
       "     {'token_id': 115972,\n",
       "      'token_str': ' â€“\\n',\n",
       "      'effect_magnitude': 0.246337890625},\n",
       "     {'token_id': 107781,\n",
       "      'token_str': 'à¹‚à¸•',\n",
       "      'effect_magnitude': 0.2462158203125}],\n",
       "    'top_suppressed': [{'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.33154296875},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.310791015625},\n",
       "     {'token_id': 57949,\n",
       "      'token_str': ' thumbs',\n",
       "      'effect_magnitude': -0.306640625},\n",
       "     {'token_id': 26518,\n",
       "      'token_str': ' bang',\n",
       "      'effect_magnitude': -0.303466796875},\n",
       "     {'token_id': 106272,\n",
       "      'token_str': 'ãªãŒã‚‰',\n",
       "      'effect_magnitude': -0.300537109375},\n",
       "     {'token_id': 48385,\n",
       "      'token_str': 'nesty',\n",
       "      'effect_magnitude': -0.30029296875},\n",
       "     {'token_id': 76466,\n",
       "      'token_str': 'asl',\n",
       "      'effect_magnitude': -0.299560546875},\n",
       "     {'token_id': 50520,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': -0.295654296875},\n",
       "     {'token_id': 27197,\n",
       "      'token_str': 'erie',\n",
       "      'effect_magnitude': -0.287353515625},\n",
       "     {'token_id': 67545,\n",
       "      'token_str': 'arie',\n",
       "      'effect_magnitude': -0.287109375}]},\n",
       "   'effect_magnitude': 24.1875,\n",
       "   'cumulative_magnitude': 191.09555053710938,\n",
       "   'amplification_factor': 5.37109375},\n",
       "  26: {'residual_magnitude': 4.765625,\n",
       "   'direct_vocab_effect': array([ 0.002104,  0.0412  ,  0.0206  , ..., -0.012215, -0.012215,\n",
       "          -0.012215], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([0.00514221, 0.45476818, 0.4016409 , ..., 0.04290259, 0.04291236,\n",
       "          0.04291689], dtype=float32),\n",
       "   'statistics': {'mean': -0.0499267578125,\n",
       "    'std': 0.07684326171875,\n",
       "    'variance': 0.0059051513671875,\n",
       "    'kurtosis': 0.1963891058897369,\n",
       "    'skew': -0.06094688771259997,\n",
       "    'max_effect': 0.320068359375,\n",
       "    'min_effect': -0.421142578125,\n",
       "    'num_positive': 32531,\n",
       "    'num_negative': 95725,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.320068359375},\n",
       "     {'token_id': 90578,\n",
       "      'token_str': 'â€¦\\n',\n",
       "      'effect_magnitude': 0.317626953125},\n",
       "     {'token_id': 115235,\n",
       "      'token_str': '\\xa0in',\n",
       "      'effect_magnitude': 0.300048828125},\n",
       "     {'token_id': 8899,\n",
       "      'token_str': '118',\n",
       "      'effect_magnitude': 0.281494140625},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.273681640625},\n",
       "     {'token_id': 117054,\n",
       "      'token_str': ' â€¦\\n',\n",
       "      'effect_magnitude': 0.267578125},\n",
       "     {'token_id': 24380,\n",
       "      'token_str': '591',\n",
       "      'effect_magnitude': 0.257080078125},\n",
       "     {'token_id': 2539,\n",
       "      'token_str': ' full',\n",
       "      'effect_magnitude': 0.253173828125},\n",
       "     {'token_id': 29959,\n",
       "      'token_str': ' Nice',\n",
       "      'effect_magnitude': 0.251708984375},\n",
       "     {'token_id': 32755,\n",
       "      'token_str': ' Led',\n",
       "      'effect_magnitude': 0.25048828125}],\n",
       "    'top_suppressed': [{'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.421142578125},\n",
       "     {'token_id': 76466,\n",
       "      'token_str': 'asl',\n",
       "      'effect_magnitude': -0.404541015625},\n",
       "     {'token_id': 50520,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': -0.396728515625},\n",
       "     {'token_id': 74611,\n",
       "      'token_str': ' poil',\n",
       "      'effect_magnitude': -0.390380859375},\n",
       "     {'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.3896484375},\n",
       "     {'token_id': 108354,\n",
       "      'token_str': 'ÅŸa',\n",
       "      'effect_magnitude': -0.383544921875},\n",
       "     {'token_id': 118915,\n",
       "      'token_str': 'Ð°Ð»ÑŽ',\n",
       "      'effect_magnitude': -0.38232421875},\n",
       "     {'token_id': 13661,\n",
       "      'token_str': ' explan',\n",
       "      'effect_magnitude': -0.381103515625},\n",
       "     {'token_id': 29943,\n",
       "      'token_str': ' pione',\n",
       "      'effect_magnitude': -0.3779296875},\n",
       "     {'token_id': 67545,\n",
       "      'token_str': 'arie',\n",
       "      'effect_magnitude': -0.376953125}]},\n",
       "   'effect_magnitude': 32.8125,\n",
       "   'cumulative_magnitude': 216.73167419433594,\n",
       "   'amplification_factor': 6.88671875},\n",
       "  27: {'residual_magnitude': 5.09765625,\n",
       "   'direct_vocab_effect': array([-0.04123 ,  0.05942 ,  0.012474, ..., -0.0124  , -0.0124  ,\n",
       "          -0.0124  ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([-0.03608704,  0.5141859 ,  0.41411495, ...,  0.03050482,\n",
       "           0.0305146 ,  0.03051913], dtype=float32),\n",
       "   'statistics': {'mean': -0.038421630859375,\n",
       "    'std': 0.077880859375,\n",
       "    'variance': 0.00606536865234375,\n",
       "    'kurtosis': 0.22741663700011872,\n",
       "    'skew': -0.04100885668856446,\n",
       "    'max_effect': 0.315673828125,\n",
       "    'min_effect': -0.429931640625,\n",
       "    'num_positive': 39274,\n",
       "    'num_negative': 88982,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 8899,\n",
       "      'token_str': '118',\n",
       "      'effect_magnitude': 0.315673828125},\n",
       "     {'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.315185546875},\n",
       "     {'token_id': 19944,\n",
       "      'token_str': '608',\n",
       "      'effect_magnitude': 0.295654296875},\n",
       "     {'token_id': 90578,\n",
       "      'token_str': 'â€¦\\n',\n",
       "      'effect_magnitude': 0.288818359375},\n",
       "     {'token_id': 15601,\n",
       "      'token_str': ' rein',\n",
       "      'effect_magnitude': 0.286376953125},\n",
       "     {'token_id': 2539,\n",
       "      'token_str': ' full',\n",
       "      'effect_magnitude': 0.282470703125},\n",
       "     {'token_id': 24380,\n",
       "      'token_str': '591',\n",
       "      'effect_magnitude': 0.279052734375},\n",
       "     {'token_id': 23606,\n",
       "      'token_str': ' complement',\n",
       "      'effect_magnitude': 0.277587890625},\n",
       "     {'token_id': 7058, 'token_str': '-\\n', 'effect_magnitude': 0.27734375},\n",
       "     {'token_id': 1054, 'token_str': ' â€œ', 'effect_magnitude': 0.27392578125}],\n",
       "    'top_suppressed': [{'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.429931640625},\n",
       "     {'token_id': 106272,\n",
       "      'token_str': 'ãªãŒã‚‰',\n",
       "      'effect_magnitude': -0.412841796875},\n",
       "     {'token_id': 76466, 'token_str': 'asl', 'effect_magnitude': -0.40234375},\n",
       "     {'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.397216796875},\n",
       "     {'token_id': 40848,\n",
       "      'token_str': 'htdocs',\n",
       "      'effect_magnitude': -0.386474609375},\n",
       "     {'token_id': 112689, 'token_str': 'lÃ½', 'effect_magnitude': -0.37890625},\n",
       "     {'token_id': 57949,\n",
       "      'token_str': ' thumbs',\n",
       "      'effect_magnitude': -0.36767578125},\n",
       "     {'token_id': 50520,\n",
       "      'token_str': 'ï¿½',\n",
       "      'effect_magnitude': -0.366455078125},\n",
       "     {'token_id': 127318,\n",
       "      'token_str': ' Ã¶rt',\n",
       "      'effect_magnitude': -0.366455078125},\n",
       "     {'token_id': 121865,\n",
       "      'token_str': ' dostan',\n",
       "      'effect_magnitude': -0.36474609375}]},\n",
       "   'effect_magnitude': 31.09375,\n",
       "   'cumulative_magnitude': 243.16470336914062,\n",
       "   'amplification_factor': 6.1015625},\n",
       "  28: {'residual_magnitude': 5.51953125,\n",
       "   'direct_vocab_effect': array([-0.0763  ,  0.04657 , -0.01331 , ...,  0.007347,  0.007347,\n",
       "           0.007347], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([-0.11238098,  0.5607557 ,  0.40080166, ...,  0.03785193,\n",
       "           0.0378617 ,  0.03786623], dtype=float32),\n",
       "   'statistics': {'mean': -0.0279998779296875,\n",
       "    'std': 0.0821533203125,\n",
       "    'variance': 0.00675201416015625,\n",
       "    'kurtosis': 0.25546298956238633,\n",
       "    'skew': -0.03244419704848397,\n",
       "    'max_effect': 0.5,\n",
       "    'min_effect': -0.437744140625,\n",
       "    'num_positive': 46985,\n",
       "    'num_negative': 81271,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.5},\n",
       "     {'token_id': 32755,\n",
       "      'token_str': ' Led',\n",
       "      'effect_magnitude': 0.401123046875},\n",
       "     {'token_id': 3063,\n",
       "      'token_str': ' lead',\n",
       "      'effect_magnitude': 0.392822265625},\n",
       "     {'token_id': 8899, 'token_str': '118', 'effect_magnitude': 0.34375},\n",
       "     {'token_id': 15601, 'token_str': ' rein', 'effect_magnitude': 0.33984375},\n",
       "     {'token_id': 21989,\n",
       "      'token_str': ' ruled',\n",
       "      'effect_magnitude': 0.324951171875},\n",
       "     {'token_id': 61950,\n",
       "      'token_str': 'Led',\n",
       "      'effect_magnitude': 0.31787109375},\n",
       "     {'token_id': 7058, 'token_str': '-\\n', 'effect_magnitude': 0.3037109375},\n",
       "     {'token_id': 23031,\n",
       "      'token_str': '996',\n",
       "      'effect_magnitude': 0.302978515625},\n",
       "     {'token_id': 23606,\n",
       "      'token_str': ' complement',\n",
       "      'effect_magnitude': 0.302490234375}],\n",
       "    'top_suppressed': [{'token_id': 76466,\n",
       "      'token_str': 'asl',\n",
       "      'effect_magnitude': -0.437744140625},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.4111328125},\n",
       "     {'token_id': 106272,\n",
       "      'token_str': 'ãªãŒã‚‰',\n",
       "      'effect_magnitude': -0.40966796875},\n",
       "     {'token_id': 40848,\n",
       "      'token_str': 'htdocs',\n",
       "      'effect_magnitude': -0.38671875},\n",
       "     {'token_id': 127318,\n",
       "      'token_str': ' Ã¶rt',\n",
       "      'effect_magnitude': -0.385986328125},\n",
       "     {'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.385009765625},\n",
       "     {'token_id': 2635, 'token_str': 'lex', 'effect_magnitude': -0.380859375},\n",
       "     {'token_id': 125443,\n",
       "      'token_str': 'ubu',\n",
       "      'effect_magnitude': -0.37548828125},\n",
       "     {'token_id': 50520, 'token_str': 'ï¿½', 'effect_magnitude': -0.375},\n",
       "     {'token_id': 112689,\n",
       "      'token_str': 'lÃ½',\n",
       "      'effect_magnitude': -0.37158203125}]},\n",
       "   'effect_magnitude': 31.09375,\n",
       "   'cumulative_magnitude': 269.9316101074219,\n",
       "   'amplification_factor': 5.6328125},\n",
       "  29: {'residual_magnitude': 6.1171875,\n",
       "   'direct_vocab_effect': array([ 0.02257  ,  0.05756  ,  0.0002127, ..., -0.03552  , -0.03552  ,\n",
       "          -0.03552  ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([-0.08981323,  0.6183119 ,  0.40101433, ...,  0.00232947,\n",
       "           0.00233924,  0.00234377], dtype=float32),\n",
       "   'statistics': {'mean': -0.08416748046875,\n",
       "    'std': 0.10699462890625,\n",
       "    'variance': 0.01145172119140625,\n",
       "    'kurtosis': 0.21971272982124734,\n",
       "    'skew': -0.060554065540474745,\n",
       "    'max_effect': 0.517578125,\n",
       "    'min_effect': -0.61181640625,\n",
       "    'num_positive': 27078,\n",
       "    'num_negative': 101178,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.517578125},\n",
       "     {'token_id': 115235,\n",
       "      'token_str': '\\xa0in',\n",
       "      'effect_magnitude': 0.450927734375},\n",
       "     {'token_id': 3063,\n",
       "      'token_str': ' lead',\n",
       "      'effect_magnitude': 0.442626953125},\n",
       "     {'token_id': 90578, 'token_str': 'â€¦\\n', 'effect_magnitude': 0.4052734375},\n",
       "     {'token_id': 32755,\n",
       "      'token_str': ' Led',\n",
       "      'effect_magnitude': 0.39404296875},\n",
       "     {'token_id': 1139,\n",
       "      'token_str': ' into',\n",
       "      'effect_magnitude': 0.38427734375},\n",
       "     {'token_id': 9522,\n",
       "      'token_str': '...\\n',\n",
       "      'effect_magnitude': 0.380615234375},\n",
       "     {'token_id': 15601,\n",
       "      'token_str': ' rein',\n",
       "      'effect_magnitude': 0.377685546875},\n",
       "     {'token_id': 38171,\n",
       "      'token_str': ' privately',\n",
       "      'effect_magnitude': 0.37548828125},\n",
       "     {'token_id': 96948,\n",
       "      'token_str': '-fontawesome',\n",
       "      'effect_magnitude': 0.366943359375}],\n",
       "    'top_suppressed': [{'token_id': 125761,\n",
       "      'token_str': ' tarif',\n",
       "      'effect_magnitude': -0.61181640625},\n",
       "     {'token_id': 13661,\n",
       "      'token_str': ' explan',\n",
       "      'effect_magnitude': -0.56982421875},\n",
       "     {'token_id': 76466,\n",
       "      'token_str': 'asl',\n",
       "      'effect_magnitude': -0.55712890625},\n",
       "     {'token_id': 100180,\n",
       "      'token_str': ' rekl',\n",
       "      'effect_magnitude': -0.55078125},\n",
       "     {'token_id': 39722,\n",
       "      'token_str': ' prostitu',\n",
       "      'effect_magnitude': -0.54931640625},\n",
       "     {'token_id': 76324, 'token_str': ' slik', 'effect_magnitude': -0.546875},\n",
       "     {'token_id': 126720,\n",
       "      'token_str': ' dÃ¡n',\n",
       "      'effect_magnitude': -0.54443359375},\n",
       "     {'token_id': 49452,\n",
       "      'token_str': ' porr',\n",
       "      'effect_magnitude': -0.53662109375},\n",
       "     {'token_id': 100951,\n",
       "      'token_str': 'Ã¡nh',\n",
       "      'effect_magnitude': -0.53076171875},\n",
       "     {'token_id': 63102,\n",
       "      'token_str': ' nackte',\n",
       "      'effect_magnitude': -0.52978515625}]},\n",
       "   'effect_magnitude': 48.75,\n",
       "   'cumulative_magnitude': 308.3067932128906,\n",
       "   'amplification_factor': 7.96875},\n",
       "  30: {'residual_magnitude': 6.9296875,\n",
       "   'direct_vocab_effect': array([ 0.11743,  0.1954 ,  0.07587, ..., -0.1804 , -0.1804 , -0.1804 ],\n",
       "         dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.02761841,  0.81374645,  0.47688103, ..., -0.17809045,\n",
       "          -0.17808068, -0.17807615], dtype=float32),\n",
       "   'statistics': {'mean': -0.174560546875,\n",
       "    'std': 0.140380859375,\n",
       "    'variance': 0.0196990966796875,\n",
       "    'kurtosis': 0.21697073405168732,\n",
       "    'skew': 0.04285751804426246,\n",
       "    'max_effect': 0.62158203125,\n",
       "    'min_effect': -0.7890625,\n",
       "    'num_positive': 13499,\n",
       "    'num_negative': 114757,\n",
       "    'num_significant': 0},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 6197,\n",
       "      'token_str': ' led',\n",
       "      'effect_magnitude': 0.62158203125},\n",
       "     {'token_id': 3063,\n",
       "      'token_str': ' lead',\n",
       "      'effect_magnitude': 0.5302734375},\n",
       "     {'token_id': 115235,\n",
       "      'token_str': '\\xa0in',\n",
       "      'effect_magnitude': 0.52587890625},\n",
       "     {'token_id': 90578, 'token_str': 'â€¦\\n', 'effect_magnitude': 0.5126953125},\n",
       "     {'token_id': 9522,\n",
       "      'token_str': '...\\n',\n",
       "      'effect_magnitude': 0.50146484375},\n",
       "     {'token_id': 35047,\n",
       "      'token_str': '..\\n',\n",
       "      'effect_magnitude': 0.495849609375},\n",
       "     {'token_id': 304, 'token_str': ' in', 'effect_magnitude': 0.495849609375},\n",
       "     {'token_id': 7058, 'token_str': '-\\n', 'effect_magnitude': 0.47705078125},\n",
       "     {'token_id': 198, 'token_str': '\\n', 'effect_magnitude': 0.4599609375},\n",
       "     {'token_id': 701, 'token_str': ' your', 'effect_magnitude': 0.458984375}],\n",
       "    'top_suppressed': [{'token_id': 104794,\n",
       "      'token_str': 'Ð½Ð¸Ð¼Ð°',\n",
       "      'effect_magnitude': -0.7890625},\n",
       "     {'token_id': 125225,\n",
       "      'token_str': 'ÐºÐ°Ð¿',\n",
       "      'effect_magnitude': -0.775390625},\n",
       "     {'token_id': 84677,\n",
       "      'token_str': ' meiden',\n",
       "      'effect_magnitude': -0.76904296875},\n",
       "     {'token_id': 83218,\n",
       "      'token_str': ' hete',\n",
       "      'effect_magnitude': -0.75830078125},\n",
       "     {'token_id': 100180,\n",
       "      'token_str': ' rekl',\n",
       "      'effect_magnitude': -0.751953125},\n",
       "     {'token_id': 76324,\n",
       "      'token_str': ' slik',\n",
       "      'effect_magnitude': -0.73828125},\n",
       "     {'token_id': 57420,\n",
       "      'token_str': '.Dictionary',\n",
       "      'effect_magnitude': -0.73828125},\n",
       "     {'token_id': 125761,\n",
       "      'token_str': ' tarif',\n",
       "      'effect_magnitude': -0.736328125},\n",
       "     {'token_id': 126720,\n",
       "      'token_str': ' dÃ¡n',\n",
       "      'effect_magnitude': -0.7314453125},\n",
       "     {'token_id': 76466,\n",
       "      'token_str': 'asl',\n",
       "      'effect_magnitude': -0.728515625}]},\n",
       "   'effect_magnitude': 80.25,\n",
       "   'cumulative_magnitude': 368.1836853027344,\n",
       "   'amplification_factor': 11.578125},\n",
       "  31: {'residual_magnitude': 11.3671875,\n",
       "   'direct_vocab_effect': array([ 0.292   ,  0.329   , -0.003242, ..., -0.9526  , -0.9526  ,\n",
       "          -0.9526  ], dtype=float16),\n",
       "   'cumulative_vocab_effect': array([ 0.3196106 ,  1.142848  ,  0.47363853, ..., -1.1307272 ,\n",
       "          -1.1307174 , -1.1307129 ], dtype=float32),\n",
       "   'statistics': {'mean': -0.654296875,\n",
       "    'std': 0.2783203125,\n",
       "    'variance': 0.07745361328125,\n",
       "    'kurtosis': 0.3472842424773077,\n",
       "    'skew': 0.4909124095694298,\n",
       "    'max_effect': 1.044921875,\n",
       "    'min_effect': -1.6318359375,\n",
       "    'num_positive': 2350,\n",
       "    'num_negative': 125906,\n",
       "    'num_significant': 10786},\n",
       "   'top_tokens': {'top_boosted': [{'token_id': 220,\n",
       "      'token_str': ' ',\n",
       "      'effect_magnitude': 1.044921875},\n",
       "     {'token_id': 11, 'token_str': ',', 'effect_magnitude': 1.013671875},\n",
       "     {'token_id': 4194, 'token_str': '\\xa0', 'effect_magnitude': 0.9892578125},\n",
       "     {'token_id': 198, 'token_str': '\\n', 'effect_magnitude': 0.94775390625},\n",
       "     {'token_id': 304, 'token_str': ' in', 'effect_magnitude': 0.88037109375},\n",
       "     {'token_id': 320, 'token_str': ' (', 'effect_magnitude': 0.86181640625},\n",
       "     {'token_id': 330, 'token_str': ' \"', 'effect_magnitude': 0.70654296875},\n",
       "     {'token_id': 264, 'token_str': ' a', 'effect_magnitude': 0.701171875},\n",
       "     {'token_id': 482, 'token_str': ' -', 'effect_magnitude': 0.68896484375},\n",
       "     {'token_id': 12, 'token_str': '-', 'effect_magnitude': 0.67578125}],\n",
       "    'top_suppressed': [{'token_id': 40729,\n",
       "      'token_str': '\\tTokenName',\n",
       "      'effect_magnitude': -1.6318359375},\n",
       "     {'token_id': 82836,\n",
       "      'token_str': 'Intialized',\n",
       "      'effect_magnitude': -1.609375},\n",
       "     {'token_id': 31112,\n",
       "      'token_str': 'esModule',\n",
       "      'effect_magnitude': -1.6005859375},\n",
       "     {'token_id': 49452,\n",
       "      'token_str': ' porr',\n",
       "      'effect_magnitude': -1.5966796875},\n",
       "     {'token_id': 57280,\n",
       "      'token_str': ' prostitut',\n",
       "      'effect_magnitude': -1.5927734375},\n",
       "     {'token_id': 125067,\n",
       "      'token_str': 'loub',\n",
       "      'effect_magnitude': -1.591796875},\n",
       "     {'token_id': 122646,\n",
       "      'token_str': 'å‡ºå“è€…',\n",
       "      'effect_magnitude': -1.5830078125},\n",
       "     {'token_id': 65053,\n",
       "      'token_str': 'ç›‘å¬é¡µé¢',\n",
       "      'effect_magnitude': -1.572265625},\n",
       "     {'token_id': 84845,\n",
       "      'token_str': 'PostalCodes',\n",
       "      'effect_magnitude': -1.568359375},\n",
       "     {'token_id': 70919,\n",
       "      'token_str': '_OW',\n",
       "      'effect_magnitude': -1.568359375}]},\n",
       "   'effect_magnitude': 254.75,\n",
       "   'cumulative_magnitude': 559.687255859375,\n",
       "   'amplification_factor': 22.40625}},\n",
       " 'accumulation_analysis': {'accumulation_pattern': 'non_linear',\n",
       "  'cumulative_trajectory': [0.0,\n",
       "   0.5997748970985413,\n",
       "   3.228803873062134,\n",
       "   7.812350273132324,\n",
       "   13.024007797241211,\n",
       "   18.205337524414062,\n",
       "   23.102645874023438,\n",
       "   27.643795013427734,\n",
       "   32.456153869628906,\n",
       "   37.33309555053711,\n",
       "   42.083133697509766,\n",
       "   46.77621078491211,\n",
       "   51.56418228149414,\n",
       "   56.444332122802734,\n",
       "   62.60988235473633,\n",
       "   68.78170013427734,\n",
       "   74.5765380859375,\n",
       "   81.9898910522461,\n",
       "   90.71671295166016,\n",
       "   101.5077133178711,\n",
       "   111.97415924072266,\n",
       "   124.61468505859375,\n",
       "   138.55255126953125,\n",
       "   153.9431915283203,\n",
       "   171.08876037597656,\n",
       "   191.09555053710938,\n",
       "   216.73167419433594,\n",
       "   243.16470336914062,\n",
       "   269.9316101074219,\n",
       "   308.3067932128906,\n",
       "   368.1836853027344,\n",
       "   559.687255859375],\n",
       "  'direct_contributions': [0.0,\n",
       "   0.599609375,\n",
       "   3.142578125,\n",
       "   5.76171875,\n",
       "   6.7265625,\n",
       "   7.25,\n",
       "   6.94140625,\n",
       "   7.43359375,\n",
       "   7.9765625,\n",
       "   8.5078125,\n",
       "   8.3359375,\n",
       "   8.65625,\n",
       "   8.875,\n",
       "   10.015625,\n",
       "   12.6484375,\n",
       "   11.4765625,\n",
       "   11.5390625,\n",
       "   12.0703125,\n",
       "   13.5234375,\n",
       "   15.5859375,\n",
       "   15.453125,\n",
       "   17.734375,\n",
       "   19.125,\n",
       "   20.78125,\n",
       "   21.96875,\n",
       "   24.1875,\n",
       "   32.8125,\n",
       "   31.09375,\n",
       "   31.09375,\n",
       "   48.75,\n",
       "   80.25,\n",
       "   254.75],\n",
       "  'significant_layers': [26, 27, 28, 29, 30, 31],\n",
       "  'total_accumulation': 559.687255859375,\n",
       "  'average_growth_rate': 1.3533446825674402},\n",
       " 'amplification_analysis': {'amplification_factors': [0.0,\n",
       "   7.11328125,\n",
       "   5.1875,\n",
       "   5.01171875,\n",
       "   5.02734375,\n",
       "   5.11328125,\n",
       "   4.98828125,\n",
       "   4.9453125,\n",
       "   4.9453125,\n",
       "   5.078125,\n",
       "   4.9609375,\n",
       "   4.984375,\n",
       "   5.04296875,\n",
       "   5.421875,\n",
       "   6.1953125,\n",
       "   5.296875,\n",
       "   4.98046875,\n",
       "   5.125,\n",
       "   5.28125,\n",
       "   5.58203125,\n",
       "   5.0703125,\n",
       "   5.171875,\n",
       "   5.140625,\n",
       "   5.1171875,\n",
       "   5.1484375,\n",
       "   5.37109375,\n",
       "   6.88671875,\n",
       "   6.1015625,\n",
       "   5.6328125,\n",
       "   7.96875,\n",
       "   11.578125,\n",
       "   22.40625],\n",
       "  'average_amplification': 5.99609375,\n",
       "  'max_amplification': 22.40625,\n",
       "  'high_amplification_layers': [1,\n",
       "   2,\n",
       "   3,\n",
       "   4,\n",
       "   5,\n",
       "   6,\n",
       "   7,\n",
       "   8,\n",
       "   9,\n",
       "   10,\n",
       "   11,\n",
       "   12,\n",
       "   13,\n",
       "   14,\n",
       "   15,\n",
       "   16,\n",
       "   17,\n",
       "   18,\n",
       "   19,\n",
       "   20,\n",
       "   21,\n",
       "   22,\n",
       "   23,\n",
       "   24,\n",
       "   25,\n",
       "   26,\n",
       "   27,\n",
       "   28,\n",
       "   29,\n",
       "   30,\n",
       "   31],\n",
       "  'dampening_layers': [0],\n",
       "  'amplification_pattern': 'amplifying'},\n",
       " 'summary': {'analysis_type': 'residual_stream',\n",
       "  'total_layers_analyzed': 32,\n",
       "  'peak_effect_layer': 31,\n",
       "  'final_effect_magnitude': 559.687255859375,\n",
       "  'magnitude_range': [0.0, 559.687255859375],\n",
       "  'effect_evolution': 'increasing'}}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "residual_stream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity and Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 16:12:08,000 - SuperWeightManager_140164721294544 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 16:12:16,832 - SuperWeightManager_140164721294544 - INFO - Restored 1/1 weights\n"
     ]
    }
   ],
   "source": [
    "perplexity_impact = session.analyzer.metrics_analyzer.measure_perplexity_impact(sw[0], n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_perplexity': 10.63492488861084,\n",
       " 'modified_perplexity': 5289.5185546875,\n",
       " 'perplexity_ratio': 497.3724412809116,\n",
       " 'perplexity_increase': 5278.883629798889,\n",
       " 'impact_severity': 'catastrophic',\n",
       " 'dataset_info': {'name': 'wikitext',\n",
       "  'config': 'wikitext-2-raw-v1',\n",
       "  'split': 'test',\n",
       "  'n_samples': 100},\n",
       " 'super_weight': SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 mlp.down_proj.weight[788, 2427]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:58:02,444 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 13:58:49,356 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity impact for Layer 1 mlp.down_proj.weight[788, 2427]: {'baseline_perplexity': 11.002143859863281, 'modified_perplexity': 11.295992851257324, 'perplexity_ratio': 1.0267083393143066, 'perplexity_increase': 0.29384899139404297, 'impact_severity': 'minimal', 'dataset_info': {'name': 'wikitext', 'config': 'wikitext-2-raw-v1', 'split': 'test', 'n_samples': 500}, 'super_weight': SuperWeight(layer=1, coords=[788, 2427], input=-443.50, output=300.50)}\n",
      "Layer 31 mlp.down_proj.weight[788, 12111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:59:38,902 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 14:00:25,809 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity impact for Layer 31 mlp.down_proj.weight[788, 12111]: {'baseline_perplexity': 11.002143859863281, 'modified_perplexity': 11.023534774780273, 'perplexity_ratio': 1.0019442497016449, 'perplexity_increase': 0.021390914916992188, 'impact_severity': 'minimal', 'dataset_info': {'name': 'wikitext', 'config': 'wikitext-2-raw-v1', 'split': 'test', 'n_samples': 500}, 'super_weight': SuperWeight(layer=31, coords=[788, 12111], input=151.00, output=-299.75)}\n"
     ]
    }
   ],
   "source": [
    "for super_weight in sw:\n",
    "    print(super_weight)\n",
    "    ppl_res = session.analyzer.metrics_analyzer.measure_perplexity_impact(super_weight, n_samples=500)\n",
    "    print(f\"Perplexity impact for {super_weight}: {ppl_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 14:16:07,042 - SuperWeightManager_139901044718128 - INFO - Successfully scaled 2/2 super weights by 0.000\n",
      "2025-07-04 14:16:51,120 - SuperWeightManager_139901044718128 - INFO - Restored 2/2 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity impact for all super weights: {'baseline_perplexity': 9.51281452178955, 'modified_perplexity': 4830.10791015625, 'perplexity_ratio': 507.7475124835725, 'perplexity_increase': 4820.59509563446, 'impact_severity': 'catastrophic', 'dataset_info': {'name': 'wikitext', 'config': 'wikitext-2-raw-v1', 'split': 'test', 'n_samples': 500}, 'super_weights': [SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75), SuperWeight(layer=31, coords=[53, 2187], input=-906.00, output=-84.50)], 'num_weights': 2, 'average_impact_per_weight': 2410.29754781723}\n"
     ]
    }
   ],
   "source": [
    "# check impact of all super weights at once\n",
    "all_sw_ppl = session.analyzer.metrics_analyzer.measure_perplexity_impact(sw, n_samples=500)\n",
    "print(f\"Perplexity impact for all super weights: {all_sw_ppl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 14:18:35,674 - SuperWeightManager_139901044718128 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 14:19:04,362 - SuperWeightManager_139901044718128 - INFO - Restored 1/1 weights\n"
     ]
    }
   ],
   "source": [
    "accuracy_impact = session.analyzer.metrics_analyzer.measure_accuracy_impact(sw[0], n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'hellaswag',\n",
       " 'baseline_accuracy': 0.64,\n",
       " 'modified_accuracy': 0.33,\n",
       " 'accuracy_drop': 0.31,\n",
       " 'accuracy_ratio': 0.515625,\n",
       " 'impact_severity': 'severe',\n",
       " 'n_samples': 100,\n",
       " 'super_weight': SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 mlp.down_proj.weight[1764, 1710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 01:51:27,451 - SuperWeightManager_13442570496 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-06-10 01:52:12,462 - SuperWeightManager_13442570496 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy impact for Layer 1 mlp.down_proj.weight[1764, 1710]: {'super_weight': SuperWeight(layer=1, coords=[1764, 1710], input=-401.50, output=-262.00), 'task': 'hellaswag', 'baseline_accuracy': 0.475, 'modified_accuracy': 0.355, 'accuracy_drop': 0.12, 'accuracy_ratio': 0.7473684210526316, 'impact_severity': 'moderate', 'n_samples': 200}\n",
      "Layer 3 mlp.down_proj.weight[1764, 1902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 01:52:59,266 - SuperWeightManager_13442570496 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-06-10 01:53:44,296 - SuperWeightManager_13442570496 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy impact for Layer 3 mlp.down_proj.weight[1764, 1902]: {'super_weight': SuperWeight(layer=3, coords=[1764, 1902], input=-63.56, output=-64.69), 'task': 'hellaswag', 'baseline_accuracy': 0.475, 'modified_accuracy': 0.465, 'accuracy_drop': 0.009999999999999953, 'accuracy_ratio': 0.9789473684210527, 'impact_severity': 'minimal', 'n_samples': 200}\n",
      "Layer 15 mlp.down_proj.weight[1764, 6840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 01:54:30,827 - SuperWeightManager_13442570496 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-06-10 01:55:15,710 - SuperWeightManager_13442570496 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy impact for Layer 15 mlp.down_proj.weight[1764, 6840]: {'super_weight': SuperWeight(layer=15, coords=[1764, 6840], input=-283.00, output=415.00), 'task': 'hellaswag', 'baseline_accuracy': 0.475, 'modified_accuracy': 0.47, 'accuracy_drop': 0.0050000000000000044, 'accuracy_ratio': 0.9894736842105263, 'impact_severity': 'minimal', 'n_samples': 200}\n"
     ]
    }
   ],
   "source": [
    "for super_weight in sw:\n",
    "    print(super_weight)\n",
    "    acc_res = session.analyzer.metrics_analyzer.measure_accuracy_impact(super_weight, n_samples=200)\n",
    "    print(f\"Accuracy impact for {super_weight}: {acc_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Super Activation Source Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:01:32,736 - SuperWeightAnalyzer_13406117104 - INFO - Tracing activation source for Layer 1 mlp.down_proj.weight[1764, 1710]\n",
      "2025-06-17 18:01:34,246 - SuperWeightAnalyzer_13406117104 - INFO - DOWN PROJ INPUT channel 1710: max_val = 401.50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Activation Source Analysis:\n",
      "Pathway: Layer 1, Channel 1710\n",
      "Key findings: ['Massive amplification detected: 415.9x increase', 'Extremely large activation magnitude: 401.5', 'Gate and up projections contribute roughly equally']\n",
      "Total amplification: 415.9x\n",
      "\n",
      "ðŸ“ Top Contributing Tokens:\n",
      "  Apple: -401.5\n",
      "   company: -0.0\n",
      "   tech: 0.0\n",
      "   worldwide: 0.0\n",
      "   Inc: 0.0\n"
     ]
    }
   ],
   "source": [
    "trace_result = session.analyzer.trace_activation_source(sw[0])\n",
    "\n",
    "# Print the key findings\n",
    "print(\"ðŸ” Activation Source Analysis:\")\n",
    "print(f\"Pathway: {trace_result['pathway_analysis']['super_weight_location']}\")\n",
    "print(f\"Key findings: {trace_result['pathway_analysis']['key_findings']}\")\n",
    "print(f\"Total amplification: {trace_result['computational_flow']['amplification_factors']['total_amplification']:.1f}x\")\n",
    "\n",
    "# See which tokens contribute most\n",
    "print(\"\\nðŸ“ Top Contributing Tokens:\")\n",
    "for contrib in trace_result['token_contributions'][:5]:\n",
    "    print(f\"  {contrib['token']}: {contrib['activation_value']:.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'super_weight': SuperWeight(layer=1, coords=[1764, 1710], input=-401.50, output=-262.00),\n",
       " 'input_text': 'Apple Inc. is a worldwide tech company.',\n",
       " 'tokens': ['Apple',\n",
       "  ' Inc',\n",
       "  '.',\n",
       "  ' is',\n",
       "  ' a',\n",
       "  ' worldwide',\n",
       "  ' tech',\n",
       "  ' company',\n",
       "  '.'],\n",
       " 'pathway_analysis': {'super_weight_location': 'Layer 1, Channel 1710',\n",
       "  'pathway_status': 'complete',\n",
       "  'key_findings': ['Massive amplification detected: 415.9x increase',\n",
       "   'Extremely large activation magnitude: 401.5',\n",
       "   'Gate and up projections contribute roughly equally'],\n",
       "  'activation_magnitude_progression': {'input_magnitude': 0.96533203125,\n",
       "   'output_magnitude': 401.5,\n",
       "   'total_amplification_factor': 415.91906929691453}},\n",
       " 'token_contributions': [{'position': 0,\n",
       "   'token': 'Apple',\n",
       "   'activation_value': -401.5,\n",
       "   'absolute_activation': 401.5,\n",
       "   'is_max_contributor': True},\n",
       "  {'position': 7,\n",
       "   'token': ' company',\n",
       "   'activation_value': -0.00027060508728027344,\n",
       "   'absolute_activation': 0.00027060508728027344,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 6,\n",
       "   'token': ' tech',\n",
       "   'activation_value': 0.00015676021575927734,\n",
       "   'absolute_activation': 0.00015676021575927734,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 5,\n",
       "   'token': ' worldwide',\n",
       "   'activation_value': 3.057718276977539e-05,\n",
       "   'absolute_activation': 3.057718276977539e-05,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 1,\n",
       "   'token': ' Inc',\n",
       "   'activation_value': 2.4974346160888672e-05,\n",
       "   'absolute_activation': 2.4974346160888672e-05,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 8,\n",
       "   'token': '.',\n",
       "   'activation_value': -2.3245811462402344e-06,\n",
       "   'absolute_activation': 2.3245811462402344e-06,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 4,\n",
       "   'token': ' a',\n",
       "   'activation_value': 4.172325134277344e-07,\n",
       "   'absolute_activation': 4.172325134277344e-07,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 2,\n",
       "   'token': '.',\n",
       "   'activation_value': 5.960464477539063e-08,\n",
       "   'absolute_activation': 5.960464477539063e-08,\n",
       "   'is_max_contributor': False},\n",
       "  {'position': 3,\n",
       "   'token': ' is',\n",
       "   'activation_value': 0.0,\n",
       "   'absolute_activation': 0.0,\n",
       "   'is_max_contributor': False}],\n",
       " 'computational_flow': {'activation_amplification_stages': {'stage_1_mlp_input': 0.96533203125,\n",
       "   'stage_2_gate_proj': 21.890625,\n",
       "   'stage_3_up_proj': 26.34375,\n",
       "   'stage_4_hadamard_result': 401.5,\n",
       "   'final_super_weight_output': 'unknown'},\n",
       "  'critical_computation_step': 'both_gate_and_up_amplification',\n",
       "  'amplification_factors': {'mlp_input_to_gate': 22.67678300455235,\n",
       "   'mlp_input_to_up': 27.289833080424888,\n",
       "   'gate_times_up_efficiency': 0.6962252856161883,\n",
       "   'total_amplification': 415.91906929691453}}}"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trace_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-17 18:11:50,404 - SuperWeightAnalyzer_13406117104 - INFO - Tracing backwards to find source of super activation for Layer 1 mlp.down_proj.weight[1764, 1710]\n",
      "2025-06-17 18:11:51,313 - SuperWeightAnalyzer_13406117104 - INFO - ðŸŽ¯ Layer 0 final output channel 1710: max = 0.047\n"
     ]
    }
   ],
   "source": [
    "# trace activation backwards\n",
    "backward_trase_result = session.analyzer.trace_activation_backwards(sw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'super_weight': SuperWeight(layer=1, coords=[1764, 1710], input=-401.50, output=-262.00),\n",
       " 'input_text': 'Apple Inc. is a worldwide tech company.',\n",
       " 'tokens': ['Apple',\n",
       "  ' Inc',\n",
       "  '.',\n",
       "  ' is',\n",
       "  ' a',\n",
       "  ' worldwide',\n",
       "  ' tech',\n",
       "  ' company',\n",
       "  '.'],\n",
       " 'source_analysis': {'progression_summary': [{'component': 'Input Embeddings',\n",
       "    'max_magnitude': 0.0076751708984375,\n",
       "    'max_position': 5},\n",
       "   {'component': 'Layer 0 Attention Output',\n",
       "    'max_magnitude': 0.0266571044921875,\n",
       "    'max_position': 7},\n",
       "   {'component': 'Layer 0 MLP Output',\n",
       "    'max_magnitude': 0.048309326171875,\n",
       "    'max_position': 6},\n",
       "   {'component': 'Layer 0 Final Output (â†’ Layer 1 Input)',\n",
       "    'max_magnitude': 0.04656982421875,\n",
       "    'max_position': 6},\n",
       "   {'component': 'Layer 1 Attention Output',\n",
       "    'max_magnitude': 0.050628662109375,\n",
       "    'max_position': 0}],\n",
       "  'major_amplification_steps': [],\n",
       "  'source_identification': 'Input Embeddings',\n",
       "  'key_insights': ['Total amplification from source: 6.6x']},\n",
       " 'component_contributions': {'input_embeddings': {'values': array([-0.002655 , -0.007317 , -0.0001656, -0.003    ,  0.00448  ,\n",
       "           0.007675 , -0.007195 ,  0.007473 , -0.0001656], dtype=float16),\n",
       "   'max_magnitude': 0.0076751708984375,\n",
       "   'max_position': 5,\n",
       "   'component_name': 'Input Embeddings'},\n",
       "  'layer0_attention_output': {'values': array([ 2.351e-02, -1.836e-03, -1.386e-02,  6.577e-03, -8.529e-05,\n",
       "          -3.733e-03,  8.926e-03,  2.666e-02,  5.310e-03], dtype=float16),\n",
       "   'max_magnitude': 0.0266571044921875,\n",
       "   'max_position': 7,\n",
       "   'component_name': 'Layer 0 Attention Output'},\n",
       "  'layer0_mlp_output': {'values': array([-0.01279 ,  0.004772,  0.00652 , -0.01604 ,  0.01564 ,  0.02968 ,\n",
       "          -0.0483  , -0.004337, -0.01142 ], dtype=float16),\n",
       "   'max_magnitude': 0.048309326171875,\n",
       "   'max_position': 6,\n",
       "   'component_name': 'Layer 0 MLP Output'},\n",
       "  'layer0_final_output': {'values': array([ 0.00807 , -0.004383, -0.00751 , -0.01246 ,  0.02003 ,  0.03363 ,\n",
       "          -0.04657 ,  0.02979 , -0.006275], dtype=float16),\n",
       "   'max_magnitude': 0.04656982421875,\n",
       "   'max_position': 6,\n",
       "   'component_name': 'Layer 0 Final Output (â†’ Layer 1 Input)'},\n",
       "  'target_layer_attention_output': {'values': array([-0.05063 ,  0.02242 , -0.02399 ,  0.003202, -0.014145,  0.01148 ,\n",
       "           0.03055 , -0.01472 , -0.02191 ], dtype=float16),\n",
       "   'max_magnitude': 0.050628662109375,\n",
       "   'max_position': 0,\n",
       "   'component_name': 'Layer 1 Attention Output'}}}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backward_trase_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperWeight(layer=1, coords=[1764, 1710], input=-401.50, output=-262.00)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding strategies for zero activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 18:11:04,615 - SuperWeightAnalyzer_139739727050640 - INFO - Mathematical super activation analysis for Layer 1 mlp.down_proj.weight[2070, 7310]\n",
      "2025-07-04 18:11:04,616 - SuperActivationAnalyzer_139739750062816 - INFO - Super activation analysis for Layer 1 mlp.down_proj.weight[2070, 7310]\n",
      "2025-07-04 18:11:04,617 - SuperActivationAnalyzer_139739750062816 - INFO - Detected architecture: MLPArchitectureType.GATED_MLP\n"
     ]
    }
   ],
   "source": [
    "mathematical_analysis = session.analyzer.mathematical_super_activation_analysis(sw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_analysis': {'input_vector_shape': [4096],\n",
       "  'input_magnitude': 43.28125,\n",
       "  'input_mean': -0.012725830078125,\n",
       "  'input_std': 0.67626953125},\n",
       " 'step1_gate_projection': {'operation': 'gate_output = W_gate @ x',\n",
       "  'bias_term': None,\n",
       "  'result_target_channel': 32.0625,\n",
       "  'has_bias': False},\n",
       " 'step2_activation': {'operation': 'activated_gate = SILU(gate_output)',\n",
       "  'input_to_activation': 32.0625,\n",
       "  'activation_output_target_channel': 32.0625,\n",
       "  'activation_function': 'silu',\n",
       "  'activation_derivative_at_point': 1.0},\n",
       " 'step3_up_projection': {'operation': 'up_output = W_up @ x',\n",
       "  'bias_term': None,\n",
       "  'result_target_channel': 29.625,\n",
       "  'has_bias': False},\n",
       " 'step4_hadamard_product': {'operation': 'hadamard_result = activated_gate âŠ™ up_output (ELEMENT-WISE MULTIPLICATION)',\n",
       "  'activated_gate_component': 32.0625,\n",
       "  'up_output_component': 29.625,\n",
       "  'super_activation_result': 950.0,\n",
       "  'formula': 'y[:, 7310] = SILU(W_gate[7310] @ x) * (W_up[7310] @ x)',\n",
       "  'this_is_where_super_activation_is_created': True},\n",
       " 'step5_down_projection': {'operation': 'final_output = W_down @ hadamard_result',\n",
       "  'super_weight_row': 2070,\n",
       "  'super_weight_processes_super_activation': 950.0,\n",
       "  'super_weight_contribution': -262.75,\n",
       "  'has_bias': False},\n",
       " 'verification': {'computed_super_activation': 950.0,\n",
       "  'super_activation_magnitude': 950.0,\n",
       "  'super_activation_sign': 'positive',\n",
       "  'expected_vs_actual': 'Expected ~950.0, Computed: 950.00'}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_analysis['mathematical_breakdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_channel_info': {'channel_index': 7310,\n",
       "  'description': 'Channel 7310 in intermediate space where super activation occurs'},\n",
       " 'gate_weights_analysis': {'operation': 'gate_output[7310] = W_gate[7310] @ x',\n",
       "  'weight_vector_norm': 1.4599609375,\n",
       "  'max_weight': 0.19921875,\n",
       "  'min_weight': -0.2294921875,\n",
       "  'mean_weight': -0.00012695789337158203,\n",
       "  'std_weight': 0.0228118896484375,\n",
       "  'bias_term': None,\n",
       "  'top_5_positive_weights': [{'dimension': 188, 'weight': 0.19921875},\n",
       "   {'dimension': 1528, 'weight': 0.14453125},\n",
       "   {'dimension': 684, 'weight': 0.138671875},\n",
       "   {'dimension': 3830, 'weight': 0.1240234375},\n",
       "   {'dimension': 1504, 'weight': 0.1201171875}],\n",
       "  'top_5_negative_weights': [{'dimension': 2388, 'weight': -0.2294921875},\n",
       "   {'dimension': 1437, 'weight': -0.2158203125},\n",
       "   {'dimension': 3150, 'weight': -0.18359375},\n",
       "   {'dimension': 155, 'weight': -0.1806640625},\n",
       "   {'dimension': 104, 'weight': -0.1708984375}]},\n",
       " 'up_weights_analysis': {'operation': 'up_output[7310] = W_up[7310] @ x',\n",
       "  'weight_vector_norm': 0.93408203125,\n",
       "  'max_weight': 0.1015625,\n",
       "  'min_weight': -0.0849609375,\n",
       "  'mean_weight': -0.00011688470840454102,\n",
       "  'std_weight': 0.01459503173828125,\n",
       "  'bias_term': None,\n",
       "  'top_5_positive_weights': [{'dimension': 3732, 'weight': 0.1015625},\n",
       "   {'dimension': 3558, 'weight': 0.09716796875},\n",
       "   {'dimension': 2740, 'weight': 0.0732421875},\n",
       "   {'dimension': 1029, 'weight': 0.0634765625},\n",
       "   {'dimension': 1628, 'weight': 0.052490234375}],\n",
       "  'top_5_negative_weights': [{'dimension': 1781, 'weight': -0.0849609375},\n",
       "   {'dimension': 2465, 'weight': -0.05126953125},\n",
       "   {'dimension': 3110, 'weight': -0.0478515625},\n",
       "   {'dimension': 2142, 'weight': -0.047607421875},\n",
       "   {'dimension': 2613, 'weight': -0.044921875}]},\n",
       " 'weight_interaction_analysis': {'gate_up_correlation': 0.5196142869643742,\n",
       "  'same_sign_percentage': 66.1865234375,\n",
       "  'weight_magnitude_ratio': 1.5634765625,\n",
       "  'coordinated_amplification': 'YES'}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_analysis['weight_analysis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'zero_gate_attack': {'attack_name': 'Zero Gate Projection Attack',\n",
       "  'current_output': 32.0625,\n",
       "  'required_change': -32.0625,\n",
       "  'modification_strategy': {'modify_dimension': 2388,\n",
       "   'current_value': -0.501953125,\n",
       "   'required_new_value': 139.20868517287235,\n",
       "   'input_change': 139.71063829787235},\n",
       "  'feasibility': 'low'},\n",
       " 'zero_up_attack': {'attack_name': 'Zero Up Projection Attack',\n",
       "  'current_output': 29.625,\n",
       "  'required_change': -29.625,\n",
       "  'modification_strategy': {'modify_dimension': 3732,\n",
       "   'current_value': 3.263671875,\n",
       "   'required_new_value': -288.4286358173077,\n",
       "   'input_change': -291.6923076923077},\n",
       "  'feasibility': 'low'},\n",
       " 'activation_saturation_attack': {'attack_name': 'SiLU Saturation Attack',\n",
       "  'current_output': 32.0625,\n",
       "  'saturation_target': -10.0,\n",
       "  'required_change': -42.0625,\n",
       "  'expected_activation_output': -0.00045397868702434395,\n",
       "  'modification_strategy': {'modify_dimension': 2388,\n",
       "   'current_value': -0.501953125,\n",
       "   'required_new_value': 182.7831532579787,\n",
       "   'input_change': 183.2851063829787}},\n",
       " 'minimal_perturbation_attack': {'attack_name': 'Minimal Perturbation Attack',\n",
       "  'chosen_strategy': 'zero_up',\n",
       "  'perturbation_magnitude': 31.71875,\n",
       "  'relative_perturbation': 0.73291015625,\n",
       "  'feasibility': 'medium'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_analysis['attack_vectors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'super_weight': SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75),\n",
       " 'architecture_info': MLPArchitectureInfo(architecture_type=<MLPArchitectureType.GATED_MLP: 'gated_mlp'>, activation_function='silu', components={'gate': MLPComponentInfo(component_name='gate_proj', component_type='gate', has_bias=False, weight_shape=(14336, 4096)), 'up': MLPComponentInfo(component_name='up_proj', component_type='up', has_bias=False, weight_shape=(14336, 4096)), 'down': MLPComponentInfo(component_name='down_proj', component_type='down', has_bias=False, weight_shape=(4096, 14336))}, has_gate=True, intermediate_size=None, hidden_size=None, is_moe=False, moe_info=None),\n",
       " 'model_agnostic_analysis': True,\n",
       " 'mathematical_breakdown': {'input_analysis': {'input_vector_shape': [4096],\n",
       "   'input_magnitude': 43.28125,\n",
       "   'input_mean': -0.012725830078125,\n",
       "   'input_std': 0.67626953125},\n",
       "  'step1_gate_projection': {'operation': 'gate_output = W_gate @ x',\n",
       "   'bias_term': None,\n",
       "   'result_target_channel': 32.0625,\n",
       "   'has_bias': False},\n",
       "  'step2_activation': {'operation': 'activated_gate = SILU(gate_output)',\n",
       "   'input_to_activation': 32.0625,\n",
       "   'activation_output_target_channel': 32.0625,\n",
       "   'activation_function': 'silu',\n",
       "   'activation_derivative_at_point': 1.0},\n",
       "  'step3_up_projection': {'operation': 'up_output = W_up @ x',\n",
       "   'bias_term': None,\n",
       "   'result_target_channel': 29.625,\n",
       "   'has_bias': False},\n",
       "  'step4_hadamard_product': {'operation': 'hadamard_result = activated_gate âŠ™ up_output (ELEMENT-WISE MULTIPLICATION)',\n",
       "   'activated_gate_component': 32.0625,\n",
       "   'up_output_component': 29.625,\n",
       "   'super_activation_result': 950.0,\n",
       "   'formula': 'y[:, 7310] = SILU(W_gate[7310] @ x) * (W_up[7310] @ x)',\n",
       "   'this_is_where_super_activation_is_created': True},\n",
       "  'step5_down_projection': {'operation': 'final_output = W_down @ hadamard_result',\n",
       "   'super_weight_row': 2070,\n",
       "   'super_weight_processes_super_activation': 950.0,\n",
       "   'super_weight_contribution': -262.75,\n",
       "   'has_bias': False},\n",
       "  'verification': {'computed_super_activation': 950.0,\n",
       "   'super_activation_magnitude': 950.0,\n",
       "   'super_activation_sign': 'positive',\n",
       "   'expected_vs_actual': 'Expected ~950.0, Computed: 950.00'}},\n",
       " 'weight_analysis': {'target_channel_info': {'channel_index': 7310,\n",
       "   'description': 'Channel 7310 in intermediate space where super activation occurs'},\n",
       "  'gate_weights_analysis': {'operation': 'gate_output[7310] = W_gate[7310] @ x',\n",
       "   'weight_vector_norm': 1.4599609375,\n",
       "   'max_weight': 0.19921875,\n",
       "   'min_weight': -0.2294921875,\n",
       "   'mean_weight': -0.00012695789337158203,\n",
       "   'std_weight': 0.0228118896484375,\n",
       "   'bias_term': None,\n",
       "   'top_5_positive_weights': [{'dimension': 188, 'weight': 0.19921875},\n",
       "    {'dimension': 1528, 'weight': 0.14453125},\n",
       "    {'dimension': 684, 'weight': 0.138671875},\n",
       "    {'dimension': 3830, 'weight': 0.1240234375},\n",
       "    {'dimension': 1504, 'weight': 0.1201171875}],\n",
       "   'top_5_negative_weights': [{'dimension': 2388, 'weight': -0.2294921875},\n",
       "    {'dimension': 1437, 'weight': -0.2158203125},\n",
       "    {'dimension': 3150, 'weight': -0.18359375},\n",
       "    {'dimension': 155, 'weight': -0.1806640625},\n",
       "    {'dimension': 104, 'weight': -0.1708984375}]},\n",
       "  'up_weights_analysis': {'operation': 'up_output[7310] = W_up[7310] @ x',\n",
       "   'weight_vector_norm': 0.93408203125,\n",
       "   'max_weight': 0.1015625,\n",
       "   'min_weight': -0.0849609375,\n",
       "   'mean_weight': -0.00011688470840454102,\n",
       "   'std_weight': 0.01459503173828125,\n",
       "   'bias_term': None,\n",
       "   'top_5_positive_weights': [{'dimension': 3732, 'weight': 0.1015625},\n",
       "    {'dimension': 3558, 'weight': 0.09716796875},\n",
       "    {'dimension': 2740, 'weight': 0.0732421875},\n",
       "    {'dimension': 1029, 'weight': 0.0634765625},\n",
       "    {'dimension': 1628, 'weight': 0.052490234375}],\n",
       "   'top_5_negative_weights': [{'dimension': 1781, 'weight': -0.0849609375},\n",
       "    {'dimension': 2465, 'weight': -0.05126953125},\n",
       "    {'dimension': 3110, 'weight': -0.0478515625},\n",
       "    {'dimension': 2142, 'weight': -0.047607421875},\n",
       "    {'dimension': 2613, 'weight': -0.044921875}]},\n",
       "  'weight_interaction_analysis': {'gate_up_correlation': 0.5196142869643742,\n",
       "   'same_sign_percentage': 66.1865234375,\n",
       "   'weight_magnitude_ratio': 1.5634765625,\n",
       "   'coordinated_amplification': 'YES'}},\n",
       " 'attack_vectors': {'zero_gate_attack': {'attack_name': 'Zero Gate Projection Attack',\n",
       "   'current_output': 32.0625,\n",
       "   'required_change': -32.0625,\n",
       "   'modification_strategy': {'modify_dimension': 2388,\n",
       "    'current_value': -0.501953125,\n",
       "    'required_new_value': 139.20868517287235,\n",
       "    'input_change': 139.71063829787235},\n",
       "   'feasibility': 'low'},\n",
       "  'zero_up_attack': {'attack_name': 'Zero Up Projection Attack',\n",
       "   'current_output': 29.625,\n",
       "   'required_change': -29.625,\n",
       "   'modification_strategy': {'modify_dimension': 3732,\n",
       "    'current_value': 3.263671875,\n",
       "    'required_new_value': -288.4286358173077,\n",
       "    'input_change': -291.6923076923077},\n",
       "   'feasibility': 'low'},\n",
       "  'activation_saturation_attack': {'attack_name': 'SiLU Saturation Attack',\n",
       "   'current_output': 32.0625,\n",
       "   'saturation_target': -10.0,\n",
       "   'required_change': -42.0625,\n",
       "   'expected_activation_output': -0.00045397868702434395,\n",
       "   'modification_strategy': {'modify_dimension': 2388,\n",
       "    'current_value': -0.501953125,\n",
       "    'required_new_value': 182.7831532579787,\n",
       "    'input_change': 183.2851063829787}},\n",
       "  'minimal_perturbation_attack': {'attack_name': 'Minimal Perturbation Attack',\n",
       "   'chosen_strategy': 'zero_up',\n",
       "   'perturbation_magnitude': 31.71875,\n",
       "   'relative_perturbation': 0.73291015625,\n",
       "   'feasibility': 'medium'}},\n",
       " 'zero_activation_strategies': {'current_state': {'gate_output': 32.0625,\n",
       "   'up_output': 29.625,\n",
       "   'activation_output': 32.062499999999616,\n",
       "   'super_activation': 949.8515624999886},\n",
       "  'mathematical_conditions_for_zero': [{'condition': 'Gate Zeroing',\n",
       "    'equation': 'W_gate[7310] @ x_modified + b_gate = 0',\n",
       "    'result': 'SILU(0) â†’ super_activation = 0 Ã— up_output = 0',\n",
       "    'difficulty': 'medium'},\n",
       "   {'condition': 'Up Zeroing',\n",
       "    'equation': 'W_up[7310] @ x_modified + b_up = 0',\n",
       "    'result': 'super_activation = activation_output Ã— 0 = 0',\n",
       "    'difficulty': 'medium'}],\n",
       "  'attack_feasibility_ranking': [{'rank': 1,\n",
       "    'strategy': 'Zero Up Projection',\n",
       "    'reason': 'Current up_output = 29.62, smaller magnitude than gate',\n",
       "    'estimated_difficulty': 'medium'},\n",
       "   {'rank': 2,\n",
       "    'strategy': 'Zero Gate Projection',\n",
       "    'reason': 'Current gate_output = 32.06, larger magnitude',\n",
       "    'estimated_difficulty': 'medium'},\n",
       "   {'rank': 3,\n",
       "    'strategy': 'SILU Saturation',\n",
       "    'reason': 'Drive gate to negative values where SILU â‰ˆ 0',\n",
       "    'estimated_difficulty': 'high'}]}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.2734375"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw[0].original_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Gradient Descent Attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from attack.attack import GradientGateZeroingAttack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 21:16:33,315 - GradientGateZeroingAttack_139782535272464 - INFO - GradientGateZeroingAttack initialized with shared MLP handler\n"
     ]
    }
   ],
   "source": [
    "gd_attack = GradientGateZeroingAttack(session.model, session.tokenizer, session.mlp_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = \"Apple Inc. is a tech company.\"\n",
    "input_ids = session.tokenizer(input_str, return_tensors='pt').to(session.model.device)['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-06 21:18:51,713 - GradientGateZeroingAttack_139782535272464 - INFO - Starting gradient attack on layer 1, channel 7310\n",
      "2025-07-06 21:18:51,714 - GradientGateZeroingAttack_139782535272464 - INFO - Attack parameters: lr=1e-05, max_iter=1000, target=0.0\n",
      "2025-07-06 21:18:51,784 - GradientGateZeroingAttack_139782535272464 - INFO - Original gate output at layer 1, channel 7310: 0.6904\n",
      "2025-07-06 21:18:51,785 - GradientGateZeroingAttack_139782535272464 - INFO - Target: 0.0000\n",
      "2025-07-06 21:18:51,785 - GradientGateZeroingAttack_139782535272464 - INFO - Starting optimization...\n",
      "Gradient Attack:   0%|          | 0/1000 [00:00<?] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸŽ‰ Target achieved!: :   1%|          | 8/1000 [00:00<01:32] , Loss=0.0000, Gate=-0.0069, Reduction=101.0%, PertNorm=0.1342\n",
      "2025-07-06 21:18:52,530 - GradientGateZeroingAttack_139782535272464 - INFO - Target achieved at iteration 9!\n",
      "2025-07-06 21:18:52,531 - GradientGateZeroingAttack_139782535272464 - INFO - === ATTACK COMPLETE ===\n",
      "2025-07-06 21:18:52,531 - GradientGateZeroingAttack_139782535272464 - INFO - Success: âœ…\n",
      "2025-07-06 21:18:52,532 - GradientGateZeroingAttack_139782535272464 - INFO - Final gate output: -0.0069\n",
      "2025-07-06 21:18:52,532 - GradientGateZeroingAttack_139782535272464 - INFO - Reduction achieved: 101.0%\n",
      "2025-07-06 21:18:52,533 - GradientGateZeroingAttack_139782535272464 - INFO - Perturbation L2 norm: 0.1342\n",
      "2025-07-06 21:18:52,533 - GradientGateZeroingAttack_139782535272464 - INFO - Iterations used: 9\n"
     ]
    }
   ],
   "source": [
    "attack_results = gd_attack.attack_gate_output(input_text=input_str, target_channel=sw[0].column, target_layer=sw[0].layer, learning_rate=0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'success': True,\n",
       " 'original_gate_output': tensor(0.6904, device='cuda:0', dtype=torch.float16),\n",
       " 'final_gate_output': -0.0069427490234375,\n",
       " 'target_value': 0.0,\n",
       " 'reduction_achieved': tensor(0.6973, device='cuda:0', dtype=torch.float16),\n",
       " 'reduction_percentage': tensor(101., device='cuda:0', dtype=torch.float16),\n",
       " 'final_loss': 4.8220157623291016e-05,\n",
       " 'iterations_used': 9,\n",
       " 'original_embeddings': tensor([[[-4.0588e-03,  1.6499e-04, -4.6997e-03,  ..., -1.8597e-04,\n",
       "           -9.9945e-04,  4.0531e-05],\n",
       "          [-2.3041e-03,  4.6692e-03,  7.1716e-03,  ...,  4.0588e-03,\n",
       "           -5.2643e-04,  8.2397e-04],\n",
       "          [ 3.0823e-03,  1.7166e-03,  4.8447e-04,  ..., -2.3651e-03,\n",
       "            6.3324e-04, -2.0905e-03],\n",
       "          ...,\n",
       "          [ 2.8839e-03, -1.3351e-03, -2.3937e-04,  ..., -4.3945e-03,\n",
       "            1.4267e-03, -2.8229e-03],\n",
       "          [ 2.6398e-03,  3.2043e-03, -2.0447e-03,  ..., -4.3335e-03,\n",
       "            4.4250e-04,  7.4005e-04],\n",
       "          [-1.1215e-03,  3.7766e-04, -2.0599e-04,  ...,  1.2131e-03,\n",
       "           -1.8787e-04, -2.7466e-04]]], device='cuda:0', dtype=torch.float16),\n",
       " 'optimized_embeddings': tensor([[[-4.1847e-03,  1.6665e-04, -4.8981e-03,  ..., -2.1636e-04,\n",
       "           -1.0233e-03,  1.2106e-04],\n",
       "          [-2.1095e-03,  4.6120e-03,  7.2823e-03,  ...,  3.9940e-03,\n",
       "           -5.1403e-04,  8.8549e-04],\n",
       "          [ 3.2063e-03,  1.6708e-03,  5.6553e-04,  ..., -2.4071e-03,\n",
       "            5.7840e-04, -2.0657e-03],\n",
       "          ...,\n",
       "          [ 3.0384e-03, -1.4515e-03, -9.0420e-05,  ..., -4.5319e-03,\n",
       "            1.3638e-03, -2.8152e-03],\n",
       "          [ 2.7809e-03,  3.0804e-03, -1.8911e-03,  ..., -4.4632e-03,\n",
       "            3.9911e-04,  7.4530e-04],\n",
       "          [-1.0071e-03,  2.1935e-04, -9.2328e-05,  ...,  1.1168e-03,\n",
       "           -2.3758e-04, -2.5225e-04]]], device='cuda:0', dtype=torch.float16),\n",
       " 'perturbation': tensor([[[-1.2589e-04,  1.6689e-06, -1.9836e-04,  ..., -3.0398e-05,\n",
       "           -2.3842e-05,  8.0526e-05],\n",
       "          [ 1.9455e-04, -5.7220e-05,  1.1063e-04,  ..., -6.4850e-05,\n",
       "            1.2398e-05,  6.1512e-05],\n",
       "          [ 1.2398e-04, -4.5776e-05,  8.1062e-05,  ..., -4.1962e-05,\n",
       "           -5.4836e-05,  2.4796e-05],\n",
       "          ...,\n",
       "          [ 1.5450e-04, -1.1635e-04,  1.4901e-04,  ..., -1.3733e-04,\n",
       "           -6.2943e-05,  7.6294e-06],\n",
       "          [ 1.4114e-04, -1.2398e-04,  1.5354e-04,  ..., -1.2970e-04,\n",
       "           -4.3392e-05,  5.2452e-06],\n",
       "          [ 1.1444e-04, -1.5831e-04,  1.1367e-04,  ..., -9.6321e-05,\n",
       "           -4.9710e-05,  2.2411e-05]]], device='cuda:0', dtype=torch.float16),\n",
       " 'perturbation_l2_norm': 0.1341552734375,\n",
       " 'perturbation_linf_norm': 0.03021240234375,\n",
       " 'optimization_history': {'iterations': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9],\n",
       "  'losses': [0.476806640625,\n",
       "   8.5,\n",
       "   17.796875,\n",
       "   12.625,\n",
       "   4.9296875,\n",
       "   1.0673828125,\n",
       "   0.317626953125,\n",
       "   0.021636962890625,\n",
       "   0.0014925003051757812,\n",
       "   4.8220157623291016e-05],\n",
       "  'gate_outputs': [0.6904296875,\n",
       "   2.916015625,\n",
       "   4.21875,\n",
       "   -3.552734375,\n",
       "   2.220703125,\n",
       "   -1.033203125,\n",
       "   0.5634765625,\n",
       "   -0.1470947265625,\n",
       "   0.03863525390625,\n",
       "   -0.0069427490234375],\n",
       "  'perturbation_norms': [0.00489044189453125,\n",
       "   0.1055908203125,\n",
       "   0.1348876953125,\n",
       "   0.1336669921875,\n",
       "   0.134033203125,\n",
       "   0.1341552734375,\n",
       "   0.1341552734375,\n",
       "   0.1341552734375,\n",
       "   0.1341552734375,\n",
       "   0.1341552734375],\n",
       "  'gradient_norms': [489.0,\n",
       "   10984.0,\n",
       "   9832.0,\n",
       "   3036.0,\n",
       "   1218.0,\n",
       "   598.5,\n",
       "   283.0,\n",
       "   76.1875,\n",
       "   19.75,\n",
       "   3.560546875]},\n",
       " 'hyperparameters': {'learning_rate': 1e-05,\n",
       "  'max_iterations': 1000,\n",
       "  'loss_type': 'mse'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimized_embeddings = attack_results['attack_result']['optimized_embeddings']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['success', 'original_gate_output', 'final_gate_output', 'target_value', 'reduction_achieved', 'reduction_percentage', 'final_loss', 'iterations_used', 'original_embeddings', 'optimized_embeddings', 'perturbation', 'perturbation_l2_norm', 'perturbation_linf_norm', 'optimization_history', 'hyperparameters'])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_results.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['success', 'original_gate_output', 'final_gate_output', 'target_value', 'reduction_achieved', 'reduction_percentage', 'final_loss', 'iterations_used', 'original_embeddings', 'optimized_embeddings', 'perturbation', 'perturbation_l2_norm', 'perturbation_linf_norm', 'optimization_history', 'hyperparameters'])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attack_results['attack_result'].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-4.1847e-03,  1.6665e-04, -4.8981e-03,  ..., -2.1636e-04,\n",
       "          -1.0233e-03,  1.2106e-04],\n",
       "         [-2.1095e-03,  4.6120e-03,  7.2823e-03,  ...,  3.9940e-03,\n",
       "          -5.1403e-04,  8.8549e-04],\n",
       "         [ 3.2063e-03,  1.6708e-03,  5.6553e-04,  ..., -2.4071e-03,\n",
       "           5.7840e-04, -2.0657e-03],\n",
       "         ...,\n",
       "         [ 3.0384e-03, -1.4515e-03, -9.0420e-05,  ..., -4.5319e-03,\n",
       "           1.3638e-03, -2.8152e-03],\n",
       "         [ 2.7809e-03,  3.0804e-03, -1.8911e-03,  ..., -4.4632e-03,\n",
       "           3.9911e-04,  7.4530e-04],\n",
       "         [-1.0071e-03,  2.1935e-04, -9.2328e-05,  ...,  1.1168e-03,\n",
       "          -2.3758e-04, -2.5225e-04]]], device='cuda:0', dtype=torch.float16)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimized_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token 0 ('<s>'): perturbation norm = 0.1063\n",
      "Token 1 ('Apple'): perturbation norm = 0.0303\n",
      "Token 2 ('Inc'): perturbation norm = 0.0228\n",
      "Token 3 ('.'): perturbation norm = 0.0378\n",
      "Token 4 ('is'): perturbation norm = 0.0311\n",
      "Token 5 ('a'): perturbation norm = 0.0395\n",
      "Token 6 ('tech'): perturbation norm = 0.0199\n",
      "Token 7 ('company'): perturbation norm = 0.0171\n",
      "Token 8 ('.'): perturbation norm = 0.0254\n",
      "Top 10 most perturbed embedding dimensions: [1387, 3876, 3423, 1004, 3570, 2078, 3178, 3680, 2702, 2960]\n",
      "Their perturbation magnitudes: [0.03875732421875, 0.0270233154296875, 0.0235137939453125, 0.0231475830078125, 0.0225067138671875, 0.021331787109375, 0.0206146240234375, 0.0205230712890625, 0.0185394287109375, 0.0160675048828125]\n"
     ]
    }
   ],
   "source": [
    "perturbation = attack_results['attack_result']['perturbation']\n",
    "\n",
    "# Which tokens changed the most?\n",
    "token_perturbation_norms = torch.norm(perturbation[0], dim=1)  # [seq_len]\n",
    "for i, norm in enumerate(token_perturbation_norms):\n",
    "    token = session.tokenizer.decode(input_ids[0, i])\n",
    "    print(f\"Token {i} ('{token}'): perturbation norm = {norm.item():.4f}\")\n",
    "\n",
    "# Which embedding dimensions changed the most?\n",
    "dim_perturbation = torch.norm(perturbation[0], dim=0)  # [embed_dim]\n",
    "top_dims = torch.topk(dim_perturbation, 10)\n",
    "print(f\"Top 10 most perturbed embedding dimensions: {top_dims.indices.tolist()}\")\n",
    "print(f\"Their perturbation magnitudes: {top_dims.values.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x400 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot perturbation patterns\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Token-wise perturbations\n",
    "token_norms = torch.norm(perturbation[0], dim=1).cpu().numpy()\n",
    "ax1.bar(range(len(token_norms)), token_norms)\n",
    "ax1.set_xlabel('Token Position')\n",
    "ax1.set_ylabel('Perturbation Norm')\n",
    "ax1.set_title('Perturbation by Token Position')\n",
    "\n",
    "# Embedding dimension perturbations\n",
    "dim_norms = torch.norm(perturbation[0], dim=0).cpu().numpy()\n",
    "ax2.hist(dim_norms, bins=50)\n",
    "ax2.set_xlabel('Perturbation Magnitude')\n",
    "ax2.set_ylabel('Number of Dimensions')\n",
    "ax2.set_title('Distribution of Embedding Dimension Changes')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Map optimized embeddings back to actual tokens to create real adversarial inputs\n",
    "\"\"\"\n",
    "import torch.nn.functional as F\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "def find_nearest_tokens(optimized_embeddings: torch.Tensor, \n",
    "                                   original_input_ids: torch.Tensor,\n",
    "                                   model, \n",
    "                                   tokenizer,\n",
    "                                   top_k: int = 10) -> Dict:\n",
    "    \"\"\"Safe cosine similarity that handles zero-norm embeddings\"\"\"\n",
    "    \n",
    "    embedding_matrix = model.get_input_embeddings().weight\n",
    "    results = {}\n",
    "    \n",
    "    for pos in range(optimized_embeddings.size(1)):\n",
    "        original_token_id = original_input_ids[0, pos].item()\n",
    "        optimized_emb = optimized_embeddings[0, pos]\n",
    "        \n",
    "        # Check optimized embedding norm\n",
    "        opt_norm = torch.norm(optimized_emb)\n",
    "        if opt_norm < 1e-8:\n",
    "            print(f\"Warning: Zero-norm optimized embedding at position {pos}\")\n",
    "            continue\n",
    "        \n",
    "        # Calculate norms for all embeddings\n",
    "        matrix_norms = torch.norm(embedding_matrix, dim=1)\n",
    "        \n",
    "        # Filter out zero-norm embeddings from vocabulary\n",
    "        valid_mask = matrix_norms > 1e-8\n",
    "        valid_embeddings = embedding_matrix[valid_mask]\n",
    "        valid_indices = torch.arange(len(embedding_matrix), device=embedding_matrix.device)[valid_mask]\n",
    "        \n",
    "        print(f\"Position {pos}: {valid_mask.sum().item()} valid embeddings out of {len(embedding_matrix)}\")\n",
    "        \n",
    "        if len(valid_embeddings) == 0:\n",
    "            print(f\"No valid embeddings found for position {pos}\")\n",
    "            continue\n",
    "        \n",
    "        # Safe cosine similarity calculation\n",
    "        opt_normalized = optimized_emb / opt_norm\n",
    "        valid_normalized = F.normalize(valid_embeddings, dim=1)\n",
    "        \n",
    "        similarities = torch.matmul(opt_normalized, valid_normalized.T)\n",
    "        \n",
    "        # Get top-k most similar\n",
    "        top_similarities, top_mask_indices = torch.topk(similarities, min(top_k * 2, len(similarities)))\n",
    "        top_indices = valid_indices[top_mask_indices]\n",
    "        \n",
    "        # Convert to readable tokens and filter\n",
    "        candidates = []\n",
    "        for sim, idx in zip(top_similarities, top_indices):\n",
    "            token_str = tokenizer.decode([idx.item()])\n",
    "            \n",
    "            # Skip control characters and very short tokens\n",
    "            if len(token_str.strip()) > 0 and not any(ord(c) < 32 for c in token_str if c):\n",
    "                candidates.append({\n",
    "                    'token_id': idx.item(),\n",
    "                    'token': token_str,\n",
    "                    'similarity': sim.item(),\n",
    "                    'is_original': idx.item() == original_token_id\n",
    "                })\n",
    "                \n",
    "                if len(candidates) >= top_k:\n",
    "                    break\n",
    "        \n",
    "        results[pos] = {\n",
    "            'original_token_id': original_token_id,\n",
    "            'original_token': tokenizer.decode([original_token_id]),\n",
    "            'candidates': candidates,\n",
    "            'perturbation_norm': torch.norm(optimized_emb - embedding_matrix[original_token_id]).item()\n",
    "        }\n",
    "    \n",
    "    return results\n",
    "\n",
    "def create_adversarial_inputs(nearest_tokens: Dict, \n",
    "                            original_input_ids: torch.Tensor,\n",
    "                            max_changes: int = 3) -> List[Dict]:\n",
    "    \"\"\"Fixed version with proper bounds checking\"\"\"\n",
    "    \n",
    "    adversarial_inputs = []\n",
    "    \n",
    "    # Strategy 1: Change only the most perturbed token\n",
    "    most_perturbed_pos = max(nearest_tokens.keys(), \n",
    "                           key=lambda pos: nearest_tokens[pos]['perturbation_norm'])\n",
    "    \n",
    "    candidates = nearest_tokens[most_perturbed_pos]['candidates']\n",
    "    for candidate in candidates[:5]:\n",
    "        if not candidate['is_original']:  # Skip the original token\n",
    "            new_input_ids = original_input_ids.clone()\n",
    "            new_input_ids[0, most_perturbed_pos] = candidate['token_id']\n",
    "            \n",
    "            adversarial_inputs.append({\n",
    "                'input_ids': new_input_ids,\n",
    "                'changes': [(most_perturbed_pos, candidate['token'])],\n",
    "                'strategy': 'single_substitution',\n",
    "                'similarity_score': candidate['similarity']\n",
    "            })\n",
    "    \n",
    "    # Strategy 2: Change top N most perturbed tokens (WITH BOUNDS CHECKING)\n",
    "    sorted_positions = sorted(nearest_tokens.keys(), \n",
    "                            key=lambda pos: nearest_tokens[pos]['perturbation_norm'], \n",
    "                            reverse=True)\n",
    "    \n",
    "    for num_changes in range(2, min(max_changes + 1, len(sorted_positions))):\n",
    "        new_input_ids = original_input_ids.clone()\n",
    "        changes = []\n",
    "        total_similarity = 0\n",
    "        valid_changes = 0\n",
    "        \n",
    "        for pos in sorted_positions[:num_changes]:\n",
    "            candidates = nearest_tokens[pos]['candidates']\n",
    "            \n",
    "            # Find first non-original candidate\n",
    "            best_candidate = None\n",
    "            for candidate in candidates:\n",
    "                if not candidate['is_original']:\n",
    "                    best_candidate = candidate\n",
    "                    break\n",
    "            \n",
    "            # Skip this position if no valid replacement found\n",
    "            if best_candidate is None:\n",
    "                continue\n",
    "                \n",
    "            new_input_ids[0, pos] = best_candidate['token_id']\n",
    "            changes.append((pos, best_candidate['token']))\n",
    "            total_similarity += best_candidate['similarity']\n",
    "            valid_changes += 1\n",
    "        \n",
    "        # Only add if we made at least one valid change\n",
    "        if valid_changes > 0:\n",
    "            adversarial_inputs.append({\n",
    "                'input_ids': new_input_ids,\n",
    "                'changes': changes,\n",
    "                'strategy': f'multi_substitution_{valid_changes}',\n",
    "                'avg_similarity_score': total_similarity / valid_changes if valid_changes > 0 else 0\n",
    "            })\n",
    "    \n",
    "    return adversarial_inputs\n",
    "\n",
    "def test_adversarial_effectiveness(adversarial_inputs: List[Dict], \n",
    "                                 model, \n",
    "                                 tokenizer,\n",
    "                                 attack_system,\n",
    "                                 target_layer: int,\n",
    "                                 target_channel: int,\n",
    "                                 original_gate_output: float) -> List[Dict]:\n",
    "    \"\"\"Fixed version with proper reduction calculation\"\"\"\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for adv_input in adversarial_inputs:\n",
    "        input_ids = adv_input['input_ids']\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            embeddings = model.get_input_embeddings()(input_ids)\n",
    "            gate_output = attack_system._get_gate_output(embeddings, target_layer, target_channel)\n",
    "            \n",
    "            # FIXED: Proper reduction calculation\n",
    "            if abs(original_gate_output) > 1e-8:\n",
    "                reduction = (abs(original_gate_output) - abs(gate_output.item())) / abs(original_gate_output) * 100\n",
    "            else:\n",
    "                reduction = 0.0\n",
    "            \n",
    "            text = tokenizer.decode(input_ids[0], skip_special_tokens=True)\n",
    "        \n",
    "        results.append({\n",
    "            **adv_input,\n",
    "            'text': text,\n",
    "            'gate_output': gate_output.item(),\n",
    "            'reduction_percentage': reduction,\n",
    "            'effectiveness_score': reduction / len(adv_input['changes']) if len(adv_input['changes']) > 0 else 0\n",
    "        })\n",
    "    \n",
    "    results.sort(key=lambda x: x['reduction_percentage'], reverse=True)\n",
    "    return results\n",
    "\n",
    "def calculate_reduction_properly(original_gate: float, new_gate: float) -> float:\n",
    "    \"\"\"Calculate reduction percentage properly\"\"\"\n",
    "    \n",
    "    if abs(original_gate) < 1e-8:\n",
    "        return 0.0  # Can't calculate meaningful reduction from ~zero\n",
    "    \n",
    "    # Raw reduction in magnitude\n",
    "    reduction = abs(original_gate) - abs(new_gate)\n",
    "    reduction_percentage = (reduction / abs(original_gate)) * 100\n",
    "    \n",
    "    return reduction_percentage\n",
    "\n",
    "def analyze_token_mapping_results(nearest_tokens: Dict, tokenizer) -> None:\n",
    "    \"\"\"\n",
    "    Print analysis of the token mapping results\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"=== TOKEN MAPPING ANALYSIS ===\")\n",
    "    \n",
    "    for pos, data in nearest_tokens.items():\n",
    "        if data['perturbation_norm'] > 0.01:  # Only show significantly perturbed positions\n",
    "            print(f\"\\nPosition {pos}: '{data['original_token']}' (perturbation: {data['perturbation_norm']:.4f})\")\n",
    "            print(\"Top replacement candidates:\")\n",
    "            \n",
    "            for i, candidate in enumerate(data['candidates'][:5]):\n",
    "                status = \"ðŸ”¸ ORIGINAL\" if candidate['is_original'] else \"ðŸ”„ CANDIDATE\"\n",
    "                print(f\"  {i+1}. '{candidate['token']}' (similarity: {candidate['similarity']:.4f}) {status}\")\n",
    "\n",
    "# Example usage function\n",
    "def run_embedding_to_token_attack(result: Dict, \n",
    "                                model, \n",
    "                                tokenizer, \n",
    "                                attack_system,\n",
    "                                target_layer: int,\n",
    "                                target_channel: int,\n",
    "                                original_input_ids: torch.Tensor) -> Dict:\n",
    "    \"\"\"\n",
    "    Complete pipeline from optimized embeddings to adversarial text inputs\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"ðŸ” Step 1: Finding nearest tokens to optimized embeddings...\")\n",
    "    nearest_tokens = find_nearest_tokens(\n",
    "        result['optimized_embeddings'],\n",
    "        original_input_ids,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        top_k=10\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸ“Š Step 2: Analyzing token mapping...\")\n",
    "    analyze_token_mapping_results(nearest_tokens, tokenizer)\n",
    "    \n",
    "    print(\"\\nðŸŽ¯ Step 3: Creating adversarial inputs...\")\n",
    "    adversarial_inputs = create_adversarial_inputs(\n",
    "        nearest_tokens,\n",
    "        original_input_ids,\n",
    "        max_changes=3\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nðŸ§ª Step 4: Testing {len(adversarial_inputs)} adversarial candidates...\")\n",
    "    effectiveness_results = test_adversarial_effectiveness(\n",
    "        adversarial_inputs,\n",
    "        model,\n",
    "        tokenizer,\n",
    "        attack_system,\n",
    "        target_layer,\n",
    "        target_channel,\n",
    "        result['original_gate_output']\n",
    "    )\n",
    "    \n",
    "    print(\"\\nðŸ† Top 5 Most Effective Adversarial Inputs:\")\n",
    "    for i, res in enumerate(effectiveness_results[:5]):\n",
    "        print(f\"\\n{i+1}. Reduction: {res['reduction_percentage']:.1f}%\")\n",
    "        print(f\"   Strategy: {res['strategy']}\")\n",
    "        print(f\"   Text: '{res['text']}'\")\n",
    "        print(f\"   Changes: {res['changes']}\")\n",
    "        print(f\"   Gate output: {res['gate_output']:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'nearest_tokens': nearest_tokens,\n",
    "        'adversarial_inputs': adversarial_inputs,\n",
    "        'effectiveness_results': effectiveness_results,\n",
    "        'best_adversarial_input': effectiveness_results[0] if effectiveness_results else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ” Step 1: Finding nearest tokens to optimized embeddings...\n",
      "Position 0: 31859 valid embeddings out of 32000\n",
      "Position 1: 31859 valid embeddings out of 32000\n",
      "Position 2: 31859 valid embeddings out of 32000\n",
      "Position 3: 31859 valid embeddings out of 32000\n",
      "Position 4: 31859 valid embeddings out of 32000\n",
      "Position 5: 31859 valid embeddings out of 32000\n",
      "Position 6: 31859 valid embeddings out of 32000\n",
      "Position 7: 31859 valid embeddings out of 32000\n",
      "Position 8: 31859 valid embeddings out of 32000\n",
      "\n",
      "ðŸ“Š Step 2: Analyzing token mapping...\n",
      "=== TOKEN MAPPING ANALYSIS ===\n",
      "\n",
      "Position 0: '<s>' (perturbation: 0.1063)\n",
      "Top replacement candidates:\n",
      "  1. '<s>' (similarity: 0.8330) ðŸ”¸ ORIGINAL\n",
      "  2. 'á¥€' (similarity: 0.0990) ðŸ”„ CANDIDATE\n",
      "  3. 'User' (similarity: 0.0948) ðŸ”„ CANDIDATE\n",
      "  4. 'NdEx' (similarity: 0.0863) ðŸ”„ CANDIDATE\n",
      "  5. '~~~~' (similarity: 0.0825) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 1: 'Apple' (perturbation: 0.0303)\n",
      "Top replacement candidates:\n",
      "  1. 'Apple' (similarity: 0.9844) ðŸ”¸ ORIGINAL\n",
      "  2. 'apple' (similarity: 0.3589) ðŸ”„ CANDIDATE\n",
      "  3. 'Google' (similarity: 0.2915) ðŸ”„ CANDIDATE\n",
      "  4. 'Microsoft' (similarity: 0.2627) ðŸ”„ CANDIDATE\n",
      "  5. 'Samsung' (similarity: 0.2500) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 2: 'Inc' (perturbation: 0.0228)\n",
      "Top replacement candidates:\n",
      "  1. 'Inc' (similarity: 0.9912) ðŸ”¸ ORIGINAL\n",
      "  2. 'INC' (similarity: 0.4375) ðŸ”„ CANDIDATE\n",
      "  3. 'Ltd' (similarity: 0.3301) ðŸ”„ CANDIDATE\n",
      "  4. 'inc' (similarity: 0.3125) ðŸ”„ CANDIDATE\n",
      "  5. 'LLC' (similarity: 0.3110) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 3: '.' (perturbation: 0.0378)\n",
      "Top replacement candidates:\n",
      "  1. '.' (similarity: 0.9194) ðŸ”¸ ORIGINAL\n",
      "  2. ').' (similarity: 0.5229) ðŸ”„ CANDIDATE\n",
      "  3. 'ã€‚' (similarity: 0.4041) ðŸ”„ CANDIDATE\n",
      "  4. '}.' (similarity: 0.4014) ðŸ”„ CANDIDATE\n",
      "  5. ':' (similarity: 0.3962) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 4: 'is' (perturbation: 0.0311)\n",
      "Top replacement candidates:\n",
      "  1. 'is' (similarity: 0.9653) ðŸ”¸ ORIGINAL\n",
      "  2. 'are' (similarity: 0.5361) ðŸ”„ CANDIDATE\n",
      "  3. 'was' (similarity: 0.5190) ðŸ”„ CANDIDATE\n",
      "  4. 'Is' (similarity: 0.4070) ðŸ”„ CANDIDATE\n",
      "  5. 'has' (similarity: 0.4058) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 5: 'a' (perturbation: 0.0395)\n",
      "Top replacement candidates:\n",
      "  1. 'a' (similarity: 0.9238) ðŸ”¸ ORIGINAL\n",
      "  2. 'an' (similarity: 0.5244) ðŸ”„ CANDIDATE\n",
      "  3. 'A' (similarity: 0.3616) ðŸ”„ CANDIDATE\n",
      "  4. 'the' (similarity: 0.3052) ðŸ”„ CANDIDATE\n",
      "  5. 'a' (similarity: 0.2343) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 6: 'tech' (perturbation: 0.0199)\n",
      "Top replacement candidates:\n",
      "  1. 'tech' (similarity: 0.9937) ðŸ”¸ ORIGINAL\n",
      "  2. 'Tech' (similarity: 0.4685) ðŸ”„ CANDIDATE\n",
      "  3. 'tech' (similarity: 0.3616) ðŸ”„ CANDIDATE\n",
      "  4. 'technology' (similarity: 0.3171) ðŸ”„ CANDIDATE\n",
      "  5. 'ech' (similarity: 0.2512) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 7: 'company' (perturbation: 0.0171)\n",
      "Top replacement candidates:\n",
      "  1. 'company' (similarity: 0.9937) ðŸ”¸ ORIGINAL\n",
      "  2. 'companies' (similarity: 0.5459) ðŸ”„ CANDIDATE\n",
      "  3. 'Company' (similarity: 0.4866) ðŸ”„ CANDIDATE\n",
      "  4. 'company' (similarity: 0.3689) ðŸ”„ CANDIDATE\n",
      "  5. 'Company' (similarity: 0.3547) ðŸ”„ CANDIDATE\n",
      "\n",
      "Position 8: '.' (perturbation: 0.0254)\n",
      "Top replacement candidates:\n",
      "  1. '.' (similarity: 0.9634) ðŸ”¸ ORIGINAL\n",
      "  2. ').' (similarity: 0.5381) ðŸ”„ CANDIDATE\n",
      "  3. ':' (similarity: 0.4165) ðŸ”„ CANDIDATE\n",
      "  4. ',' (similarity: 0.4165) ðŸ”„ CANDIDATE\n",
      "  5. 'ã€‚' (similarity: 0.4036) ðŸ”„ CANDIDATE\n",
      "\n",
      "ðŸŽ¯ Step 3: Creating adversarial inputs...\n",
      "\n",
      "ðŸ§ª Step 4: Testing 6 adversarial candidates...\n",
      "\n",
      "ðŸ† Top 5 Most Effective Adversarial Inputs:\n",
      "\n",
      "1. Reduction: 99.2%\n",
      "   Strategy: single_substitution\n",
      "   Text: '~~~~ Apple Inc. is a tech company.'\n",
      "   Changes: [(0, '~~~~')]\n",
      "   Gate output: 0.0052\n",
      "\n",
      "2. Reduction: 89.8%\n",
      "   Strategy: single_substitution\n",
      "   Text: 'User Apple Inc. is a tech company.'\n",
      "   Changes: [(0, 'User')]\n",
      "   Gate output: -0.0701\n",
      "\n",
      "3. Reduction: -154.8%\n",
      "   Strategy: single_substitution\n",
      "   Text: 'á¥€ Apple Inc. is a tech company.'\n",
      "   Changes: [(0, 'á¥€')]\n",
      "   Gate output: 1.7588\n",
      "\n",
      "4. Reduction: -155.2%\n",
      "   Strategy: single_substitution\n",
      "   Text: 'NdEx Apple Inc. is a tech company.'\n",
      "   Changes: [(0, 'NdEx')]\n",
      "   Gate output: 1.7627\n",
      "\n",
      "5. Reduction: -156.5%\n",
      "   Strategy: multi_substitution_2\n",
      "   Text: 'á¥€ Apple Inc. is an tech company.'\n",
      "   Changes: [(0, 'á¥€'), (5, 'an')]\n",
      "   Gate output: 1.7705\n"
     ]
    }
   ],
   "source": [
    "# Run the complete pipeline\n",
    "token_attack_results = run_embedding_to_token_attack(\n",
    "    attack_results,                    # Your gradient attack result\n",
    "    session.model, \n",
    "    session.tokenizer, \n",
    "    gd_attack,\n",
    "    target_layer=sw[0].layer,\n",
    "    target_channel=sw[0].column,\n",
    "    original_input_ids=input_ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'nearest_tokens': {0: {'original_token_id': 1,\n",
       "   'original_token': '<s>',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.10626220703125},\n",
       "  1: {'original_token_id': 10244,\n",
       "   'original_token': 'Apple',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.0303497314453125},\n",
       "  2: {'original_token_id': 5671,\n",
       "   'original_token': 'Inc',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.02276611328125},\n",
       "  3: {'original_token_id': 28723,\n",
       "   'original_token': '.',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.03778076171875},\n",
       "  4: {'original_token_id': 349,\n",
       "   'original_token': 'is',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.0310516357421875},\n",
       "  5: {'original_token_id': 264,\n",
       "   'original_token': 'a',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.03948974609375},\n",
       "  6: {'original_token_id': 14130,\n",
       "   'original_token': 'tech',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.0198516845703125},\n",
       "  7: {'original_token_id': 2496,\n",
       "   'original_token': 'company',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.0171051025390625},\n",
       "  8: {'original_token_id': 28723,\n",
       "   'original_token': '.',\n",
       "   'candidates': [{'token_id': 10,\n",
       "     'token': '\\x07',\n",
       "     'similarity': nan,\n",
       "     'is_original': False},\n",
       "    {'token_id': 9, 'token': '\\x06', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 7, 'token': '\\x04', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 8, 'token': '\\x05', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 4, 'token': '\\x01', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 0, 'token': '<unk>', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 5, 'token': '\\x02', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 6, 'token': '\\x03', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 11, 'token': '\\x08', 'similarity': nan, 'is_original': False},\n",
       "    {'token_id': 14,\n",
       "     'token': '\\x0b',\n",
       "     'similarity': nan,\n",
       "     'is_original': False}],\n",
       "   'perturbation_norm': 0.025360107421875}},\n",
       " 'adversarial_inputs': [{'input_ids': tensor([[   10, 10244,  5671, 28723,   349,   264, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x07')],\n",
       "   'strategy': 'single_substitution',\n",
       "   'similarity_score': nan},\n",
       "  {'input_ids': tensor([[    9, 10244,  5671, 28723,   349,   264, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x06')],\n",
       "   'strategy': 'single_substitution',\n",
       "   'similarity_score': nan},\n",
       "  {'input_ids': tensor([[    7, 10244,  5671, 28723,   349,   264, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x04')],\n",
       "   'strategy': 'single_substitution',\n",
       "   'similarity_score': nan},\n",
       "  {'input_ids': tensor([[    8, 10244,  5671, 28723,   349,   264, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x05')],\n",
       "   'strategy': 'single_substitution',\n",
       "   'similarity_score': nan},\n",
       "  {'input_ids': tensor([[    4, 10244,  5671, 28723,   349,   264, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x01')],\n",
       "   'strategy': 'single_substitution',\n",
       "   'similarity_score': nan},\n",
       "  {'input_ids': tensor([[    9, 10244,  5671, 28723,   349,     9, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x06'), (5, '\\x06')],\n",
       "   'strategy': 'multi_substitution_2',\n",
       "   'avg_similarity_score': nan},\n",
       "  {'input_ids': tensor([[    9, 10244,  5671,     9,   349,     9, 14130,  2496, 28723]],\n",
       "          device='cuda:0'),\n",
       "   'changes': [(0, '\\x06'), (5, '\\x06'), (3, '\\x06')],\n",
       "   'strategy': 'multi_substitution_3',\n",
       "   'avg_similarity_score': nan}]}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "token_attack_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tokenization:\n",
      "  IDs: tensor([[    1, 10244,  5671, 28723,   349,   264, 14130,  2496, 28723]])\n",
      "  Tokens: ['<s>', 'Apple', 'Inc', '.', 'is', 'a', 'tech', 'company', '.']\n",
      "\n",
      "Attacked tokenization:\n",
      "  IDs: tensor([[    1, 28705, 11902, 10244,  5671, 28723,   349,   264, 14130,  2496,\n",
      "         28723]])\n",
      "  Tokens: ['<s>', '', '~~~~', 'Apple', 'Inc', '.', 'is', 'a', 'tech', 'company', '.']\n"
     ]
    }
   ],
   "source": [
    "# Test what happens when you tokenize\n",
    "original_text = \"Apple Inc. is a tech company.\"\n",
    "attacked_text = \"~~~~ Apple Inc. is a tech company.\"\n",
    "\n",
    "original_tokens = session.tokenizer(original_text, return_tensors=\"pt\")\n",
    "attacked_tokens = session.tokenizer(attacked_text, return_tensors=\"pt\")\n",
    "\n",
    "print(\"Original tokenization:\")\n",
    "print(f\"  IDs: {original_tokens['input_ids']}\")\n",
    "print(f\"  Tokens: {[session.tokenizer.decode([id]) for id in original_tokens['input_ids'][0]]}\")\n",
    "\n",
    "print(\"\\nAttacked tokenization:\")\n",
    "print(f\"  IDs: {attacked_tokens['input_ids']}\")\n",
    "print(f\"  Tokens: {[session.tokenizer.decode([id]) for id in attacked_tokens['input_ids'][0]]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_attack_on_model_output(original_text: str, attacked_text: str, model, tokenizer):\n",
    "    \"\"\"Test how the attack affects actual model predictions\"\"\"\n",
    "    \n",
    "    # Tokenize both\n",
    "    original_tokens = tokenizer(original_text, return_tensors=\"pt\").to(model.device)\n",
    "    attacked_tokens = tokenizer(attacked_text, return_tensors=\"pt\").to(model.device)\n",
    "    \n",
    "    # Get model outputs\n",
    "    with torch.no_grad():\n",
    "        original_output = model(**original_tokens)\n",
    "        attacked_output = model(**attacked_tokens)\n",
    "    \n",
    "    # Compare final predictions (last token logits)\n",
    "    original_logits = original_output.logits[0, -1]  # Last token predictions\n",
    "    attacked_logits = attacked_output.logits[0, -1]\n",
    "    \n",
    "    # Get top 10 predictions for each\n",
    "    original_probs = torch.softmax(original_logits, dim=-1)\n",
    "    attacked_probs = torch.softmax(attacked_logits, dim=-1)\n",
    "    \n",
    "    original_top = torch.topk(original_probs, 10)\n",
    "    attacked_top = torch.topk(attacked_probs, 10)\n",
    "    \n",
    "    print(\"=== MODEL OUTPUT COMPARISON ===\")\n",
    "    print(f\"Original text: '{original_text}'\")\n",
    "    print(f\"Attacked text:  '{attacked_text}'\")\n",
    "    print()\n",
    "    \n",
    "    print(\"Original predictions:\")\n",
    "    for i, (prob, idx) in enumerate(zip(original_top.values, original_top.indices)):\n",
    "        token = tokenizer.decode([idx.item()])\n",
    "        print(f\"  {i+1:2d}. '{token}' ({prob:.4f})\")\n",
    "    \n",
    "    print(\"\\nAttacked predictions:\")\n",
    "    for i, (prob, idx) in enumerate(zip(attacked_top.values, attacked_top.indices)):\n",
    "        token = tokenizer.decode([idx.item()])\n",
    "        print(f\"  {i+1:2d}. '{token}' ({prob:.4f})\")\n",
    "    \n",
    "    # Calculate change in prediction distribution\n",
    "    kl_divergence = torch.nn.functional.kl_div(\n",
    "        torch.log_softmax(attacked_logits, dim=-1),\n",
    "        torch.softmax(original_logits, dim=-1),\n",
    "        reduction='sum'\n",
    "    )\n",
    "    \n",
    "    print(f\"\\nKL divergence between predictions: {kl_divergence.item():.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'original_tokens': original_tokens,\n",
    "        'attacked_tokens': attacked_tokens,\n",
    "        'original_top_predictions': original_top,\n",
    "        'attacked_top_predictions': attacked_top,\n",
    "        'kl_divergence': kl_divergence.item()\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== MODEL OUTPUT COMPARISON ===\n",
      "Original text: 'Apple Inc. is a tech company.'\n",
      "Attacked text:  '~~~~ Apple Inc. is a tech company.'\n",
      "\n",
      "Original predictions:\n",
      "   1. 'It' (0.2477)\n",
      "   2. 'The' (0.0817)\n",
      "   3. 'They' (0.0607)\n",
      "   4. 'Apple' (0.0536)\n",
      "   5. '\n",
      "' (0.0430)\n",
      "   6. 'But' (0.0392)\n",
      "   7. 'Its' (0.0312)\n",
      "   8. 'This' (0.0227)\n",
      "   9. 'That' (0.0220)\n",
      "  10. 'And' (0.0195)\n",
      "\n",
      "Attacked predictions:\n",
      "   1. 'It' (0.2137)\n",
      "   2. 'Apple' (0.0739)\n",
      "   3. '' (0.0716)\n",
      "   4. '\n",
      "' (0.0688)\n",
      "   5. 'They' (0.0673)\n",
      "   6. 'The' (0.0627)\n",
      "   7. 'Its' (0.0234)\n",
      "   8. 'But' (0.0178)\n",
      "   9. 'This' (0.0149)\n",
      "  10. 'In' (0.0137)\n",
      "\n",
      "KL divergence between predictions: 0.1278\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test your best attack\n",
    "original_text = \"Apple Inc. is a tech company.\"\n",
    "attacked_text = \"~~~~ Apple Inc. is a tech company.\"\n",
    "\n",
    "results = test_attack_on_model_output(original_text, attacked_text, session.model, session.tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_super_weight_directly(original_text: str, attacked_text: str, \n",
    "                              model, tokenizer, super_weight, attack_system):\n",
    "    \"\"\"Test the super weight activation directly\"\"\"\n",
    "    \n",
    "    print(\"=== SUPER WEIGHT ACTIVATION TEST ===\")\n",
    "    \n",
    "    # Test original\n",
    "    original_tokens = tokenizer(original_text, return_tensors=\"pt\").to(model.device)\n",
    "    original_embeddings = model.get_input_embeddings()(original_tokens['input_ids'])\n",
    "    original_gate = attack_system._get_gate_output(original_embeddings, super_weight.layer, super_weight.column)\n",
    "    \n",
    "    # Test attacked\n",
    "    attacked_tokens = tokenizer(attacked_text, return_tensors=\"pt\").to(model.device)\n",
    "    attacked_embeddings = model.get_input_embeddings()(attacked_tokens['input_ids'])\n",
    "    attacked_gate = attack_system._get_gate_output(attacked_embeddings, super_weight.layer, super_weight.column)\n",
    "    \n",
    "    reduction = (abs(original_gate.item()) - abs(attacked_gate.item())) / abs(original_gate.item()) * 100\n",
    "    \n",
    "    print(f\"Original text: '{original_text}'\")\n",
    "    print(f\"  Super weight gate output: {original_gate.item():.4f}\")\n",
    "    print(f\"Attacked text: '{attacked_text}'\")\n",
    "    print(f\"  Super weight gate output: {attacked_gate.item():.4f}\")\n",
    "    print(f\"Reduction: {reduction:.1f}%\")\n",
    "    \n",
    "    return {\n",
    "        'original_gate': original_gate.item(),\n",
    "        'attacked_gate': attacked_gate.item(),\n",
    "        'reduction_percentage': reduction\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SUPER WEIGHT ACTIVATION TEST ===\n",
      "Original text: 'Apple Inc. is a tech company.'\n",
      "  Super weight gate output: 0.6904\n",
      "Attacked text: '~~~~ Apple Inc. is a tech company.'\n",
      "  Super weight gate output: -0.1934\n",
      "Reduction: 72.0%\n"
     ]
    }
   ],
   "source": [
    "# Test super weight\n",
    "sw_results = test_super_weight_directly(\n",
    "    original_text, attacked_text, session.model, session.tokenizer, \n",
    "    sw[0],  # Your super weight\n",
    "    gd_attack  # Your attack system\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super-weights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
