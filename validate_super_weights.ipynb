{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super Weights Analysis - Identifying Super Weights and their Impact on Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from research.researcher import SuperWeightResearchSession\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_name = 'mistralai/Mistral-7B-v0.1'\n",
    "# model_name = 'meta-llama/Llama-2-7b-hf'\n",
    "model_name = 'OLMo-1B-0724-hf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found locally downloaded model at /Users/fabiangrob/models/OLMo-1B-0724-hf\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82be08435f574bd28211dc429afa0f40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 02:22:14,169 - SuperWeightManager_13335784384 - INFO - SuperWeightManager initialized with shared MLP handler\n",
      "2025-09-01 02:22:14,172 - SuperWeightDetector_13335784480 - INFO - SuperWeightDetector initialized for -Users-fabiangrob-models-OLMo-1B-0724-hf\n",
      "2025-09-01 02:22:14,172 - SuperWeightDetector_13335784480 - INFO - Model has 16 layers\n",
      "2025-09-01 02:22:14,172 - SuperWeightDetector_13335784480 - INFO - SuperWeightDetector initialized with manager integration\n",
      "2025-09-01 02:22:14,173 - SuperWeightResearch_13275716896 - INFO - SuperWeightResearchSession initialized\n",
      "2025-09-01 02:22:14,173 - SuperWeightResearch_13275716896 - INFO - Model: -Users-fabiangrob-models-OLMo-1B-0724-hf\n",
      "2025-09-01 02:22:14,174 - SuperWeightResearch_13275716896 - INFO - Architecture: gated_mlp\n",
      "2025-09-01 02:22:14,174 - SuperWeightResearch_13275716896 - INFO - Using detector: SuperWeightDetector\n"
     ]
    }
   ],
   "source": [
    "session = SuperWeightResearchSession.from_model_name(model_name, cache_dir='~/models/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OlmoForCausalLM(\n",
       "  (model): OlmoModel(\n",
       "    (embed_tokens): Embedding(50304, 2048, padding_idx=1)\n",
       "    (layers): ModuleList(\n",
       "      (0-15): 16 x OlmoDecoderLayer(\n",
       "        (self_attn): OlmoAttention(\n",
       "          (q_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (k_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (v_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "          (o_proj): Linear(in_features=2048, out_features=2048, bias=False)\n",
       "        )\n",
       "        (mlp): OlmoMLP(\n",
       "          (gate_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=2048, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=2048, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): OlmoLayerNorm()\n",
       "        (post_attention_layernorm): OlmoLayerNorm()\n",
       "      )\n",
       "    )\n",
       "    (norm): OlmoLayerNorm()\n",
       "    (rotary_emb): OlmoRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=2048, out_features=50304, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session.model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 02:22:15,457 - SuperWeightResearch_13275716896 - INFO - Starting super weight detection\n",
      "2025-09-01 02:22:15,458 - SuperWeightDetector_13335784480 - INFO - Starting super weight detection\n",
      "2025-09-01 02:22:15,458 - SuperWeightDetector_13335784480 - INFO - Parameters: threshold=70.0, max_iterations=10\n",
      "2025-09-01 02:22:15,458 - SuperWeightDetector_13335784480 - INFO - Zero detected weights: True\n",
      "2025-09-01 02:22:15,462 - SuperWeightDetector_13335784480 - INFO - === Iteration 1 ===\n",
      "2025-09-01 02:22:15,879 - SuperWeightDetector_13335784480 - INFO - Found 2 potential super weights in iteration 1\n",
      "2025-09-01 02:22:15,879 - SuperWeightDetector_13335784480 - INFO - Zeroing 2 detected super weights...\n",
      "2025-09-01 02:22:15,909 - SuperWeightManager_13335784384 - INFO - Successfully scaled 2/2 super weights by 0.000\n",
      "2025-09-01 02:22:15,909 - SuperWeightDetector_13335784480 - INFO - Found 2 new super weights:\n",
      "2025-09-01 02:22:15,909 - SuperWeightDetector_13335784480 - INFO -   1. Layer 1 mlp.down_proj.weight[1764, 1710] - Input: -401.50, Output: -262.00\n",
      "2025-09-01 02:22:15,909 - SuperWeightDetector_13335784480 - INFO -   2. Layer 15 mlp.down_proj.weight[1764, 6840] - Input: -283.00, Output: 415.00\n",
      "2025-09-01 02:22:15,910 - SuperWeightDetector_13335784480 - INFO - === Iteration 2 ===\n",
      "2025-09-01 02:22:16,071 - SuperWeightDetector_13335784480 - INFO - Found 2 potential super weights in iteration 2\n",
      "2025-09-01 02:22:16,072 - SuperWeightDetector_13335784480 - INFO - Zeroing 2 detected super weights...\n",
      "2025-09-01 02:22:16,082 - SuperWeightManager_13335784384 - INFO - Successfully scaled 2/2 super weights by 0.000\n",
      "2025-09-01 02:22:16,082 - SuperWeightDetector_13335784480 - INFO - Found 2 new super weights:\n",
      "2025-09-01 02:22:16,083 - SuperWeightDetector_13335784480 - INFO -   1. Layer 2 mlp.down_proj.weight[1764, 8041] - Input: 345.25, Output: -227.50\n",
      "2025-09-01 02:22:16,083 - SuperWeightDetector_13335784480 - INFO -   2. Layer 15 mlp.down_proj.weight[1764, 3454] - Input: -170.38, Output: 145.88\n",
      "2025-09-01 02:22:16,083 - SuperWeightDetector_13335784480 - INFO - === Iteration 3 ===\n",
      "2025-09-01 02:22:16,246 - SuperWeightDetector_13335784480 - INFO - Found 0 potential super weights in iteration 3\n",
      "2025-09-01 02:22:16,247 - SuperWeightDetector_13335784480 - INFO - No new super weights found. Stopping detection.\n",
      "2025-09-01 02:22:16,247 - SuperWeightDetector_13335784480 - INFO - === DETECTION COMPLETE ===\n",
      "2025-09-01 02:22:16,248 - SuperWeightDetector_13335784480 - INFO - Found 4 super weights:\n",
      "2025-09-01 02:22:16,248 - SuperWeightDetector_13335784480 - INFO - 1. Layer 1 mlp.down_proj.weight[1764, 1710] (Iteration 1)\n",
      "2025-09-01 02:22:16,248 - SuperWeightDetector_13335784480 - INFO -    Input: -401.50, Output: -262.00\n",
      "2025-09-01 02:22:16,249 - SuperWeightDetector_13335784480 - INFO - 2. Layer 15 mlp.down_proj.weight[1764, 6840] (Iteration 1)\n",
      "2025-09-01 02:22:16,249 - SuperWeightDetector_13335784480 - INFO -    Input: -283.00, Output: 415.00\n",
      "2025-09-01 02:22:16,249 - SuperWeightDetector_13335784480 - INFO - 3. Layer 2 mlp.down_proj.weight[1764, 8041] (Iteration 2)\n",
      "2025-09-01 02:22:16,250 - SuperWeightDetector_13335784480 - INFO -    Input: 345.25, Output: -227.50\n",
      "2025-09-01 02:22:16,250 - SuperWeightDetector_13335784480 - INFO - 4. Layer 15 mlp.down_proj.weight[1764, 3454] (Iteration 2)\n",
      "2025-09-01 02:22:16,251 - SuperWeightDetector_13335784480 - INFO -    Input: -170.38, Output: 145.88\n",
      "2025-09-01 02:22:16,251 - SuperWeightDetector_13335784480 - INFO - Super weights found in 3 layers:\n",
      "2025-09-01 02:22:16,251 - SuperWeightDetector_13335784480 - INFO -   Layer 1: 1 super weights\n",
      "2025-09-01 02:22:16,252 - SuperWeightDetector_13335784480 - INFO -   Layer 15: 2 super weights\n",
      "2025-09-01 02:22:16,252 - SuperWeightDetector_13335784480 - INFO -   Layer 2: 1 super weights\n",
      "2025-09-01 02:22:16,252 - SuperWeightDetector_13335784480 - INFO - Restoring all modified weights...\n",
      "2025-09-01 02:22:16,257 - SuperWeightManager_13335784384 - INFO - Restored 4/4 weights\n",
      "2025-09-01 02:22:16,257 - SuperWeightResearch_13275716896 - INFO - Detection complete. Found 4 super weights\n"
     ]
    }
   ],
   "source": [
    "sw = session.detect_super_weights(spike_threshold=70.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SuperWeight(layer=1, coords=[1764, 1710], input=-401.50, output=-262.00),\n",
       " SuperWeight(layer=15, coords=[1764, 6840], input=-283.00, output=415.00),\n",
       " SuperWeight(layer=2, coords=[1764, 8041], input=345.25, output=-227.50),\n",
       " SuperWeight(layer=15, coords=[1764, 3454], input=-170.38, output=145.88)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Vocabulary Effect Card: Layer 1 mlp.down_proj.weight[1764, 1710] ===\n",
      "Processing applied: True\n",
      "\n",
      "--- Raw Dot Product Analysis ---\n",
      "Classification: UNCLEAR (0.15)\n",
      "  Effects too small or distributed to classify clearly\n",
      "Moments: var=0.000, skew=0.20, kurt=-3.00\n",
      "Percentiles: p5=-0.010, p50=-0.000, p95=0.012\n",
      "Best theme: whitespace_prefixed (score: 0.126)\n",
      "Top 10 boosted:\n",
      "  1. ' �' (+0.038)\n",
      "  2. ' vet' (+0.031)\n",
      "  3. ' stir' (+0.031)\n",
      "  4. ' appeal' (+0.031)\n",
      "  5. ' appro' (+0.031)\n",
      "  6. ' comm' (+0.031)\n",
      "  7. ' Polish' (+0.030)\n",
      "  8. ' plac' (+0.030)\n",
      "  9. ' bro' (+0.029)\n",
      "  10. ' MOT' (+0.029)\n",
      "Top 10 suppressed:\n",
      "  1. ' mar' (-0.034)\n",
      "  2. ' mutual' (-0.031)\n",
      "  3. ' Bell' (-0.029)\n",
      "  4. '039' (-0.028)\n",
      "  5. ' corresponding' (-0.028)\n",
      "  6. ' RE' (-0.027)\n",
      "  7. ' enormous' (-0.027)\n",
      "  8. ' notebook' (-0.027)\n",
      "  9. ' Final' (-0.027)\n",
      "  10. ' respective' (-0.027)\n",
      "\n",
      "--- Cosine Similarity Analysis ---\n",
      "Classification: UNCLEAR (0.01)\n",
      "Moments: var=0.000, skew=-0.13, kurt=-0.24\n",
      "Percentiles: p5=-0.021, p50=-0.001, p95=0.019\n",
      "Classification: UNCLEAR (0.15)\n",
      "  Effects too small or distributed to classify clearly\n",
      "Moments: var=0.00, skew=0.20, kurt=-3.00\n",
      "Best theme: whitespace_prefixed (score: 0.126)\n",
      "Top 10 boosted:\n",
      "  1. ' �' (+0.038)\n",
      "  2. ' vet' (+0.031)\n",
      "  3. ' stir' (+0.031)\n",
      "  4. ' appeal' (+0.031)\n",
      "  5. ' appro' (+0.031)\n",
      "  6. ' comm' (+0.031)\n",
      "  7. ' Polish' (+0.030)\n",
      "  8. ' plac' (+0.030)\n",
      "  9. ' bro' (+0.029)\n",
      "  10. ' MOT' (+0.029)\n",
      "Top 10 suppressed:\n",
      "  1. ' mar' (-0.034)\n",
      "  2. ' mutual' (-0.031)\n",
      "  3. ' Bell' (-0.029)\n",
      "  4. '039' (-0.028)\n",
      "  5. ' corresponding' (-0.028)\n",
      "  6. ' RE' (-0.027)\n",
      "  7. ' enormous' (-0.027)\n",
      "  8. ' notebook' (-0.027)\n",
      "  9. ' Final' (-0.027)\n",
      "  10. ' respective' (-0.027)\n"
     ]
    }
   ],
   "source": [
    "# Enhanced analysis with Universal Neurons processing\n",
    "enhanced_analysis = session.analyzer.vocabulary_analyzer.analyze_neuron_vocabulary_effects(\n",
    "    sw[0], \n",
    "    apply_universal_neurons_processing=True  # Enable layer norm folding & mean-centering\n",
    ")\n",
    "\n",
    "# Display the enhanced results\n",
    "session.analyzer.vocabulary_analyzer.display_vocabulary_card(enhanced_analysis, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 02:27:31,848 - SuperWeightManager_13335784384 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-09-01 02:27:45,586 - SuperWeightManager_13335784384 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Intervention Effect Card: Layer 1 mlp.down_proj.weight[1764, 1710] ===\n",
      "Loss: 3.3462 → 8.6478 (Δ+5.3016)\n",
      "Entropy: 3.2634 → 5.2730 (Δ+2.0096)\n",
      "Top-K Margin: 0.3086 → 0.2235 (Δ-0.0851)\n",
      "Stopword Mass: 0.1672 → 0.0607 (Δ-0.1066)\n",
      "Evaluated on 100 samples\n"
     ]
    }
   ],
   "source": [
    "# Analyze intervention effects with robust windowed evaluation\n",
    "intervention_results = session.analyzer.vocabulary_analyzer.analyze_super_weight_intervention(\n",
    "    sw[0],\n",
    "    n_samples=100  # Uses token-level filtering now\n",
    ")\n",
    "\n",
    "# Display intervention results\n",
    "session.analyzer.vocabulary_analyzer.display_intervention_results(intervention_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 02:28:11,527 - SuperWeightManager_13335784384 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-09-01 02:28:24,102 - SuperWeightManager_13335784384 - INFO - Restored 1/1 weights\n",
      "2025-09-01 02:28:36,538 - SuperWeightManager_13335784384 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-09-01 02:28:48,911 - SuperWeightManager_13335784384 - INFO - Restored 1/1 weights\n",
      "2025-09-01 02:29:01,348 - SuperWeightManager_13335784384 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-09-01 02:29:13,587 - SuperWeightManager_13335784384 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Control Experiments ===\n",
      "Super Weight vs Random Baseline:\n",
      "  SW delta loss: +5.2069\n",
      "  Random delta loss: +5.2069\n",
      "  Specificity ratio: 1.00x\n",
      "\n",
      "Neuron vs Scalar:\n",
      "  Scalar contribution: 1.38\n",
      "\n",
      "Deterministic check:\n",
      "  Is deterministic: True\n"
     ]
    }
   ],
   "source": [
    "# Run comprehensive control experiments\n",
    "control_results = session.analyzer.vocabulary_analyzer.analyze_controls_and_baselines(\n",
    "    sw[0],\n",
    "    n_samples=100\n",
    ")\n",
    "\n",
    "print(\"=== Control Experiments ===\")\n",
    "print(f\"Super Weight vs Random Baseline:\")\n",
    "print(f\"  SW delta loss: {control_results['random_baseline']['sw_delta_loss']:+.4f}\")\n",
    "print(f\"  Random delta loss: {control_results['random_baseline']['random_delta_loss']:+.4f}\")\n",
    "print(f\"  Specificity ratio: {control_results['random_baseline']['specificity_ratio']:.2f}x\")\n",
    "\n",
    "print(f\"\\nNeuron vs Scalar:\")\n",
    "print(f\"  Scalar contribution: {control_results['neuron_vs_scalar']['scalar_contribution_ratio']:.2f}\")\n",
    "\n",
    "print(f\"\\nDeterministic check:\")\n",
    "print(f\"  Is deterministic: {control_results['noop_check']['is_deterministic']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 03:08:48,953 - SuperWeightManager_13335784384 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-09-01 03:08:49,051 - SuperWeightManager_13335784384 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Cascade Effect Card: Layer 1 mlp.down_proj.weight[1764, 1710] ===\n",
      "Input: Apple Inc. develops innovative technology solutions.\n",
      "Pattern: accelerating\n",
      "Layers analyzed: 8\n",
      "Actual layer indices: [0, 2, 4, 6, 8, 10, 12, 14]\n",
      "Top-K margin parameter: 15\n",
      "\n",
      "Layer-by-layer effects:\n",
      "  Layer 0: entropy_Δ=+0.0000, margin_Δ=+0.0000, magnitude=0.0000\n",
      "  Layer 2: entropy_Δ=+0.0078, margin_Δ=-0.0242, magnitude=15.3984\n",
      "  Layer 4: entropy_Δ=+0.0000, margin_Δ=-0.0254, magnitude=14.8125\n",
      "  Layer 6: entropy_Δ=+0.0000, margin_Δ=+0.0061, magnitude=16.8594\n",
      "  Layer 8: entropy_Δ=+0.0078, margin_Δ=-0.0100, magnitude=18.9219\n",
      "  Layer 10: entropy_Δ=-0.0078, margin_Δ=+0.0154, magnitude=21.1094\n",
      "  Layer 12: entropy_Δ=-0.0078, margin_Δ=-0.0742, magnitude=26.7031\n",
      "  Layer 14: entropy_Δ=-0.0312, margin_Δ=-0.1768, magnitude=44.9062\n",
      "\n",
      "Actual layers analyzed: [0, 2, 4, 6, 8, 10, 12, 14]\n"
     ]
    }
   ],
   "source": [
    "# Analyze cascade effects with custom parameters\n",
    "cascade_results = session.analyzer.vocabulary_analyzer.analyze_cascade_effects(\n",
    "    sw[0],\n",
    "    input_text=\"Apple Inc. develops innovative technology solutions.\",\n",
    "    num_layers=8,  # Sample 8 layers instead of default 5\n",
    "    top_k_margin=15  # Use top-15 for margin calculation instead of default 10\n",
    ")\n",
    "\n",
    "# Display with the new method that shows actual layer indices\n",
    "session.analyzer.vocabulary_analyzer.display_cascade_results(cascade_results)\n",
    "\n",
    "# Now you can see which exact layers were analyzed!\n",
    "print(f\"Actual layers analyzed: {cascade_results['actual_layer_indices']}\")\n",
    "# Example output: [0, 4, 8, 12, 16, 20, 24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Enhanced vs Standard Analysis Comparison ===\n",
      "Enhanced Analysis:\n",
      "=== Vocabulary Effect Card: Layer 1 mlp.down_proj.weight[1764, 1710] ===\n",
      "Processing applied: True\n",
      "\n",
      "--- Raw Dot Product Analysis ---\n",
      "Classification: UNCLEAR (0.15)\n",
      "  Effects too small or distributed to classify clearly\n",
      "Moments: var=0.000, skew=0.20, kurt=-3.00\n",
      "Percentiles: p5=-0.010, p50=-0.000, p95=0.012\n",
      "Best theme: whitespace_prefixed (score: 0.126)\n",
      "Top 5 boosted:\n",
      "  1. ' �' (+0.038)\n",
      "  2. ' vet' (+0.031)\n",
      "  3. ' stir' (+0.031)\n",
      "  4. ' appeal' (+0.031)\n",
      "  5. ' appro' (+0.031)\n",
      "Top 5 suppressed:\n",
      "  1. ' mar' (-0.034)\n",
      "  2. ' mutual' (-0.031)\n",
      "  3. ' Bell' (-0.029)\n",
      "  4. '039' (-0.028)\n",
      "  5. ' corresponding' (-0.028)\n",
      "\n",
      "--- Cosine Similarity Analysis ---\n",
      "Classification: UNCLEAR (0.01)\n",
      "Moments: var=0.000, skew=-0.13, kurt=-0.24\n",
      "Percentiles: p5=-0.021, p50=-0.001, p95=0.019\n",
      "Classification: UNCLEAR (0.15)\n",
      "  Effects too small or distributed to classify clearly\n",
      "Moments: var=0.00, skew=0.20, kurt=-3.00\n",
      "Best theme: whitespace_prefixed (score: 0.126)\n",
      "Top 5 boosted:\n",
      "  1. ' �' (+0.038)\n",
      "  2. ' vet' (+0.031)\n",
      "  3. ' stir' (+0.031)\n",
      "  4. ' appeal' (+0.031)\n",
      "  5. ' appro' (+0.031)\n",
      "Top 5 suppressed:\n",
      "  1. ' mar' (-0.034)\n",
      "  2. ' mutual' (-0.031)\n",
      "  3. ' Bell' (-0.029)\n",
      "  4. '039' (-0.028)\n",
      "  5. ' corresponding' (-0.028)\n",
      "\n",
      "==================================================\n",
      "Standard Analysis:\n",
      "=== Vocabulary Effect Card: Layer 1 mlp.down_proj.weight[1764, 1710] ===\n",
      "Processing applied: False\n",
      "\n",
      "--- Raw Dot Product Analysis ---\n",
      "Classification: UNCLEAR (0.15)\n",
      "  Effects too small or distributed to classify clearly\n",
      "Moments: var=0.000, skew=0.20, kurt=-3.00\n",
      "Percentiles: p5=-0.011, p50=-0.001, p95=0.011\n",
      "Best theme: whitespace_prefixed (score: 0.127)\n",
      "Top 5 boosted:\n",
      "  1. ' �' (+0.038)\n",
      "  2. ' vet' (+0.031)\n",
      "  3. ' stir' (+0.031)\n",
      "  4. ' appeal' (+0.031)\n",
      "  5. ' appro' (+0.031)\n",
      "Top 5 suppressed:\n",
      "  1. ' mar' (-0.034)\n",
      "  2. ' mutual' (-0.032)\n",
      "  3. ' Bell' (-0.029)\n",
      "  4. '039' (-0.028)\n",
      "  5. ' corresponding' (-0.028)\n",
      "\n",
      "--- Cosine Similarity Analysis ---\n",
      "Classification: UNCLEAR (0.01)\n",
      "Moments: var=0.000, skew=-0.10, kurt=-0.19\n",
      "Percentiles: p5=-0.022, p50=-0.001, p95=0.018\n",
      "Classification: UNCLEAR (0.15)\n",
      "  Effects too small or distributed to classify clearly\n",
      "Moments: var=0.00, skew=0.20, kurt=-3.00\n",
      "Best theme: whitespace_prefixed (score: 0.127)\n",
      "Top 5 boosted:\n",
      "  1. ' �' (+0.038)\n",
      "  2. ' vet' (+0.031)\n",
      "  3. ' stir' (+0.031)\n",
      "  4. ' appeal' (+0.031)\n",
      "  5. ' appro' (+0.031)\n",
      "Top 5 suppressed:\n",
      "  1. ' mar' (-0.034)\n",
      "  2. ' mutual' (-0.032)\n",
      "  3. ' Bell' (-0.029)\n",
      "  4. '039' (-0.028)\n",
      "  5. ' corresponding' (-0.028)\n"
     ]
    }
   ],
   "source": [
    "# Compare enhanced vs standard analysis\n",
    "print(\"=== Enhanced vs Standard Analysis Comparison ===\")\n",
    "\n",
    "# Enhanced (with Universal Neurons processing)\n",
    "enhanced = session.analyzer.vocabulary_analyzer.analyze_neuron_vocabulary_effects(\n",
    "    sw[0], \n",
    "    apply_universal_neurons_processing=True\n",
    ")\n",
    "\n",
    "# Standard (without processing)\n",
    "standard = session.analyzer.vocabulary_analyzer.analyze_neuron_vocabulary_effects(\n",
    "    sw[0], \n",
    "    apply_universal_neurons_processing=False\n",
    ")\n",
    "\n",
    "print(\"Enhanced Analysis:\")\n",
    "session.analyzer.vocabulary_analyzer.display_vocabulary_card(enhanced)\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"Standard Analysis:\")\n",
    "session.analyzer.vocabulary_analyzer.display_vocabulary_card(standard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Token Class Enrichment ===\n",
      "Best enriched class: whitespace_prefixed\n",
      "Enrichment score: 0.126\n",
      "Description: Effects concentrated in whitespace_prefixed tokens\n",
      "\n",
      "All enrichment scores:\n",
      "  whitespace_prefixed: 0.126 (mean=+0.002, count=28854)\n"
     ]
    }
   ],
   "source": [
    "# Analyze enrichment in specific token classes\n",
    "analysis = session.analyzer.vocabulary_analyzer.analyze_neuron_vocabulary_effects(\n",
    "    sw[0], apply_universal_neurons_processing=True\n",
    ")\n",
    "\n",
    "enrichment = analysis['raw_analysis']['enrichment']\n",
    "print(\"=== Token Class Enrichment ===\")\n",
    "print(f\"Best enriched class: {enrichment['best_theme']['class']}\")\n",
    "print(f\"Enrichment score: {enrichment['best_theme']['score']:.3f}\")\n",
    "print(f\"Description: {enrichment['best_theme']['description']}\")\n",
    "\n",
    "print(\"\\nAll enrichment scores:\")\n",
    "for class_name, score in enrichment['enrichment_scores'].items():\n",
    "    if score > 0.1:  # Only show significant enrichments\n",
    "        effects = enrichment['class_effects'][class_name]\n",
    "        print(f\"  {class_name}: {score:.3f} (mean={effects['mean']:+.3f}, count={effects['count']})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perplexity and Accuracy analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sw[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 16:12:08,000 - SuperWeightManager_140164721294544 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 16:12:16,832 - SuperWeightManager_140164721294544 - INFO - Restored 1/1 weights\n"
     ]
    }
   ],
   "source": [
    "perplexity_impact = session.analyzer.metrics_analyzer.measure_perplexity_impact(sw[0], n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'baseline_perplexity': 10.63492488861084,\n",
       " 'modified_perplexity': 5289.5185546875,\n",
       " 'perplexity_ratio': 497.3724412809116,\n",
       " 'perplexity_increase': 5278.883629798889,\n",
       " 'impact_severity': 'catastrophic',\n",
       " 'dataset_info': {'name': 'wikitext',\n",
       "  'config': 'wikitext-2-raw-v1',\n",
       "  'split': 'test',\n",
       "  'n_samples': 100},\n",
       " 'super_weight': SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perplexity_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 mlp.down_proj.weight[788, 2427]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:58:02,444 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 13:58:49,356 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity impact for Layer 1 mlp.down_proj.weight[788, 2427]: {'baseline_perplexity': 11.002143859863281, 'modified_perplexity': 11.295992851257324, 'perplexity_ratio': 1.0267083393143066, 'perplexity_increase': 0.29384899139404297, 'impact_severity': 'minimal', 'dataset_info': {'name': 'wikitext', 'config': 'wikitext-2-raw-v1', 'split': 'test', 'n_samples': 500}, 'super_weight': SuperWeight(layer=1, coords=[788, 2427], input=-443.50, output=300.50)}\n",
      "Layer 31 mlp.down_proj.weight[788, 12111]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 13:59:38,902 - SuperWeightManager_139901926293312 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 14:00:25,809 - SuperWeightManager_139901926293312 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity impact for Layer 31 mlp.down_proj.weight[788, 12111]: {'baseline_perplexity': 11.002143859863281, 'modified_perplexity': 11.023534774780273, 'perplexity_ratio': 1.0019442497016449, 'perplexity_increase': 0.021390914916992188, 'impact_severity': 'minimal', 'dataset_info': {'name': 'wikitext', 'config': 'wikitext-2-raw-v1', 'split': 'test', 'n_samples': 500}, 'super_weight': SuperWeight(layer=31, coords=[788, 12111], input=151.00, output=-299.75)}\n"
     ]
    }
   ],
   "source": [
    "for super_weight in sw:\n",
    "    print(super_weight)\n",
    "    ppl_res = session.analyzer.metrics_analyzer.measure_perplexity_impact(super_weight, n_samples=500)\n",
    "    print(f\"Perplexity impact for {super_weight}: {ppl_res}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 14:16:07,042 - SuperWeightManager_139901044718128 - INFO - Successfully scaled 2/2 super weights by 0.000\n",
      "2025-07-04 14:16:51,120 - SuperWeightManager_139901044718128 - INFO - Restored 2/2 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity impact for all super weights: {'baseline_perplexity': 9.51281452178955, 'modified_perplexity': 4830.10791015625, 'perplexity_ratio': 507.7475124835725, 'perplexity_increase': 4820.59509563446, 'impact_severity': 'catastrophic', 'dataset_info': {'name': 'wikitext', 'config': 'wikitext-2-raw-v1', 'split': 'test', 'n_samples': 500}, 'super_weights': [SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75), SuperWeight(layer=31, coords=[53, 2187], input=-906.00, output=-84.50)], 'num_weights': 2, 'average_impact_per_weight': 2410.29754781723}\n"
     ]
    }
   ],
   "source": [
    "# check impact of all super weights at once\n",
    "all_sw_ppl = session.analyzer.metrics_analyzer.measure_perplexity_impact(sw, n_samples=500)\n",
    "print(f\"Perplexity impact for all super weights: {all_sw_ppl}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-04 14:18:35,674 - SuperWeightManager_139901044718128 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-07-04 14:19:04,362 - SuperWeightManager_139901044718128 - INFO - Restored 1/1 weights\n"
     ]
    }
   ],
   "source": [
    "accuracy_impact = session.analyzer.metrics_analyzer.measure_accuracy_impact(sw[0], n_samples=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'task': 'hellaswag',\n",
       " 'baseline_accuracy': 0.64,\n",
       " 'modified_accuracy': 0.33,\n",
       " 'accuracy_drop': 0.31,\n",
       " 'accuracy_ratio': 0.515625,\n",
       " 'impact_severity': 'severe',\n",
       " 'n_samples': 100,\n",
       " 'super_weight': SuperWeight(layer=1, coords=[2070, 7310], input=950.00, output=-262.75)}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer 1 mlp.down_proj.weight[1764, 1710]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 01:51:27,451 - SuperWeightManager_13442570496 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-06-10 01:52:12,462 - SuperWeightManager_13442570496 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy impact for Layer 1 mlp.down_proj.weight[1764, 1710]: {'super_weight': SuperWeight(layer=1, coords=[1764, 1710], input=-401.50, output=-262.00), 'task': 'hellaswag', 'baseline_accuracy': 0.475, 'modified_accuracy': 0.355, 'accuracy_drop': 0.12, 'accuracy_ratio': 0.7473684210526316, 'impact_severity': 'moderate', 'n_samples': 200}\n",
      "Layer 3 mlp.down_proj.weight[1764, 1902]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 01:52:59,266 - SuperWeightManager_13442570496 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-06-10 01:53:44,296 - SuperWeightManager_13442570496 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy impact for Layer 3 mlp.down_proj.weight[1764, 1902]: {'super_weight': SuperWeight(layer=3, coords=[1764, 1902], input=-63.56, output=-64.69), 'task': 'hellaswag', 'baseline_accuracy': 0.475, 'modified_accuracy': 0.465, 'accuracy_drop': 0.009999999999999953, 'accuracy_ratio': 0.9789473684210527, 'impact_severity': 'minimal', 'n_samples': 200}\n",
      "Layer 15 mlp.down_proj.weight[1764, 6840]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-10 01:54:30,827 - SuperWeightManager_13442570496 - INFO - Successfully scaled 1/1 super weights by 0.000\n",
      "2025-06-10 01:55:15,710 - SuperWeightManager_13442570496 - INFO - Restored 1/1 weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy impact for Layer 15 mlp.down_proj.weight[1764, 6840]: {'super_weight': SuperWeight(layer=15, coords=[1764, 6840], input=-283.00, output=415.00), 'task': 'hellaswag', 'baseline_accuracy': 0.475, 'modified_accuracy': 0.47, 'accuracy_drop': 0.0050000000000000044, 'accuracy_ratio': 0.9894736842105263, 'impact_severity': 'minimal', 'n_samples': 200}\n"
     ]
    }
   ],
   "source": [
    "for super_weight in sw:\n",
    "    print(super_weight)\n",
    "    acc_res = session.analyzer.metrics_analyzer.measure_accuracy_impact(super_weight, n_samples=200)\n",
    "    print(f\"Accuracy impact for {super_weight}: {acc_res}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detailed mathematical break down of super activation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-01 03:12:11,893 - SuperWeightAnalyzer_13066373392 - INFO - Mathematical super activation analysis for Layer 1 mlp.down_proj.weight[1764, 1710]\n",
      "2025-09-01 03:12:11,895 - SuperActivationAnalyzer_13335784816 - INFO - Super activation analysis for Layer 1 mlp.down_proj.weight[1764, 1710]\n",
      "2025-09-01 03:12:11,896 - SuperActivationAnalyzer_13335784816 - INFO - Detected architecture: MLPArchitectureType.GATED_MLP\n"
     ]
    }
   ],
   "source": [
    "mathematical_analysis = session.analyzer.mathematical_super_activation_analysis(sw[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_analysis': {'input_vector_shape': [2048],\n",
       "  'input_magnitude': 45.21875,\n",
       "  'input_mean': 4.470348358154297e-06,\n",
       "  'input_std': 0.99951171875},\n",
       " 'step1_gate_projection': {'operation': 'gate_output = W_gate @ x',\n",
       "  'bias_term': None,\n",
       "  'result_target_channel': 15.2421875,\n",
       "  'has_bias': False},\n",
       " 'step2_activation': {'operation': 'activated_gate = SILU(gate_output)',\n",
       "  'input_to_activation': 15.2421875,\n",
       "  'activation_output_target_channel': 15.2421875,\n",
       "  'activation_function': 'silu',\n",
       "  'activation_derivative_at_point': 1.000003395600431},\n",
       " 'step3_up_projection': {'operation': 'up_output = W_up @ x',\n",
       "  'bias_term': None,\n",
       "  'result_target_channel': -26.34375,\n",
       "  'has_bias': False},\n",
       " 'step4_hadamard_product': {'operation': 'hadamard_result = activated_gate ⊙ up_output (ELEMENT-WISE MULTIPLICATION)',\n",
       "  'activated_gate_component': 15.2421875,\n",
       "  'up_output_component': -26.34375,\n",
       "  'super_activation_result': -401.5,\n",
       "  'formula': 'y[:, 1710] = SILU(W_gate[1710] @ x) * (W_up[1710] @ x)',\n",
       "  'this_is_where_super_activation_is_created': True},\n",
       " 'step5_down_projection': {'operation': 'final_output = W_down @ hadamard_result',\n",
       "  'super_weight_row': 1764,\n",
       "  'super_weight_processes_super_activation': -401.5,\n",
       "  'super_weight_contribution': -262.0,\n",
       "  'has_bias': False},\n",
       " 'verification': {'computed_super_activation': -401.5,\n",
       "  'super_activation_magnitude': 401.5,\n",
       "  'super_activation_sign': 'negative',\n",
       "  'expected_vs_actual': 'Expected ~-401.5, Computed: -401.50'}}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_analysis['mathematical_breakdown']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target_channel_info': {'channel_index': 1710,\n",
       "  'description': 'Channel 1710 in intermediate space where super activation occurs'},\n",
       " 'gate_weights_analysis': {'operation': 'gate_output[1710] = W_gate[1710] @ x',\n",
       "  'weight_vector_norm': 1.39453125,\n",
       "  'max_weight': 0.317138671875,\n",
       "  'min_weight': -0.2432861328125,\n",
       "  'mean_weight': 0.0005812644958496094,\n",
       "  'std_weight': 0.0308074951171875,\n",
       "  'bias_term': None,\n",
       "  'top_5_positive_weights': [{'dimension': 803, 'weight': 0.317138671875},\n",
       "   {'dimension': 1542, 'weight': 0.266357421875},\n",
       "   {'dimension': 1930, 'weight': 0.246337890625},\n",
       "   {'dimension': 1344, 'weight': 0.2396240234375},\n",
       "   {'dimension': 517, 'weight': 0.1917724609375}],\n",
       "  'top_5_negative_weights': [{'dimension': 1981, 'weight': -0.2432861328125},\n",
       "   {'dimension': 623, 'weight': -0.2041015625},\n",
       "   {'dimension': 1916, 'weight': -0.149658203125},\n",
       "   {'dimension': 967, 'weight': -0.1490478515625},\n",
       "   {'dimension': 130, 'weight': -0.1474609375}]},\n",
       " 'up_weights_analysis': {'operation': 'up_output[1710] = W_up[1710] @ x',\n",
       "  'weight_vector_norm': 1.3056640625,\n",
       "  'max_weight': 0.275390625,\n",
       "  'min_weight': -0.09918212890625,\n",
       "  'mean_weight': -0.0004031658172607422,\n",
       "  'std_weight': 0.0288543701171875,\n",
       "  'bias_term': None,\n",
       "  'top_5_positive_weights': [{'dimension': 1764, 'weight': 0.275390625},\n",
       "   {'dimension': 1139, 'weight': 0.1201171875},\n",
       "   {'dimension': 1655, 'weight': 0.11749267578125},\n",
       "   {'dimension': 1618, 'weight': 0.10455322265625},\n",
       "   {'dimension': 1916, 'weight': 0.0968017578125}],\n",
       "  'top_5_negative_weights': [{'dimension': 517, 'weight': -0.09918212890625},\n",
       "   {'dimension': 819, 'weight': -0.0963134765625},\n",
       "   {'dimension': 803, 'weight': -0.09539794921875},\n",
       "   {'dimension': 915, 'weight': -0.089111328125},\n",
       "   {'dimension': 1735, 'weight': -0.08795166015625}]},\n",
       " 'weight_interaction_analysis': {'gate_up_correlation': -0.0711809548182152,\n",
       "  'same_sign_percentage': 49.755859375,\n",
       "  'weight_magnitude_ratio': 1.068359375,\n",
       "  'coordinated_amplification': 'NO'}}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mathematical_analysis['weight_analysis']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "super-weights",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
